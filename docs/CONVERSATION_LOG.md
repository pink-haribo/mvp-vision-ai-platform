## [2025-11-14 14:00] Dual Storage ì•„í‚¤í…ì²˜ êµ¬í˜„ ë° ê²€ì¦

### ë…¼ì˜ ì£¼ì œ
- MinIO ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ Dual Storage ë¶„ë¦¬ í•„ìš”ì„±
- ëª¨ë¸ ê°œë°œì ê´€ì ì—ì„œ Storage ì¶”ìƒí™”
- í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì „ì²´ í…ŒìŠ¤íŠ¸ (ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ â†’ í•™ìŠµ â†’ Checkpoint ì—…ë¡œë“œ)
- Backend CORS ì„¤ì • ì˜¤ë¥˜ ìˆ˜ì •

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. Dual Storage ì•„í‚¤í…ì²˜ í™•ë¦½ âœ…
**ë°°ê²½**:
- ê¸°ì¡´: ë‹¨ì¼ MinIO ì¸ìŠ¤í„´ìŠ¤ì— ëª¨ë“  ë°ì´í„° í˜¼ì¬
- ë¬¸ì œ: ë°ì´í„°ì…‹(ì½ê¸° ìœ„ì£¼)ê³¼ í•™ìŠµ ê²°ê³¼ë¬¼(ì“°ê¸° ìœ„ì£¼)ì˜ ì•¡ì„¸ìŠ¤ íŒ¨í„´ ì°¨ì´

**ê²°ì •**:
- **External Storage (MinIO-Datasets)** - Port 9000/9001
  - ìš©ë„: ë°ì´í„°ì…‹ ì´ë¯¸ì§€ ì €ì¥ (ì½ê¸° ìœ„ì£¼)
  - Bucket: training-datasets, vision-platform-dev
  
- **Internal Storage (MinIO-Results)** - Port 9002/9003
  - ìš©ë„: í•™ìŠµ ê²°ê³¼ë¬¼ (ì“°ê¸° ìœ„ì£¼)
  - Bucket: training-checkpoints, training-results, model-weights, config-schemas, mlflow-artifacts

**ì´ìœ **:
- ì„±ëŠ¥ ê²©ë¦¬: ì½ê¸°/ì“°ê¸° ì›Œí¬ë¡œë“œ ë¶„ë¦¬
- ë³´ì•ˆ ê²½ê³„: ë°ì´í„°ì…‹ê³¼ ê²°ê³¼ë¬¼ ë¶„ë¦¬
- ë¹„ìš© ìµœì í™”: ê° ìŠ¤í† ë¦¬ì§€ì— ë§ëŠ” ì •ì±… ì ìš© ê°€ëŠ¥

#### 2. DualStorageClient êµ¬í˜„ - ê°œë°œì ê²½í—˜ ê°œì„  âœ…
**ë¬¸ì œ**: ëª¨ë¸ ê°œë°œìê°€ ë‘ ê°œì˜ S3Clientë¥¼ ì§ì ‘ ê´€ë¦¬í•´ì•¼ í•¨

**í•´ê²°ì±…**: íˆ¬ëª…í•œ ë¼ìš°íŒ…ì„ ì œê³µí•˜ëŠ” `DualStorageClient` ì¶”ê°€
```python
# ì´ì „ (ë³µì¡)
dataset_client = S3Client(endpoint_9000, ...)
checkpoint_client = S3Client(endpoint_9002, ...)

dataset_client.download_dataset(...)
checkpoint_client.upload_checkpoint(...)

# í˜„ì¬ (ì‹¬í”Œ)
storage = DualStorageClient()  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ì„¤ì •

storage.download_dataset(...)   # ìë™ìœ¼ë¡œ External Storage ì‚¬ìš©
storage.upload_checkpoint(...)  # ìë™ìœ¼ë¡œ Internal Storage ì‚¬ìš©
```

**íŠ¹ì§•**:
- í™˜ê²½ë³€ìˆ˜ ìë™ ì½ê¸° (EXTERNAL_*, INTERNAL_*)
- Legacy fallback ì§€ì› (S3_ENDPOINT ë“±)
- ëª…í™•í•œ ë¡œê¹…ìœ¼ë¡œ ë””ë²„ê¹… ìš©ì´
- ëª¨ë¸ ê°œë°œìëŠ” storage routing ì‹ ê²½ ì•ˆ ì¨ë„ ë¨

### êµ¬í˜„ ë‚´ìš©

#### 1. Infrastructure (docker-compose.tier0.yaml)
- **íŒŒì¼**: `platform/infrastructure/docker-compose.tier0.yaml`
- **ë³€ê²½ì‚¬í•­**:
  - ë‹¨ì¼ `minio` ì„œë¹„ìŠ¤ë¥¼ `minio-datasets`, `minio-results`ë¡œ ë¶„ë¦¬
  - ê°ê° ë…ë¦½ì ì¸ port, volume, bucket ì„¤ì •
  - minio-setup ì„œë¹„ìŠ¤ì—ì„œ ì–‘ìª½ ë²„í‚· ìƒì„±

#### 2. DualStorageClient ì¶”ê°€
- **íŒŒì¼**: `platform/trainers/ultralytics/utils.py`
- **ì¶”ê°€ ê¸°ëŠ¥**:
  ```python
  class DualStorageClient:
      """Transparent dual storage routing"""
      def __init__(self):
          # External Storage (Datasets)
          self.external_client = S3Client(...)
          # Internal Storage (Results)
          self.internal_client = S3Client(...)
      
      def download_dataset(self, dataset_id, dest_dir):
          """Auto-route to External Storage"""
          self.external_client.download_dataset(...)
      
      def upload_checkpoint(self, local_path, job_id):
          """Auto-route to Internal Storage"""
          self.internal_client.upload_checkpoint(...)
  ```

#### 3. train.py ìˆ˜ì •
- **íŒŒì¼**: `platform/trainers/ultralytics/train.py`
- **ë³€ê²½ì‚¬í•­**:
  - `S3Client` â†’ `DualStorageClient` import ë³€ê²½
  - ë‹¨ì¼ `storage` ê°ì²´ë¡œ ëª¨ë“  storage ì‘ì—… ì²˜ë¦¬
  - ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥¸ storageë¡œ ë¼ìš°íŒ…

#### 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
- **íŒŒì¼**: `platform/trainers/ultralytics/.env`
- **êµ¬ì¡°**:
  ```bash
  # External Storage (MinIO-Datasets) - for datasets
  EXTERNAL_STORAGE_ENDPOINT=http://localhost:9000
  EXTERNAL_BUCKET_DATASETS=training-datasets
  
  # Internal Storage (MinIO-Results) - for checkpoints
  INTERNAL_STORAGE_ENDPOINT=http://localhost:9002
  INTERNAL_BUCKET_CHECKPOINTS=training-checkpoints
  
  # Legacy fallback
  S3_ENDPOINT=http://localhost:9000
  ```

#### 5. Backend CORS ì„¤ì • ìˆ˜ì •
- **íŒŒì¼**: `platform/backend/.env`
- **ë¬¸ì œ**: JSON ë°°ì—´ í˜•ì‹ì´ comma-separatedë¡œ íŒŒì‹±ë˜ì§€ ì•ŠìŒ
- **ìˆ˜ì •**: 
  ```bash
  # Before
  CORS_ORIGINS=["http://localhost:3000","http://127.0.0.1:3000"]
  
  # After
  CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
  ```

### ê²€ì¦ ê²°ê³¼

#### End-to-End í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ âœ…

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**: YOLOv8n í•™ìŠµ (Job ID 15)
1. âœ… ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ: MinIO-Datasets (9000) â† training-datasets bucket
2. âœ… DICE â†’ YOLO ë³€í™˜: 25 train, 7 val images, 43 classes
3. âœ… í•™ìŠµ ì‹¤í–‰: 2 epochs, 0.015 hours (CPU)
4. âœ… Checkpoint ì—…ë¡œë“œ: MinIO-Results (9002) â† training-checkpoints bucket
5. âœ… MLflow ì—°ë™: run_id 924c7209cf824d70a284b951b7e976ba
6. âœ… Backend callback: ì„±ê³µ

**ë¡œê·¸ í™•ì¸**:
```
Dual Storage initialized:
  External (Datasets): http://localhost:9000 -> training-datasets
  Internal (Results):  http://localhost:9002 -> training-checkpoints

[Dual Storage] Downloading dataset from External Storage
[Dual Storage] Uploading checkpoint to Internal Storage
Checkpoint uploaded to s3://training-checkpoints/checkpoints/15/best.pt
```

**ì‹¤ì œ íŒŒì¼ í™•ì¸**:
```bash
$ docker exec platform-minio-results-tier0 mc ls local/training-checkpoints/checkpoints/15/
[2025-11-14 06:08:23 UTC] 6.0MiB STANDARD best.pt
```

### ê¸°ìˆ ì  ê°œì„ ì 

#### ê°œë°œì ê²½í—˜ ê°œì„ 
- **ì´ì „**: ë‘ ê°œì˜ S3Clientë¥¼ ì§ì ‘ ê´€ë¦¬, endpoint/bucket ì„ íƒ í•„ìš”
- **í˜„ì¬**: ë‹¨ì¼ DualStorageClient, ìë™ ë¼ìš°íŒ…
- **íš¨ê³¼**: ì½”ë“œ ë‹¨ìˆœí™”, ì‹¤ìˆ˜ ë°©ì§€, ëª…í™•í•œ ì˜ë„ í‘œí˜„

#### í™•ì¥ì„±
- ìƒˆë¡œìš´ storage operation ì¶”ê°€ ìš©ì´
- ë‹¤ë¥¸ framework trainerì— ë™ì¼ íŒ¨í„´ ì ìš© ê°€ëŠ¥
- Production í™˜ê²½ì—ì„œë„ ë™ì¼í•˜ê²Œ ì‘ë™ (í™˜ê²½ë³€ìˆ˜ë§Œ ë³€ê²½)

### ë‹¤ìŒ ë‹¨ê³„

- [ ] ì²´í¬ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (Phase 3.3 Dual Storage ì™„ë£Œ)
- [ ] ë³€ê²½ì‚¬í•­ ì»¤ë°‹
- [ ] ë‹¤ë¥¸ framework trainer (timm, huggingface)ì—ë„ DualStorageClient ì ìš©
- [ ] Backend dual_storage.pyì™€ trainer utils.py í†µí•© ê³ ë ¤
- [ ] Production ë°°í¬ ì‹œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • ê°€ì´ë“œ ì‘ì„±

### ê´€ë ¨ ë¬¸ì„œ
- Infrastructure: `platform/infrastructure/docker-compose.tier0.yaml`
- Trainer Utils: `platform/trainers/ultralytics/utils.py`
- Train Script: `platform/trainers/ultralytics/train.py`
- Backend Dual Storage: `platform/backend/app/utils/dual_storage.py`

---

# Conversation Log

ì´ íŒŒì¼ì€ Claude Code ëŒ€í™” ì„¸ì…˜ì˜ íƒ€ì„ë¼ì¸ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
ì„¸ì…˜ì´ ë°”ë€Œì–´ë„ ì´ì „ ë…¼ì˜ ë‚´ìš©ì„ ë¹ ë¥´ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì‚¬ìš© ë°©ë²•**: `/log-session` ëª…ë ¹ì–´ë¡œ í˜„ì¬ ì„¸ì…˜ ë‚´ìš© ì¶”ê°€

---

## [2025-11-07 19:00] ë¡œì»¬ ê°œë°œ ì›Œí¬í”Œë¡œìš° ìµœì í™” - Docker ë¹Œë“œ ì œê±°

### ë…¼ì˜ ì£¼ì œ
- Training ì½”ë“œ ìˆ˜ì • ì‹œ ë§¤ë²ˆ Docker ì´ë¯¸ì§€ ë¹Œë“œ ë¬¸ì œ í•´ê²°
- Frontend + Backend + Training ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ ë°©ë²•
- Frameworkë³„ Training Service ì‹¤í–‰ ë°©ì‹
- ë¡œì»¬ ê°œë°œ í™˜ê²½ ì„¤ì • ë° ìë™í™”

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. 3ë‹¨ê³„ ê°œë°œ ì›Œí¬í”Œë¡œìš° í™•ë¦½ âœ…
- **Tier 1: ë¡œì»¬ ê°œë°œ (subprocess)** - 99% ì‚¬ìš© âš¡âš¡âš¡
  - Backendê°€ Python subprocessë¡œ train.py ì§ì ‘ ì‹¤í–‰
  - Frameworkë³„ ê°€ìƒí™˜ê²½ ì‚¬ìš© (venv-timm, venv-ultralytics, venv-huggingface)
  - ì‹¤í–‰ ì†ë„: 5-30ì´ˆ (Docker ë¹Œë“œ ë¶ˆí•„ìš”)
  - ì‹œê°„ ì ˆì•½: **145ë¶„/ì¼** (10íšŒ ë°˜ë³µ ê¸°ì¤€)

- **Tier 2: K8s í…ŒìŠ¤íŠ¸ (ConfigMap ì£¼ì…)** - ë°°í¬ ì „ ê²€ì¦ âš¡âš¡
  - ì½”ë“œë¥¼ ConfigMapìœ¼ë¡œ ì£¼ì…í•˜ì—¬ K8s Job ì‹¤í–‰
  - ì´ë¯¸ì§€ ì¬ë¹Œë“œ ë¶ˆí•„ìš” (1-3ë¶„ ì†Œìš”)
  - ì‹¤ì œ K8s í™˜ê²½ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

- **Tier 3: Production ë°°í¬** - ìµœì¢… ë‹¨ê³„ë§Œ âš¡
  - Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° ë°°í¬
  - 10-15ë¶„ ì†Œìš”
  - ë°°í¬ ì§ì „ì—ë§Œ ì‹¤í–‰

#### 2. ë¡œì»¬ ê°œë°œ ì¸í”„ë¼ êµ¬ì„± âœ…
**Kind í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì„œë¹„ìŠ¤**:
- MLflow (Port 30500): Experiment tracking, SQLite backend
- MinIO (Port 30900/30901): S3-compatible object storage (R2 ëŒ€ì²´)
- Prometheus (Port 30090): Metrics collection
- Grafana (Port 30030): Monitoring dashboard

**ë°ì´í„° ì˜ì†ì„±**:
- MLflow PVC: 5Gi (SQLite database)
- MinIO PVC: 20Gi (datasets, checkpoints, results)

**R2 â†’ MinIO ì „í™˜ ì´ìœ **:
- ë¡œì»¬ ê°œë°œì— ì¸í„°ë„· ë¶ˆí•„ìš”
- Credentials ê´€ë¦¬ ë¶ˆí•„ìš”
- ë¬´ë£Œ (ë¹„ìš© ì ˆê°)
- S3-compatible API ë™ì¼

#### 3. Frameworkë³„ Training Service êµ¬ì¡° âœ…
**í˜„ì¬ êµ¬í˜„ ìƒíƒœ**:
```
Backend API (Port 8000)
  â†“ HTTP
TrainingServiceClient (framework ê¸°ë°˜ ë¼ìš°íŒ…)
  â†“
api_server.py (Training Service)
  â†“
subprocess.Popen([venv-{framework}/python, train.py])
  â†“
Adapter Pattern (TimmAdapter, UltralyticsAdapter, HuggingFaceAdapter)
```

**Frameworkë³„ ê°€ìƒí™˜ê²½**:
```
mvp/training/
â”œâ”€â”€ venv-timm/          # timm ì „ìš© ì˜ì¡´ì„±
â”œâ”€â”€ venv-ultralytics/   # ultralytics ì „ìš© ì˜ì¡´ì„±
â”œâ”€â”€ venv-huggingface/   # huggingface ì „ìš© ì˜ì¡´ì„±
â””â”€â”€ train.py            # ê³µí†µ Adapter íŒ¨í„´
```

**ë™ì‘ ë°©ì‹**:
1. Backend: `TrainingServiceClient(framework="ultralytics")`
2. Training Service: `venv-ultralytics/python train.py --framework=ultralytics`
3. train.py: `UltralyticsAdapter` ì„ íƒ ë° ì‹¤í–‰

#### 4. ì¼ìƒ ê°œë°œ í”Œë¡œìš° (ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸)

**í™˜ê²½ ì‹œì‘ (ì•„ì¹¨ í•œ ë²ˆ)**:
```powershell
# K8s ì„œë¹„ìŠ¤ ì‹œì‘ (MLflow, MinIO)
.\dev-start.ps1 -SkipBuild  # 2-3ë¶„ ì†Œìš”
```

**ê°œë°œ (3ê°œ í„°ë¯¸ë„)**:
```powershell
# Terminal 1: Backend
cd mvp/backend
.\venv\Scripts\activate
python -m uvicorn app.main:app --reload --port 8000

# Terminal 2: Frontend
cd mvp/frontend
npm run dev

# Terminal 3: ë¸Œë¼ìš°ì €
start http://localhost:3000
```

**Training ì‹¤í–‰**:
1. Frontendì—ì„œ ìì—°ì–´ ì…ë ¥: "ResNet50ìœ¼ë¡œ ê³ ì–‘ì´/ê°œ ë¶„ë¥˜ í•™ìŠµí•´ì¤˜"
2. Backendê°€ TrainingJob ìƒì„±
3. Backendê°€ subprocessë¡œ train.py ì‹¤í–‰ (Frameworkë³„ venv ì‚¬ìš©)
4. MLflowì— ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ê¸°ë¡
5. Frontendì—ì„œ ê²°ê³¼ í™•ì¸

**í™˜ê²½ ì¢…ë£Œ (ì €ë…)**:
```powershell
.\dev-stop.ps1
```

### êµ¬í˜„ ë‚´ìš©

#### ìë™í™” ìŠ¤í¬ë¦½íŠ¸ (6ê°œ ìƒì„±)

**í™˜ê²½ ê´€ë¦¬**:
- `dev-start.ps1`: K8s í™˜ê²½ ìë™ ì‹œì‘
  - Kind í´ëŸ¬ìŠ¤í„° ìƒì„±/ê²€ì¦
  - Docker ì´ë¯¸ì§€ ë¹Œë“œ (ì„ íƒì  `-SkipBuild`)
  - K8s ë¦¬ì†ŒìŠ¤ ë°°í¬ (MLflow, MinIO, Prometheus, Grafana)
  - ì„œë¹„ìŠ¤ Ready ëŒ€ê¸°
  - MinIO ë²„í‚· ìƒì„±

- `dev-stop.ps1`: K8s í™˜ê²½ ì¢…ë£Œ
  - `-DeleteCluster`: ì™„ì „ ì‚­ì œ
  - ê¸°ë³¸: ì¤‘ì§€ (ë°ì´í„° ìœ ì§€)

- `dev-status.ps1`: í™˜ê²½ ìƒíƒœ í™•ì¸
  - í´ëŸ¬ìŠ¤í„° ìƒíƒœ
  - ì„œë¹„ìŠ¤ ìƒíƒœ
  - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
  - `-Watch`: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

**Training ì‹¤í–‰**:
- `dev-train-local.ps1`: ë¡œì»¬ Python ì§ì ‘ ì‹¤í–‰
  - í™˜ê²½ë³€ìˆ˜ ìë™ ì„¤ì • (MLflow, MinIO)
  - subprocess ì‹¤í–‰
  - ê°€ì¥ ë¹ ë¦„ (ì´ˆ ë‹¨ìœ„)

- `dev-train-k8s.ps1`: K8s Job (ConfigMap ì£¼ì…)
  - ì½”ë“œë¥¼ ConfigMapìœ¼ë¡œ ìƒì„±
  - ê¸°ì¡´ Docker ì´ë¯¸ì§€ ì‚¬ìš©
  - ì´ë¯¸ì§€ ì¬ë¹Œë“œ ë¶ˆí•„ìš” (ë¶„ ë‹¨ìœ„)

**K8s ì„¤ì •**:
- `mvp/k8s/minio-config.yaml`: MinIO ë°°í¬
- `mvp/k8s/minio-pvc.yaml`: MinIO ì˜ì† ìŠ¤í† ë¦¬ì§€ (20Gi)
- `mvp/k8s/mlflow-config.yaml`: MLflow ë°°í¬ (ìˆ˜ì •)
- `mvp/k8s/mlflow-pvc.yaml`: MLflow ì˜ì† ìŠ¤í† ë¦¬ì§€ (5Gi)

#### ë¬¸ì„œí™”

**ê°€ì´ë“œ ë¬¸ì„œ** (4ê°œ ìƒì„±):
- `GETTING_STARTED.md`: 5ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°
  - ì‹¤ì „ ì˜ˆì œ (ê³ ì–‘ì´/ê°œ ë¶„ë¥˜)
  - ì¼ë°˜ì ì¸ ê°œë°œ ì‚¬ì´í´
  - íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

- `DEV_WORKFLOW.md`: ê°œë°œ ì›Œí¬í”Œë¡œìš° ìƒì„¸ ê°€ì´ë“œ
  - 3ë‹¨ê³„ ì ‘ê·¼ë²• ì„¤ëª…
  - ìŠ¤í¬ë¦½íŠ¸ ìƒì„¸ ì‚¬ìš©ë²•
  - ì‹¤ì „ íŒ

- `QUICK_DEV_GUIDE.md`: í•œ í˜ì´ì§€ ë¹ ë¥¸ ì°¸ì¡°
  - í•µì‹¬ ëª…ë ¹ì–´ë§Œ
  - ê°œë°œ íš¨ìœ¨ì„± ë¹„êµ
  - TL;DR

- `README.md`: ì—…ë°ì´íŠ¸
  - Getting Started ë§í¬ ì¶”ê°€
  - ê°œë°œ ì›Œí¬í”Œë¡œìš° ì„¹ì…˜ ì¶”ê°€

**ì¸í”„ë¼ ë¬¸ì„œ** (4ê°œ ìƒì„±):
- `mvp/k8s/MINIO_SETUP.md`: MinIO ì‚¬ìš©ë²•
- `mvp/k8s/MLFLOW_SETUP.md`: MLflow ì‚¬ìš©ë²•
- `mvp/k8s/DATA_PERSISTENCE.md`: ë°ì´í„° ì˜ì†ì„± ì„¤ëª…
- `mvp/k8s/DOCKER_VS_K8S.md`: Docker vs K8s ë¹„êµ

**ê¸°ìˆ  ë¬¸ì„œ**:
- `docs/k8s/20251107_development_workflow_setup.md`: ì „ì²´ ì„¤ê³„ ë¬¸ì„œ
  - ë°°ê²½ ë° ì»¨í…ìŠ¤íŠ¸
  - 3ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ìƒì„¸
  - ëŒ€ì•ˆ ë¹„êµ
  - ë¹„ìš© ë¶„ì„
  - ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ

### ìƒ˜í”Œ ë°ì´í„°ì…‹

**sample_dataset (ê³ ì–‘ì´/ê°œ ë¶„ë¥˜)**:
- ìœ„ì¹˜: `mvp/data/datasets/sample_dataset/`
- êµ¬ì¡°:
  ```
  sample_dataset/
  â”œâ”€â”€ train/
  â”‚   â”œâ”€â”€ cats/  (20ì¥)
  â”‚   â””â”€â”€ dogs/  (20ì¥)
  â””â”€â”€ val/
      â”œâ”€â”€ cats/  (5ì¥)
      â””â”€â”€ dogs/  (5ì¥)
  ```
- Format: ImageFolder (image_classification)
- ìš©ë„: ë¡œì»¬ ê°œë°œ í…ŒìŠ¤íŠ¸

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

**dev-train-local.ps1 ìë™ ì„¤ì •**:
```powershell
MLFLOW_TRACKING_URI    = http://localhost:30500
MLFLOW_S3_ENDPOINT_URL = http://localhost:30900
AWS_ACCESS_KEY_ID      = minioadmin
AWS_SECRET_ACCESS_KEY  = minioadmin
MLFLOW_S3_IGNORE_TLS   = true
JOB_ID                 = local-20251107-143000
MODEL_NAME             = yolo11n
FRAMEWORK              = ultralytics
NUM_EPOCHS             = 10
```

### ê°œë°œ íš¨ìœ¨ì„± ë¹„êµ

| ë°©ë²• | ì‹œê°„ | ì‚¬ìš© ì‹œê¸° | ë¹ˆë„ |
|------|------|-----------|------|
| **ë¡œì»¬ ì‹¤í–‰ (subprocess)** | 5-30ì´ˆ | ì¼ìƒ ê°œë°œ | 99% |
| ConfigMap ì£¼ì… (K8s) | 1-3ë¶„ | í†µí•© í…ŒìŠ¤íŠ¸ | ë°°í¬ ì „ 1íšŒ |
| Docker ì´ë¯¸ì§€ ë¹Œë“œ | 10-15ë¶„ | ìµœì¢… ë°°í¬ | ë°°í¬ ì‹œë§Œ |

**ì‹œê°„ ì ˆì•½ ê³„ì‚°**:
```
ê¸°ì¡´ ë°©ì‹: 10íšŒ ë°˜ë³µ Ã— 15ë¶„ = 150ë¶„
ìƒˆ ë°©ì‹: 10íšŒ ë°˜ë³µ Ã— 30ì´ˆ = 5ë¶„
ì ˆì•½: 145ë¶„/ì¼ (ì•½ 2.4ì‹œê°„)
```

### ë‹¤ìŒ ë‹¨ê³„

#### ì¦‰ì‹œ ê°€ëŠ¥ (í…ŒìŠ¤íŠ¸)
- [ ] ë¡œì»¬ í™˜ê²½ ì‹œì‘: `.\dev-start.ps1 -SkipBuild`
- [ ] Backend + Frontend ì‹¤í–‰
- [ ] ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ (Frontend â†’ Backend â†’ Training â†’ MLflow)

#### í–¥í›„ ê°œì„ 
- [ ] Docker Compose ëŒ€ì•ˆ ì œê³µ (Kind ëŒ€ì‹ )
- [ ] Health check ê°œì„  (Training Service)
- [ ] ìë™ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (`dev-all.ps1` - Backend + Frontend ë™ì‹œ ì‹œì‘)

### ê´€ë ¨ ë¬¸ì„œ
- **ê°€ì´ë“œ**: [GETTING_STARTED.md](../GETTING_STARTED.md), [DEV_WORKFLOW.md](../DEV_WORKFLOW.md), [QUICK_DEV_GUIDE.md](../QUICK_DEV_GUIDE.md)
- **ì¸í”„ë¼**: [mvp/k8s/MINIO_SETUP.md](../mvp/k8s/MINIO_SETUP.md), [mvp/k8s/MLFLOW_SETUP.md](../mvp/k8s/MLFLOW_SETUP.md)
- **ì„¤ê³„**: [docs/k8s/20251107_development_workflow_setup.md](../docs/k8s/20251107_development_workflow_setup.md)

### í•µì‹¬ í†µì°°

#### Docker ë¹Œë“œ ì œê±°ì˜ ì„íŒ©íŠ¸
- **ê°œë°œ ì†ë„**: 30ë°° í–¥ìƒ (15ë¶„ â†’ 30ì´ˆ)
- **ê°œë°œì ê²½í—˜**: ì¦‰ê°ì  í”¼ë“œë°± ê°€ëŠ¥
- **ë¹„ìš©**: ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ì ˆì•½

#### Microservice ì•„í‚¤í…ì²˜ ì¼ê´€ì„±
- **ë¡œì»¬ = Production**: ë™ì¼í•œ êµ¬ì¡°
- **Framework ê²©ë¦¬**: ê°€ìƒí™˜ê²½ìœ¼ë¡œ ì˜ì¡´ì„± ì¶©ëŒ ë°©ì§€
- **subprocess**: ê°œë°œ ì‹œ ë¹ ë¦„, Productionì€ K8s Job

#### ë°ì´í„° ì˜ì†ì„±
- **PVC í™œìš©**: Kind ì¬ì‹œì‘í•´ë„ ë°ì´í„° ìœ ì§€
- **MLflow ë©”íƒ€ë°ì´í„°**: SQLite + PVC (5Gi)
- **MinIO ê°ì²´**: PVC (20Gi)

### ê¸°ìˆ  ë…¸íŠ¸

#### ConfigMap ì½”ë“œ ì£¼ì… ë°©ì‹
```yaml
# ConfigMap ìƒì„±
apiVersion: v1
kind: ConfigMap
metadata:
  name: training-code-dev-123
data:
  train.py: |
    # ì‹¤ì œ train.py ë‚´ìš©

# Jobì—ì„œ ë§ˆìš´íŠ¸
volumes:
- name: training-code
  configMap:
    name: training-code-dev-123
volumeMounts:
- name: training-code
  mountPath: /code/train.py
  subPath: train.py
```

#### Frameworkë³„ subprocess ì‹¤í–‰
```python
# api_server.py:99-106
venv_python = f"venv-{request.framework}/Scripts/python.exe"
if os.path.exists(venv_python):
    python_exe = venv_python  # Framework-specific venv
else:
    python_exe = "python"  # Fallback

cmd = [python_exe, "train.py", "--framework", request.framework, ...]
process = subprocess.Popen(cmd)
```

#### Kind í´ëŸ¬ìŠ¤í„° Port Mapping
```yaml
# dev-start.ps1ì—ì„œ ìƒì„±
kind: Cluster
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30500  # MLflow
  - containerPort: 30900  # MinIO API
  - containerPort: 30901  # MinIO Console
  - containerPort: 30090  # Prometheus
  - containerPort: 30030  # Grafana
```

---

## [2025-11-07 14:30] Kubernetes Training ë°©ì‹ FAQ - í•µì‹¬ ì§ˆë¬¸ 4ê°€ì§€ í•´ê²°

### ë…¼ì˜ ì£¼ì œ
- K8s Job ë°©ì‹ì—ì„œ í•™ìŠµ ì¤‘ë‹¨/ì¬ì‹œì‘ ê°€ëŠ¥ì„±
- í”„ë ˆì„ì›Œí¬ë³„ ì„¤ì •(Config) ê´€ë¦¬ ë°©ë²•
- Inference (Single/Batch) êµ¬í˜„ í˜„í™©
- í…ŒìŠ¤íŠ¸ ì „ëµ ë° ì‹¤í–‰ ë°©ë²•

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. Checkpoint Resumeìœ¼ë¡œ í•™ìŠµ ì¬ì‹œì‘ ê°€ëŠ¥ âœ…
- **ì§ˆë¬¸**: K8s Jobì€ pause/resumeì´ ì–´ë µì§€ ì•Šë‚˜?
- **ë‹µë³€**: Checkpoint ê¸°ë°˜ ì¬ì‹œì‘ìœ¼ë¡œ í•´ê²°
- **êµ¬í˜„ ìƒíƒœ**: ì™„ì „ êµ¬í˜„ë¨ (`train.py:83-360`)

**ë³µì›ë˜ëŠ” ìƒíƒœ**:
- Model weights
- Optimizer state
- LR scheduler state
- Current epoch number
- Best validation accuracy

**K8sì—ì„œì˜ ë™ì‘**:
```yaml
# ìë™ ì¬ì‹œì‘ ì„¤ì •
spec:
  backoffLimit: 3
  restartPolicy: OnFailure
  # ëª¨ë“  Jobì„ --resume ëª¨ë“œë¡œ ì‹¤í–‰
  args: ["--checkpoint_path=s3://...", "--resume"]
```

**Scenario**:
- Epoch 10/50 ì§„í–‰ ì¤‘ â†’ Pod ì¢…ë£Œ
- K8s ìë™ ì¬ì‹œì‘
- Epoch 10 checkpoint ë¡œë“œ
- Epoch 11ë¶€í„° ì¬ê°œ

#### 2. Adapter Pattern + Config Schemaë¡œ í”„ë ˆì„ì›Œí¬ë³„ ì„¤ì • âœ…
- **ì§ˆë¬¸**: ëª¨ë¸/í”„ë ˆì„ì›Œí¬ë§ˆë‹¤ ë‹¤ë¥¸ ConfigëŠ” ì–´ë–»ê²Œ?
- **ë‹µë³€**: ê° Adapterê°€ ìì²´ Config Schema ì •ì˜

**TIMM ì˜ˆì‹œ**:
```python
config_schema = {
    "optimizer_type": ["adam", "adamw", "sgd"],
    "scheduler_type": ["cosine", "step", "plateau"],
    "mixup": bool,
    "cutmix": bool,
}

presets = {
    "easy": {"optimizer": "adam", "mixup": False},
    "medium": {"optimizer": "adamw", "mixup": True},
    "advanced": {"optimizer": "adamw", "mixup": True, "cutmix": True},
}
```

**Ultralytics ì˜ˆì‹œ**:
```python
config_schema = {
    "optimizer_type": ["Adam", "AdamW", "SGD"],
    "cos_lr": bool,
    "mosaic": float,  # YOLO-specific
    "mixup": float,
    "copy_paste": float,
}
```

**ì‚¬ìš© ë°©ë²•**:
1. **Preset**: "ë‚œì´ë„ mediumìœ¼ë¡œ" â†’ LLMì´ preset ì ìš©
2. **ì„¸ë¶€ ì„¤ì •**: "AdamW, lr 0.001, mosaic 1.0" â†’ LLMì´ advanced_config ìƒì„±
3. **DB ì €ì¥**: `training_jobs.advanced_config` (JSONB)

#### 3. Inference êµ¬í˜„ í˜„í™©
- **Single Inference**: âœ… ì™„ì „ êµ¬í˜„
- **Batch Inference (TestRun)**: âœ… êµ¬í˜„
- **Production Batch**: âš ï¸ í–¥í›„ êµ¬í˜„

**Single Inference API**:
```python
# POST /api/v1/test/inference/single
result = adapter.infer_single("image.jpg")
# â†’ {"predicted_label": "cat", "confidence": 0.92, "top5_predictions": [...]}
```

**ëª¨ë“  Adapter êµ¬í˜„ ì™„ë£Œ**:
- `TimmAdapter.infer_single()`: lines 1040-1118
- `UltralyticsAdapter.infer_single()`: lines 2568+
- `TransformersAdapter.infer_single()`: lines 594, 820

**Batch Inference (TestRun)**:
```python
# POST /api/v1/test/runs
test_run = create_test_run(
    job_id=123,
    test_dataset_path="s3://bucket/test_dataset/"
)
# Background taskë¡œ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬
```

#### 4. 4ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì „ëµ âœ…
- **Level 1: Unit Tests** (`mvp/backend/tests/unit/`)
- **Level 2: Integration Tests** (`mvp/backend/tests/integration/`)
- **Level 3: Subprocess E2E** (`mvp/training/test_train_subprocess_e2e.py`)
- **Level 4: K8s Job Tests** (`mvp/backend/tests/k8s/`)

**í…ŒìŠ¤íŠ¸ ì‹¤í–‰**:
```bash
# Level 1: Unit
cd mvp/backend && pytest tests/unit/ -v

# Level 2: Integration
pytest tests/integration/ -v

# Level 3: E2E
cd mvp/training && python test_train_subprocess_e2e.py

# Level 4: K8s
kind create cluster --name training-test
kind load docker-image vision-platform/trainer-timm:latest
cd mvp/backend && pytest tests/k8s/ -v
```

### êµ¬í˜„ ë‚´ìš©

#### ì¢…í•© FAQ ë¬¸ì„œ
**íŒŒì¼**: `docs/k8s/K8S_TRAINING_FAQ.md` (ìƒˆë¡œ ìƒì„±)

**í¬í•¨ ë‚´ìš©** (ì „ì²´ 1000+ lines):
1. **í•™ìŠµ ì¤‘ë‹¨/ì¬ì‹œì‘** (360 lines)
   - Checkpoint resume êµ¬í˜„ ì„¸ë¶€ì‚¬í•­
   - K8s Job ìë™ ì¬ì‹œì‘ ë™ì‘
   - Multi-stage training (24ì‹œê°„+ í•™ìŠµ)
   - Checkpoint ì €ì¥ ì£¼ê¸° ì„¤ì •
   - K8s Job vs ì¼ë°˜ ì„œë²„ ë¹„êµ

2. **í”„ë ˆì„ì›Œí¬ë³„ Config** (400 lines)
   - Preset ì‹œìŠ¤í…œ (easy/medium/advanced)
   - ì„¸ë¶€ ì„¤ì • ë°©ì‹
   - TIMM/Ultralytics Config Schema ì˜ˆì‹œ
   - Config ì „ë‹¬ Flow
   - DB ì €ì¥ ë° ë¡œë”©

3. **Inference êµ¬í˜„** (300 lines)
   - Single inference API
   - Batch inference (TestRun)
   - Adapterë³„ êµ¬í˜„ ìƒì„¸
   - Frontend ì‚¬ìš© ì˜ˆì‹œ
   - Production batch ì œì•ˆ

4. **í…ŒìŠ¤íŠ¸ ë°©ë²•** (400 lines)
   - 4ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ê³„ì¸µ
   - í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
   - K8s í´ëŸ¬ìŠ¤í„° ì…‹ì—…
   - CI/CD í†µí•© ì˜ˆì‹œ
   - Coverage ëª©í‘œ

### ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

#### Checkpoint Resume íë¦„
```python
# 1. ì²˜ìŒ ì‹œì‘ (checkpoint ì—†ìŒ)
python train.py --job_id=123 --num_epochs=50

# 2. Epoch 10ì—ì„œ ì¤‘ë‹¨

# 3. ì¬ì‹œì‘ (ìë™ìœ¼ë¡œ epoch 10ë¶€í„°)
python train.py --job_id=123 \
    --checkpoint_path=s3://bucket/job_123/weights/last.pt \
    --resume \
    --num_epochs=50
```

#### Config Schema êµ¬ì¡°
```python
# Adapterë³„ schema ì •ì˜
class TimmAdapter:
    def get_config_schema(self):
        return [
            ConfigField("optimizer_type", type="select", options=[...]),
            ConfigField("scheduler_type", type="select", options=[...]),
            ConfigField("mixup", type="bool", default=False),
        ]

    def get_preset_config(self, preset: str):
        return self.presets[preset]  # easy/medium/advanced
```

#### Inference Result Schema
```python
class InferenceResult:
    image_path: str
    predicted_label: str
    confidence: float
    top5_predictions: List[Dict]
    inference_time_ms: float
    preprocessing_time_ms: float
    postprocessing_time_ms: float
```

### í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€

**êµ¬í˜„ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤**:
- `test_adapter_imports.py` - Adapter ë¡œë”©
- `test_advanced_config.py` - Config ê²€ì¦
- `test_inference_api.py` - Inference ì—”ë“œí¬ì¸íŠ¸
- `test_checkpoint_inference.py` - Checkpoint ë¡œë”©
- `test_train_subprocess_e2e.py` - ì „ì²´ íŒŒì´í”„ë¼ì¸
- `test_inference_pretrained.py` - Pretrained ëª¨ë¸
- `test_training_config.py` - ì„¤ì • ê²€ì¦
- `test_validation_metrics_persistence.py` - ë©”íŠ¸ë¦­ ì €ì¥

### ìš”ì•½ í‘œ

| ì§ˆë¬¸ | êµ¬í˜„ ìƒíƒœ | í•µì‹¬ íŒŒì¼ |
|------|-----------|----------|
| **í•™ìŠµ ì¤‘ë‹¨/ì¬ì‹œì‘** | âœ… ì™„ì „ êµ¬í˜„ | `train.py:83-360`, `base.py:1242-1287` |
| **í”„ë ˆì„ì›Œí¬ë³„ Config** | âœ… ì™„ì „ êµ¬í˜„ | `timm_adapter.py:14-326`, `ultralytics_adapter.py:39-250` |
| **Inference** | âœ… Single ì™„ì „ êµ¬í˜„<br>âœ… Batch (TestRun)<br>âš ï¸ Production Batch í–¥í›„ | `timm_adapter.py:1040-1118`, `test_inference.py` |
| **í…ŒìŠ¤íŠ¸** | âœ… ì™„ì „ êµ¬í˜„ | `tests/unit/`, `tests/integration/`, E2E scripts |

### ë‹¤ìŒ ë‹¨ê³„

#### ì¦‰ì‹œ ê°€ëŠ¥ (í…ŒìŠ¤íŠ¸)
- [ ] ë¡œì»¬ K8s í´ëŸ¬ìŠ¤í„°ë¡œ í…ŒìŠ¤íŠ¸ (Kind + QUICKSTART.md)
- [ ] Checkpoint resume ë™ì‘ ê²€ì¦
- [ ] Inference API ì‹¤ì œ í˜¸ì¶œ í…ŒìŠ¤íŠ¸

#### í–¥í›„ ê°œì„ 
- [ ] Production Batch Inference API (K8s Job ê¸°ë°˜)
- [ ] WebSocket í†µí•©ìœ¼ë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°•í™”
- [ ] Goal #2: LLM Agent ê³ ë„í™”

### ê´€ë ¨ ë¬¸ì„œ
- **FAQ ë¬¸ì„œ**: [docs/k8s/K8S_TRAINING_FAQ.md](../k8s/K8S_TRAINING_FAQ.md) (ì‹ ê·œ)
- **K8s ë§ˆì´ê·¸ë ˆì´ì…˜**: [docs/k8s/20251106_kubernetes_job_migration_plan.md](../k8s/20251106_kubernetes_job_migration_plan.md)
- **ëª¨ë‹ˆí„°ë§ í†µí•©**: [mvp/k8s/MONITORING_INTEGRATION.md](../../mvp/k8s/MONITORING_INTEGRATION.md)
- **K8s QUICKSTART**: [mvp/k8s/QUICKSTART.md](../../mvp/k8s/QUICKSTART.md)

### í•µì‹¬ í†µì°°

#### K8s Jobì˜ ì œì•½ì„ Checkpointë¡œ ê·¹ë³µ
- K8s Jobì€ pause ë¶ˆê°€ â†’ Checkpoint resumeìœ¼ë¡œ ë™ì¼ íš¨ê³¼
- Pod ì¬ì‹œì‘ = ìƒˆ Job ìƒì„± + `--resume` í”Œë˜ê·¸
- R2 Storage ë•ë¶„ì— checkpoint ì˜ì†ì„± ë³´ì¥

#### Adapter Patternì˜ ìœ ì—°ì„±
- Frameworkë§ˆë‹¤ ì™„ì „íˆ ë‹¤ë¥¸ config í•„ìš”
- ê° Adapterê°€ ìì²´ schema ì •ì˜
- Presetìœ¼ë¡œ ê°„í¸í•¨ + ì„¸ë¶€ ì„¤ì •ìœ¼ë¡œ ìœ ì—°ì„±

#### í…ŒìŠ¤íŠ¸ì˜ ê³„ì¸µí™”
- Unit â†’ Integration â†’ E2E â†’ K8s
- ê° ë ˆë²¨ì´ ë‹¤ë¥¸ ë¶€ë¶„ì„ ê²€ì¦
- Production-ready ë³´ì¥

### ê¸°ìˆ  ë…¸íŠ¸

#### Checkpoint ì €ì¥ ìœ„ì¹˜
```
ë¡œì»¬: output/job_{job_id}/weights/best.pt, last.pt
R2: checkpoints/projects/{project_id}/jobs/{job_id}/best.pt, last.pt
```

#### Config ì „ë‹¬ ì²´ì¸
```
ì‚¬ìš©ì ìì—°ì–´
  â†’ LLM Parser
  â†’ TrainingIntent.advanced_config
  â†’ DB (training_jobs.advanced_config JSONB)
  â†’ train.py --job_id
  â†’ load_advanced_config_from_db()
  â†’ Adapter(advanced_config)
  â†’ Framework-specific êµ¬í˜„
```

#### 4ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œê°„
- Level 1 (Unit): ~30ì´ˆ
- Level 2 (Integration): ~2ë¶„
- Level 3 (E2E): ~5ë¶„ (tiny dataset)
- Level 4 (K8s): ~10ë¶„ (í´ëŸ¬ìŠ¤í„° ì…‹ì—… í¬í•¨)

---

## [2025-11-05 14:45] Checkpoint ê´€ë¦¬ ì •ì±… ë° R2 ì—…ë¡œë“œ ì „ëµ ìˆ˜ë¦½

### ë…¼ì˜ ì£¼ì œ
- ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì¤‘ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ì •ì±… ëˆ„ë½ ë°œê²¬
- R2 ì—…ë¡œë“œ ì‹œì  ê²°ì • (ë§¤ epoch vs í•™ìŠµ ì™„ë£Œ ì‹œ)
- í•™ìŠµ ì¤‘ë‹¨ ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬ (Ctrl+C, Error, ì¡°ê¸° ì¢…ë£Œ)
- UI ë©”íŠ¸ë¦­ í…Œì´ë¸”ì˜ ì²´í¬í¬ì¸íŠ¸ í‘œì‹œ ë™ê¸°í™”

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. í˜„ì¬ ìƒíƒœ í™•ì¸
- **ë¡œì»¬ ì €ì¥**:
  - âœ… YOLO `save_period = -1` (best.pt + last.ptë§Œ ì €ì¥)
  - âœ… ì¤‘ê°„ epoch checkpoint ì €ì¥ ì•ˆí•¨
  - âœ… íš¨ìœ¨ì ì¸ ë¡œì»¬ ê´€ë¦¬

- **R2 ì—…ë¡œë“œ**:
  - âŒ `upload_checkpoint()` í•¨ìˆ˜ëŠ” êµ¬í˜„ë˜ì–´ ìˆìŒ
  - âŒ í•˜ì§€ë§Œ ì‹¤ì œë¡œ í˜¸ì¶œë˜ì§€ ì•ŠìŒ!
  - âŒ ì²´í¬í¬ì¸íŠ¸ê°€ ë¡œì»¬ì—ë§Œ ë‚¨ìŒ

- **ë¬¸ì œì **:
  - ì‹œê°„ì´ ì§€ë‚œ í›„ ì¶”ë¡  ì‚¬ìš© ë¶ˆê°€ (ë¡œì»¬ íŒŒì¼ ì‚­ì œ ê°€ëŠ¥)
  - Exception ì²˜ë¦¬ì—ì„œ checkpoint_dir ëˆ„ë½
  - UIëŠ” ë¡œì»¬ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œ (R2 ì—…ë¡œë“œ ìƒíƒœ ì•„ë‹˜)

#### 2. R2 ì—…ë¡œë“œ ì‹œì  ê²°ì • (Option 1 ì„ íƒ âœ…)

**ê³ ë ¤í•œ ì˜µì…˜ë“¤**:

| ì˜µì…˜ | ì¥ì  | ë‹¨ì  | ê²°ì • |
|------|------|------|------|
| ë§¤ epoch | ìµœëŒ€ ì•ˆì „ì„± | ë†’ì€ ë¹„ìš©, ëŠë¦° í•™ìŠµ | âŒ |
| N epochë§ˆë‹¤ | ê· í˜• | ì—¬ì „íˆ ì¤‘ë³µ ì—…ë¡œë“œ | âŒ |
| ê°œì„  ì‹œë§ˆë‹¤ | ì˜ë¯¸ìˆëŠ” ì—…ë¡œë“œ | ì´ˆë°˜ = ë§¤ epoch | âŒ |
| **ì™„ë£Œ ì‹œ 1íšŒ** | ê°„ë‹¨, ë¹ ë¦„, ì €ë ´ | ì¤‘ê°„ ë°±ì—… ì—†ìŒ | âœ… |

**ì„ íƒ ì´ìœ **:
- ëŒ€ë¶€ë¶„ì˜ í•™ìŠµì€ ì •ìƒ ì™„ë£Œë¨
- ì¤‘ë‹¨ì€ rare case
- 2ê°œ íŒŒì¼ë§Œ ì—…ë¡œë“œ (best.pt + last.pt)
- í•™ìŠµ ì„±ëŠ¥ ì˜í–¥ 0
- ë¹„ìš© íš¨ìœ¨ì  (~$0.60/ì›” for 1000 jobs)

#### 3. í•™ìŠµ ì¤‘ë‹¨ ì²˜ë¦¬ (í•µì‹¬ ê°œì„  ì‚¬í•­)

**ë¬¸ì œ ë°œê²¬**:
```python
# í˜„ì¬ ì½”ë“œ
try:
    results = self.model.train(**train_args)
    callbacks.on_train_end(checkpoint_dir=checkpoint_dir)  # âœ…

except KeyboardInterrupt:
    callbacks.on_train_end()  # âŒ checkpoint_dir ì—†ìŒ!

except Exception as e:
    callbacks.on_train_end()  # âŒ checkpoint_dir ì—†ìŒ!
```

**í•´ê²° ë°©ì•ˆ**:
```python
# checkpoint_dirë¥¼ try ë¸”ë¡ ë°–ì—ì„œ ì •ì˜
checkpoint_dir = os.path.join(self.output_dir, f"job_{self.job_id}", "weights")

try:
    results = self.model.train(**train_args)
except KeyboardInterrupt:
    print("[YOLO] Uploading checkpoints before exit...")
    callbacks.on_train_end(checkpoint_dir=checkpoint_dir)  # âœ…
    raise
except Exception as e:
    print("[YOLO] Attempting to upload despite error...")
    callbacks.on_train_end(checkpoint_dir=checkpoint_dir)  # âœ…
    raise

# ì •ìƒ ì™„ë£Œ
callbacks.on_train_end(checkpoint_dir=checkpoint_dir)
```

**ì¤‘ë‹¨ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì²˜ë¦¬**:
- User ì¤‘ë‹¨ (Ctrl+C): âœ… í˜„ì¬ê¹Œì§€ best/last ì—…ë¡œë“œ
- ì—ëŸ¬ ë°œìƒ: âœ… ì—…ë¡œë“œ ì‹œë„ (íŒŒì¼ ìˆìœ¼ë©´)
- ì¡°ê¸° ì¢…ë£Œ: âœ… ì •ìƒ ì™„ë£Œë¡œ ì²˜ë¦¬
- ì´ˆë°˜ ì¤‘ë‹¨: âœ… íŒŒì¼ ì—†ìœ¼ë©´ warningë§Œ (non-blocking)

#### 4. DB ì²´í¬í¬ì¸íŠ¸ ì¶”ì  ì „ëµ

**í˜„ì¬ ë¬¸ì œ**:
```python
# ultralytics_adapter.py:1590-1602
# í•™ìŠµ ì¤‘ ë§¤ epochë§ˆë‹¤ checkpoint_path ì €ì¥ (ë¡œì»¬ ê²½ë¡œ)
if os.path.exists(best_weights):
    checkpoint_path = best_weights  # ë¬¸ì œ: ë¡œì»¬ ê²½ë¡œ!
```

**ìƒˆë¡œìš´ ì „ëµ**:
```python
# í•™ìŠµ ì¤‘
checkpoint_path = None  # DBì— ì €ì¥ ì•ˆí•¨

# on_train_end()ì—ì„œë§Œ
1. R2ì— ì—…ë¡œë“œ
2. Best epoch ì°¾ê¸° (highest primary_metric_value)
3. Last epoch ì°¾ê¸° (max epoch)
4. DB UPDATE: í•´ë‹¹ epochë“¤ì˜ checkpoint_path = 'r2://...'
```

**ê²°ê³¼**:
- í•™ìŠµ ì¤‘: ëª¨ë“  epoch checkpoint_path = NULL
- í•™ìŠµ ì™„ë£Œ/ì¤‘ë‹¨: Best & Last epochë§Œ checkpoint_path = 'r2://...'
- UI: R2 ì—…ë¡œë“œëœ checkpointë§Œ ì²´í¬ë§ˆí¬ í‘œì‹œ

### êµ¬í˜„ ë‚´ìš©

#### 1. on_train_end() í™•ì¥
**íŒŒì¼**: `platform_sdk/base.py:1724`

```python
def on_train_end(self, final_metrics=None, checkpoint_dir=None):
    # 1. Upload best.pt to R2
    if checkpoint_dir and os.path.exists(best_pt):
        success = upload_checkpoint(best_pt, job_id, 'best.pt', project_id)
        if success:
            best_epoch = _find_best_epoch()
            r2_path = f'r2://.../{project_id}/jobs/{job_id}/best.pt'
            uploaded_checkpoints[best_epoch] = r2_path

    # 2. Upload last.pt to R2
    if checkpoint_dir and os.path.exists(last_pt):
        success = upload_checkpoint(last_pt, job_id, 'last.pt', project_id)
        if success:
            last_epoch = _find_last_epoch()
            r2_path = f'r2://.../{project_id}/jobs/{job_id}/last.pt'
            uploaded_checkpoints[last_epoch] = r2_path

    # 3. Update DB with R2 paths
    _update_checkpoint_paths(uploaded_checkpoints)

    # 4. End MLflow
    mlflow.end_run()
```

**ìƒˆë¡œìš´ í—¬í¼ ë©”ì„œë“œ**:
- `_find_best_epoch()`: DBì—ì„œ highest primary_metric_value ì°¾ê¸°
- `_find_last_epoch()`: DBì—ì„œ max(epoch) ì°¾ê¸°
- `_update_checkpoint_paths()`: validation_results í…Œì´ë¸” UPDATE

#### 2. Exception í•¸ë“¤ë§ ìˆ˜ì •
**íŒŒì¼**: `adapters/ultralytics_adapter.py:1967-1999`

```python
# Line 1995: checkpoint_dir ë¯¸ë¦¬ ì •ì˜
checkpoint_dir = os.path.join(self.output_dir, f"job_{self.job_id}", "weights")

try:
    results = self.model.train(**train_args)
except KeyboardInterrupt:
    callbacks.on_train_end(checkpoint_dir=checkpoint_dir)  # âœ…
    raise
except Exception as e:
    callbacks.on_train_end(checkpoint_dir=checkpoint_dir)  # âœ…
    raise

callbacks.on_train_end(checkpoint_dir=checkpoint_dir)
```

#### 3. í•™ìŠµ ì¤‘ checkpoint_path ì œê±°
**íŒŒì¼**: `adapters/ultralytics_adapter.py:1590-1602`

```python
# ê¸°ì¡´ ì½”ë“œ ì œê±° (ë¡œì»¬ ê²½ë¡œ í• ë‹¹)
# checkpoint_path = best_weights if os.path.exists(best_weights) else last_weights

# ìƒˆ ì½”ë“œ (ê°„ë‹¨!)
checkpoint_path = None  # R2 ì—…ë¡œë“œ í›„ì—ë§Œ ì„¤ì •ë¨
```

#### 4. upload_checkpoint() ë°˜í™˜ê°’ ì¶”ê°€
**íŒŒì¼**: `platform_sdk/storage.py:527`

```python
def upload_checkpoint(...) -> bool:  # ë°˜í™˜ íƒ€ì… ì¶”ê°€
    try:
        # ... ì—…ë¡œë“œ ë¡œì§ ...
        return True  # ì„±ê³µ
    except Exception as e:
        print(f"[R2 WARNING] Upload failed: {e}")
        return False  # ì‹¤íŒ¨
```

### ë¹„ìš© ë¶„ì„

**Storage (Cloudflare R2)**:
- íŒŒì¼ë‹¹: ~20MB (YOLO11s average)
- ì¡ë‹¹: 40MB (best.pt + last.pt)
- 1000 jobs: 40GB
- ë¹„ìš©: $0.015/GB/month
- **ì›” ë¹„ìš©: $0.60** (affordable!)

**ë¹„êµ (ëŒ€ì•ˆë“¤)**:
- ë§¤ epoch (100 epochs): 2GB/job â†’ $30/month (50ë°° ë¹„ìŒˆ!)
- 10 epochë§ˆë‹¤: 200MB/job â†’ $3/month (5ë°° ë¹„ìŒˆ)
- ì™„ë£Œ ì‹œ 1íšŒ: 40MB/job â†’ $0.60/month âœ…

**Upload ë¹„ìš©**:
- PUT operations: Free (10M requests/month)
- 2 uploads/job: ë¬´ì‹œ ê°€ëŠ¥

### íƒ€ì„ë¼ì¸ ë™ì‘

**100 epoch í•™ìŠµ ì˜ˆì‹œ**:
```
Epoch 1-99:
  - DB: checkpoint_path = NULL for all epochs
  - UI: No checkmarks

Epoch 100 (ì™„ë£Œ):
  - Upload best.pt (assume epoch 85 was best)
  - Upload last.pt (epoch 100)
  - DB UPDATE:
    - epoch 85: checkpoint_path = 'r2://...best.pt'
    - epoch 100: checkpoint_path = 'r2://...last.pt'
  - UI: Checkmarks on epochs 85, 100 only
```

**Epoch 20 ì¤‘ë‹¨ ì˜ˆì‹œ**:
```
Epoch 1-19: No uploads
Epoch 20: User presses Ctrl+C
  - KeyboardInterrupt caught
  - Upload best.pt (assume epoch 18)
  - Upload last.pt (epoch 20)
  - DB UPDATE: epochs 18, 20 get R2 paths
  - UI: 2 checkmarks
```

### ë¬¸ì„œí™”

**ìƒì„±ëœ ë¬¸ì„œ**: `docs/training/20251105_checkpoint_management_and_r2_upload_policy.md`

**í¬í•¨ ë‚´ìš©**:
- Background & context (ë¬¸ì œ ë°œê²¬ ê³¼ì •)
- Current state (ì½”ë“œ ë¶„ì„ ê²°ê³¼)
- Proposed solution (ì„ íƒí•œ ì •ì±…)
- Implementation plan (4 phases)
- Technical details (R2 ê²½ë¡œ, DB ìŠ¤í‚¤ë§ˆ, ì˜ˆì‹œ)
- Alternatives considered (4ê°€ì§€ ì˜µì…˜ ë¹„êµ)
- Cost analysis (storage & operations)
- Migration path (ê¸°ì¡´ job ì²˜ë¦¬)
- References (ê´€ë ¨ íŒŒì¼ & ë¬¸ì„œ)

### ë‹¤ìŒ ë‹¨ê³„

#### Immediate (êµ¬í˜„ í•„ìš”)
- [ ] `on_train_end()` êµ¬í˜„ (upload + DB update)
- [ ] Exception handling ìˆ˜ì • (checkpoint_dir ì „ë‹¬)
- [ ] í•™ìŠµ ì¤‘ checkpoint_path í• ë‹¹ ì œê±°
- [ ] `upload_checkpoint()` ë°˜í™˜ê°’ ìˆ˜ì •
- [ ] í…ŒìŠ¤íŠ¸ (ì •ìƒ ì™„ë£Œ, ì¤‘ë‹¨, ì—ëŸ¬)

#### Future Enhancements (P1-P3)
- [ ] Checkpoint download API (inferenceìš©)
- [ ] Lifecycle policy (30ì¼ í›„ ìë™ ì‚­ì œ)
- [ ] Checkpoint browser UI
- [ ] Resume training from R2 checkpoint

### ê´€ë ¨ ë¬¸ì„œ
- **ì„¤ê³„ ë¬¸ì„œ**: [docs/training/20251105_checkpoint_management_and_r2_upload_policy.md](../training/20251105_checkpoint_management_and_r2_upload_policy.md)
- **ì´ì „ ì„¸ì…˜**: [Project-Centric Checkpoint Storage](../CONVERSATION_LOG.md#2025-11-04-2130-project-centric-checkpoint-storage-êµ¬í˜„) (2025-11-04)
- **Validation ì´ìŠˆ**: [YOLO Validation Metrics](../CONVERSATION_LOG.md#2025-11-05-1415-yolo-validation-metrics-ì´ìŠˆ-ì¡°ì‚¬-ë°-stratified-split-êµ¬í˜„) (2025-11-05)

### í•µì‹¬ í†µì°° (Key Insights)

#### Cost-Benefit Analysis
- **Best + Last only**: ì¶©ë¶„í•¨ (ì¶”ë¡  + ì¬í•™ìŠµ)
- **ë§¤ epoch ì €ì¥**: ë¶ˆí•„ìš” (50ë°° ë¹„ìš©, ì„±ëŠ¥ ì €í•˜)
- **ì¤‘ë‹¨ ì²˜ë¦¬**: í•„ìˆ˜ (partial resultsë„ ê°€ì¹˜ìˆìŒ)

#### Design Principles
1. **Simplicity over Safety**: MVPëŠ” ê°„ë‹¨í•¨ ìš°ì„ 
2. **Cost-Effective**: ë¹„ìš© ìµœì†Œí™” ($0.60/month)
3. **Non-Blocking**: ì—…ë¡œë“œ ì‹¤íŒ¨í•´ë„ í•™ìŠµ ê³„ì†
4. **User-Friendly**: UIëŠ” ì‹¤ì œ R2 ìƒíƒœ ë°˜ì˜

#### Exception Handling Philosophy
```
"Try to save something rather than save nothing"
- ì¤‘ë‹¨ë˜ì–´ë„ best/last checkpoint ë³´ì¡´
- ì—ëŸ¬ ë°œìƒí•´ë„ ì—…ë¡œë“œ ì‹œë„
- ì‹¤íŒ¨í•´ë„ warningë§Œ (non-critical)
```

### ê¸°ìˆ  ë…¸íŠ¸

#### R2 Path Convention
```
With project_id:
  r2://vision-platform-prod/checkpoints/projects/{project_id}/jobs/{job_id}/best.pt
  r2://vision-platform-prod/checkpoints/projects/{project_id}/jobs/{job_id}/last.pt

Without project_id (test jobs):
  r2://vision-platform-prod/checkpoints/test-jobs/job_{job_id}/best.pt
  r2://vision-platform-prod/checkpoints/test-jobs/job_{job_id}/last.pt
```

#### Database Lifecycle
```sql
-- During training
validation_results.checkpoint_path = NULL

-- After upload (only for best & last epochs)
UPDATE validation_results
SET checkpoint_path = 'r2://...'
WHERE job_id = ? AND epoch IN (best_epoch, last_epoch)
```

#### Frontend Logic
```tsx
// Show checkmark only if R2 path exists
{metric.checkpoint_path?.startsWith('r2://') ? (
  <CheckCircle2 className="text-green-600" />
) : (
  <XCircle className="text-gray-300" />
)}
```

---

## [2025-11-05 14:15] YOLO Validation Metrics ì´ìŠˆ ì¡°ì‚¬ ë° Stratified Split êµ¬í˜„

### ë…¼ì˜ ì£¼ì œ
- YOLO í•™ìŠµ ì¤‘ validation metricsê°€ í•­ìƒ 0ì¸ ë¬¸ì œ ë””ë²„ê¹…
- ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ë¶„í¬ ë¶ˆê· í˜• ë¬¸ì œ ë°œê²¬
- PyTorch InferenceMode ì œì•½ì‚¬í•­ ë°œê²¬
- Stratified split ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. Validation Metrics = 0 ë¬¸ì œ (CANNOT FIX)
- **ì¦ìƒ**:
  - Training lossëŠ” ì •ìƒ ê°ì†Œ
  - Validation metrics (mAP, precision, recall) í•­ìƒ 0.0
  - Confusion matrix ì™„ì „íˆ ë¹„ì–´ìˆìŒ (sum = 0.0)

- **Root Cause 1**: ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ë¶„í¬ ë¶ˆê· í˜•
  - COCO32 (32 images, 43 classes): 9ê°œ í´ë˜ìŠ¤ê°€ validation setì—ë§Œ ì¡´ì¬
  - ëª¨ë¸ì´ í•´ë‹¹ í´ë˜ìŠ¤ë¥¼ í•œ ë²ˆë„ í•™ìŠµí•˜ì§€ ëª»í•¨
  - **í•´ê²°**: Stratified split êµ¬í˜„ âœ…

- **Root Cause 2**: PyTorch InferenceMode ì œì•½
  - Ultralyticsê°€ `torch.inference_mode()` ì‚¬ìš© (not `torch.no_grad()`)
  - InferenceModeëŠ” í…ì„œë¥¼ irreversibly ë³€í™˜
  - Manual validation í›„ `requires_grad` ë³µì› ë¶ˆê°€ëŠ¥
  - RuntimeError: "Setting requires_grad=True on inference tensor outside InferenceMode is not allowed"
  - **ê²°ë¡ **: ê·¼ë³¸ì  PyTorch ì„¤ê³„ ì œì•½, í•´ê²° ë¶ˆê°€ âŒ

- **Root Cause 3**: Ultralytics Callback íƒ€ì´ë°
  - `on_fit_epoch_end` ì‹œì ì— `validator.batch = None`
  - `validator.pred = None` (ì˜ˆì¸¡ê°’ ì—†ìŒ)
  - Validationì´ ì‹¤í–‰ë˜ì§€ë§Œ callbackì—ì„œ ë°ì´í„° ì ‘ê·¼ ë¶ˆê°€

#### 2. Stratified Split êµ¬í˜„ (âœ… SOLVED)
- **ë°°ê²½**:
  - Random splitì€ ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë°œìƒ
  - ì˜ˆ: 32 images, 43 classes â†’ 0.74 images/class í‰ê· 
  - 9ê°œ í´ë˜ìŠ¤ê°€ validationì—ë§Œ ì¡´ì¬ (trainì— 0ê°œ)

- **ì•Œê³ ë¦¬ì¦˜** (`dice_to_yolo.py:136-212`):
  ```python
  1. Build image-to-classes mapping
  2. For rare classes (1 image): â†’ train set (ìš°ì„ ìˆœìœ„)
  3. For classes with 2+ images: â†’ both train & val
  4. Remaining images â†’ 80/20 ratio
  5. Verify: no validation-only classes
  ```

- **ê²°ê³¼**:
  - Val-only classes: 9 â†’ 0 âœ…
  - ëª¨ë“  validation í´ë˜ìŠ¤ê°€ training setì— ì¡´ì¬
  - COCO32, COCO128 ëª¨ë‘ ê²€ì¦ ì™„ë£Œ

#### 3. Train-Mode Validation í…ŒìŠ¤íŠ¸ (ë¶€ë¶„ ì„±ê³µ)
- **ì‹œë„**: Training mode + `torch.no_grad()` ë°©ì‹
  ```python
  with torch.no_grad():
      preds = model(val_batch['img'])
  optimizer.zero_grad()
  ```

- **ì—ëŸ¬**: `RuntimeError: expected scalar type Byte but found Float`
  - ì›ì¸: Validation batch imagesê°€ uint8 (0-255)
  - ëª¨ë¸ì€ float32 (0.0-1.0) ê¸°ëŒ€
  - í•´ê²° ë°©ë²•: `imgs = batch['img'].float() / 255.0`

- **ê²°ë¡ **: Train-mode validation ê°€ëŠ¥í•˜ì§€ë§Œ ì¶”ê°€ êµ¬í˜„ í•„ìš”
  - ë°ì´í„° íƒ€ì… ë³€í™˜
  - Metric ê³„ì‚° ë¡œì§ (mAP, confusion matrix ë“±)
  - ì˜ˆìƒ ì‘ì—…: 1-2ì¼

#### 4. Post-Training Validation (ê¶Œì¥ Workaround)
- **ë°©ì‹**: í•™ìŠµ ì™„ë£Œ í›„ ë³„ë„ validation ì‹¤í–‰
  ```python
  results = model.train(...)
  val_metrics = model.val(data=data_yaml, split='val')
  ```

- **ì¥ì **:
  - ê°„ë‹¨, ì•ˆì •ì 
  - Full metrics ì œê³µ
  - Training ê°„ì„­ ì—†ìŒ

- **ë‹¨ì **:
  - Per-epoch ëª¨ë‹ˆí„°ë§ ë¶ˆê°€
  - ìµœì¢… ë©”íŠ¸ë¦­ë§Œ í™•ì¸ ê°€ëŠ¥

### êµ¬í˜„ ë‚´ìš©

#### Stratified Split Implementation
**`mvp/training/converters/dice_to_yolo.py:136-212`**:
```python
# 1. Image-to-classes mapping
image_classes = {}
for image in images:
    classes_in_image = set(ann['category_id'] for ann in annotations)
    image_classes[image_id] = classes_in_image

# 2. Class-to-images mapping
class_to_images = defaultdict(list)
for image in images:
    for cls in image_classes[image_id]:
        class_to_images[cls].append(image)

# 3. Stratified allocation
for cls, cls_images in sorted(class_to_images.items(), key=lambda x: len(x[1])):
    if len(cls_images) == 1:
        train_images.append(cls_images[0])  # Rare class â†’ train
    elif len(cls_images) >= 2:
        train_images.append(cls_images[0])  # Both splits
        val_images.append(cls_images[1])

# 4. Distribute remaining (80/20)
remaining_images = [img for img in images if img not in used]
for image in remaining_images:
    if len(train_images) < target_train_size:
        train_images.append(image)
    else:
        val_images.append(image)

# 5. Verify
val_only_classes = val_classes - train_classes
if val_only_classes:
    print(f"WARNING: {len(val_only_classes)} classes only in val")
else:
    print(f"[OK] All {len(val_classes)} val classes in train")
```

#### Validation Debugging
**`mvp/training/adapters/ultralytics_adapter.py:1200-1700`**:
- Train/val dataset label count ë¡œê¹…
- Confusion matrix ìƒì„¸ ë””ë²„ê¹…
- Validation batch ì²˜ë¦¬ ì¶”ì  callbacks
- Manual validation ì‹œë„ (3ê°€ì§€ ì ‘ê·¼)
- Train-mode validation í…ŒìŠ¤íŠ¸

#### Issue Documentation
**`docs/issues/yolo_validation_metrics.md`** (ìƒˆ íŒŒì¼):
- **Status**: ğŸ”´ CANNOT FIX - PyTorch Design Limitation
- **Impact**: Medium (training works, post-training validation works)
- Root cause ë¶„ì„ (3ê°€ì§€)
- Investigation log (4 attempts)
- Possible solutions (4 options)
- Lessons learned

#### Analysis Tool
**`analyze_class_dist.py`** (ìƒˆ íŒŒì¼):
- Train/val split í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
- Val-only classes íƒì§€
- í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±
- DICE annotations.json ì—°ë™

### ì¡°ì‚¬ ê³¼ì • (Investigation Log)

#### Attempt 1: Callback Debugging
- ì¶”ê°€ callbacks: `on_val_batch_start`, `on_val_batch_end`, `on_val_end`
- ë°œê²¬: `validator.batch = None`, `validator.pred = None`
- ê²°ë¡ : Callback íƒ€ì´ë°ì— ë°ì´í„° ë¯¸ì ‘ê·¼

#### Attempt 2: Manual Validation (model.val())
- ì‹œë„: `on_fit_epoch_end`ì—ì„œ `model.val()` ì§ì ‘ í˜¸ì¶œ
- ì—ëŸ¬: `RuntimeError: element 0 does not require grad`
- ì›ì¸: `model.val()`ì´ gradient ë¹„í™œì„±í™”

#### Attempt 3: State Restoration
- ì‹œë„: Parameter `requires_grad` ìƒíƒœ ì €ì¥ í›„ ë³µì›
  ```python
  original_grad_states = {name: p.requires_grad for name, p in model.named_parameters()}
  # Run validation
  for name, param in model.named_parameters():
      param.requires_grad = original_grad_states[name]  # FAILS!
  ```
- ì—ëŸ¬: `RuntimeError: Setting requires_grad=True on inference tensor`
- ì›ì¸: PyTorch InferenceMode ì œì•½

#### Attempt 4: Train-Mode Validation
- ì‹œë„: Training mode + `torch.no_grad()` ì¡°í•©
  ```python
  with torch.no_grad():
      preds = model(val_batch['img'])
  optimizer.zero_grad()
  ```
- ì—ëŸ¬: `RuntimeError: expected scalar type Byte but found Float`
- ì›ì¸: Data type mismatch (uint8 vs float32)
- ê²°ë¡ : ë°ì´í„° ì „ì²˜ë¦¬ ì¶”ê°€í•˜ë©´ ê°€ëŠ¥ (ì¶”ê°€ êµ¬í˜„ í•„ìš”)

### Git ì‘ì—…

#### Commit
```
fee0630 feat(training): implement stratified dataset split for YOLO training

- Add stratified split algorithm to ensure all validation classes
  appear in training set (critical for small datasets)
- Val-only classes: 9 â†’ 0 (COCO32 tested)
- Document PyTorch InferenceMode limitation
- Add validation debugging callbacks
- Create class distribution analysis tool

Known Issue: Validation metrics still 0 due to PyTorch InferenceMode.
Post-training validation works. See docs/issues/yolo_validation_metrics.md
```

**ë³€ê²½ íŒŒì¼ (4ê°œ)**:
- `mvp/training/converters/dice_to_yolo.py` (+140 lines)
- `mvp/training/adapters/ultralytics_adapter.py` (+338 lines)
- `docs/issues/yolo_validation_metrics.md` (+227 lines, ìƒˆ íŒŒì¼)
- `analyze_class_dist.py` (+90 lines, ìƒˆ íŒŒì¼)

### í…ŒìŠ¤íŠ¸ ê²°ê³¼

#### COCO32 Dataset
- **Images**: 32ì¥
- **Classes**: 43ê°œ (COCO)
- **Before stratified split**: 9 classes val-only âŒ
- **After stratified split**: 0 classes val-only âœ…
- **Train/Val**: 25/7 images

#### COCO128 Dataset
- **Images**: 128ì¥
- **Classes**: 71ê°œ (COCO)
- **Stratified split**: 0 classes val-only âœ…
- **Train/Val**: 92/36 images
- **Annotations**: 929ê°œ objects

### ë‹¤ìŒ ë‹¨ê³„

#### Immediate (Close Issue)
- [x] Stratified split êµ¬í˜„
- [x] Issue ë¬¸ì„œí™”
- [x] Commit ìƒì„±
- [ ] **Inference API í…ŒìŠ¤íŠ¸** (ë‹¤ìŒ ìš°ì„ ìˆœìœ„)

#### Future (If Needed)
- [ ] Custom validator êµ¬í˜„ (~1-2ì¼)
  - Train-mode validation with proper data type handling
  - Manual mAP, precision, recall calculation
  - Confusion matrix construction
- [ ] Test other YOLO models (seg, pose, obb)
- [ ] Test timm models (ResNet, EfficientNet)

### ê´€ë ¨ ë¬¸ì„œ
- **Issue ë¬¸ì„œ**: [docs/issues/yolo_validation_metrics.md](../issues/yolo_validation_metrics.md)
- **Converter**: mvp/training/converters/dice_to_yolo.py:136-212
- **Adapter**: mvp/training/adapters/ultralytics_adapter.py:1200-1700
- **Analysis Tool**: analyze_class_dist.py

### í•µì‹¬ í†µì°° (Key Insights)

#### PyTorch InferenceMode vs no_grad
| Context | Gradient | Post-restoration | Performance |
|---------|----------|------------------|-------------|
| `no_grad()` | Disabled | âœ… Possible | Slower |
| `inference_mode()` | Disabled | âŒ Impossible | Faster |

**ê²°ë¡ **: UltralyticsëŠ” ì„±ëŠ¥ì„ ìœ„í•´ InferenceMode ì„ íƒ â†’ Flexibility í¬ìƒ

#### Small Dataset Challenge
- **0.74 images/class** (32 images, 43 classes)
- Random splitì€ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì¥
- Stratified split í•„ìˆ˜

#### Validation Monitoring Workaround
- âœ… Training lossë¡œ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
- âœ… Post-training validationìœ¼ë¡œ ìµœì¢… ë©”íŠ¸ë¦­ í™•ì¸
- âŒ Per-epoch validation metrics (ë‹¹ë¶„ê°„ í¬ê¸°)

### ê¸°ìˆ  ë…¸íŠ¸

#### Stratified Split vs Random Split
```python
# Random Split (ê¸°ì¡´ - ë¬¸ì œìˆìŒ)
random.shuffle(images)
split_idx = int(len(images) * 0.8)
train = images[:split_idx]
val = images[split_idx:]

# Stratified Split (ìƒˆë¡œìš´ - í•´ê²°)
# 1. Ensure all val classes in train
# 2. Distribute remaining by ratio
# 3. Verify no val-only classes
```

#### Label Path Structure
```
DICE Dataset (Original):
  datasets/uuid-123/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ 000000000009.jpg
    â”‚   â””â”€â”€ ...
    â””â”€â”€ labels/              # Single directory
        â”œâ”€â”€ 000000000009.txt
        â””â”€â”€ ...

YOLO Split (Converted):
  datasets/uuid-123_yolo/
    â”œâ”€â”€ train.txt            # Absolute paths
    â”œâ”€â”€ val.txt              # Absolute paths
    â””â”€â”€ data.yaml
```

**Key**: Labels stay in original DICE directory, not split into train/val subdirs.

---

## [2025-11-04 21:30] Project-Centric Checkpoint Storage êµ¬í˜„

### ë…¼ì˜ ì£¼ì œ
- Multi-tenant ì§€ì›ì„ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ êµ¬ì¡° ê°œì„ 
- í˜„ì¬ ê²½ë¡œ êµ¬ì¡°ì˜ ë¬¸ì œì  ì‹ë³„ ë° í•´ê²° ë°©ì•ˆ ë…¼ì˜
- ì „ì²´ training pipelineì— project_id ì „íŒŒ
- Training Service êµ¬í˜„ í˜„í™© ë¬¸ì„œí™”

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. Project-Centric Checkpoint Storage êµ¬ì¡° (Option 1 ì„ íƒ)
- **ë°°ê²½**:
  - ê¸°ì¡´: `checkpoints/job_{job_id}/` â†’ ì—¬ëŸ¬ ì‚¬ìš©ì/í”„ë¡œì íŠ¸/ì‹¤í—˜ êµ¬ë¶„ ë¶ˆê°€
  - TrainingJobì— `project_id`, `created_by`, `session_id`, `experiment_name` ì¡´ì¬
  - Multi-tenant í™˜ê²½ì—ì„œ ì²´í¬í¬ì¸íŠ¸ êµ¬ë¶„ í•„ìš”

- **ê²°ì •**: Project-centric ê³„ì¸µ êµ¬ì¡° âœ…
  ```
  checkpoints/
  â”œâ”€â”€ projects/
  â”‚   â””â”€â”€ {project_id}/
  â”‚       â””â”€â”€ jobs/
  â”‚           â””â”€â”€ {job_id}/
  â”‚               â”œâ”€â”€ best.pt
  â”‚               â””â”€â”€ last.pt
  â””â”€â”€ test-jobs/
      â””â”€â”€ job_{job_id}/
          â”œâ”€â”€ best.pt
          â””â”€â”€ last.pt
  ```

- **ì´ìœ **:
  - í”„ë¡œì íŠ¸ ë‹¨ìœ„ ê´€ë¦¬ (ê°€ì¥ ì§ê´€ì )
  - í…ŒìŠ¤íŠ¸/ê°œë°œ job ë³„ë„ ê´€ë¦¬ (project_id = null)
  - ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶ˆí•„ìš” (ì‚¬ìš©ìê°€ ìˆ˜ë™ ì‚­ì œ)

#### 2. ì „ì²´ Pipelineì— project_id ì „íŒŒ
- **Data Flow**:
  ```
  Backend (training_manager.py)
    â†’ job_config.project_id
      â†’ Training Service API (api_server.py)
        â†’ TrainingRequest.project_id
          â†’ train.py --project_id
            â†’ TrainingAdapter(project_id)
              â†’ TrainingCallbacks(project_id)
                â†’ upload_checkpoint(project_id)
                  â†’ R2 Storage (conditional path)
  ```

- **êµ¬í˜„ ìœ„ì¹˜** (6ê°œ íŒŒì¼ ìˆ˜ì •):
  1. `storage.py:527` - upload_checkpoint() conditional path logic
  2. `base.py:378` - TrainingAdapter.__init__ accepts project_id
  3. `base.py:1488` - TrainingCallbacks.__init__ accepts project_id
  4. `base.py:1861` - _upload_checkpoints_to_r2() passes project_id
  5. `ultralytics_adapter.py:1082` - Pass project_id to callbacks
  6. `train.py:95` - Add --project_id argument
  7. `api_server.py:60` - TrainingRequest.project_id field
  8. `training_manager.py:125` - job_config includes project_id

### êµ¬í˜„ ë‚´ìš©

#### Storage Layer
**`mvp/training/platform_sdk/storage.py`**:
```python
def upload_checkpoint(
    checkpoint_path: str,
    job_id: int,
    checkpoint_name: str = "best.pt",
    project_id: int = None  # ì¶”ê°€
):
    # Build path based on project_id
    if project_id:
        key = f'checkpoints/projects/{project_id}/jobs/{job_id}/{checkpoint_name}'
    else:
        key = f'checkpoints/test-jobs/job_{job_id}/{checkpoint_name}'
```

#### Adapter Layer
**`mvp/training/adapters/base.py`**:
```python
class TrainingAdapter:
    def __init__(
        self,
        model_config: ModelConfig,
        dataset_config: DatasetConfig,
        training_config: TrainingConfig,
        output_dir: str,
        job_id: int,
        project_id: int = None  # ì¶”ê°€
    ):
        self.project_id = project_id

class TrainingCallbacks:
    def __init__(
        self,
        job_id: int,
        model_config: 'ModelConfig',
        training_config: 'TrainingConfig',
        db_session=None,
        project_id: int = None  # ì¶”ê°€
    ):
        self.project_id = project_id

    def _upload_checkpoints_to_r2(self, checkpoint_dir: str = None):
        upload_checkpoint(
            checkpoint_path=str(checkpoint_file),
            job_id=self.job_id,
            checkpoint_name=checkpoint_name,
            project_id=self.project_id  # ì „ë‹¬
        )
```

#### Training Service API
**`mvp/training/api_server.py`**:
```python
class TrainingRequest(BaseModel):
    job_id: int
    framework: str
    # ... other fields
    project_id: Optional[int] = None  # ì¶”ê°€

def run_training(request: TrainingRequest):
    cmd = [...]
    if request.project_id is not None:
        cmd.extend(["--project_id", str(request.project_id)])
```

#### Training Script
**`mvp/training/train.py`**:
```python
def parse_args():
    parser.add_argument('--project_id', type=int, default=None,
                        help='Project ID for organizing checkpoints in R2')

adapter = adapter_class(
    model_config=model_config,
    dataset_config=dataset_config,
    training_config=training_config,
    output_dir=args.output_dir,
    job_id=args.job_id,
    project_id=args.project_id,  # ì „ë‹¬
    logger=logger
)
```

#### Backend
**`mvp/backend/app/utils/training_manager.py`**:
```python
job_config = {
    "job_id": job_id,
    "framework": job.framework,
    # ... other fields
    "project_id": job.project_id  # ì¶”ê°€
}
```

### ë¬¸ì„œí™”

#### `docs/trainer/IMPLEMENTATION_STATUS.md` (ìƒˆ íŒŒì¼)
**í¬í•¨ ë‚´ìš©**:
- Training Service ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨
- êµ¬í˜„ ì™„ë£Œ ê¸°ëŠ¥ (Phase 1)
  - Microservice Architecture âœ…
  - R2 Storage Integration âœ…
  - YOLO Training Pipeline âœ…
  - DICE Dataset Format âœ…
  - Project-Centric Checkpoints âœ…
- í…ŒìŠ¤íŠ¸ ê²°ê³¼ (Job #11, #12, #13)
- ê¸°ìˆ  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­
- API ì—”ë“œí¬ì¸íŠ¸ ë¬¸ì„œ
- ë‹¤ìŒ ë‹¨ê³„ (Phase 2: Frontend Integration)

### Git ì‘ì—…

#### Commit
```
67142e4 feat(training): implement project-centric checkpoint storage

- Add project_id parameter throughout training pipeline
- Implement conditional path logic in upload_checkpoint()
- Update all adapters and callbacks to handle project_id
- Add comprehensive implementation status document
```

**ë³€ê²½ íŒŒì¼ (7ê°œ)**:
- `mvp/training/platform_sdk/storage.py`
- `mvp/training/adapters/base.py`
- `mvp/training/adapters/ultralytics_adapter.py`
- `mvp/training/train.py`
- `mvp/training/api_server.py`
- `mvp/backend/app/utils/training_manager.py`
- `docs/trainer/IMPLEMENTATION_STATUS.md` (ìƒˆ íŒŒì¼)

### í…ŒìŠ¤íŠ¸ ê³„íš

#### Job #14 í…ŒìŠ¤íŠ¸ (ë‹¤ìŒ ë‹¨ê³„)
**ëª©í‘œ**: ìƒˆë¡œìš´ project-centric ê²½ë¡œ êµ¬ì¡° ê²€ì¦

**ì‹œë‚˜ë¦¬ì˜¤ 1**: project_id ìˆëŠ” ê²½ìš°
- Job with project_id = 5
- Expected path: `checkpoints/projects/5/jobs/14/best.pt`

**ì‹œë‚˜ë¦¬ì˜¤ 2**: project_id ì—†ëŠ” ê²½ìš° (test job)
- Job with project_id = null
- Expected path: `checkpoints/test-jobs/job_14/best.pt`

**ê²€ì¦ ì‚¬í•­**:
- Backendê°€ project_idë¥¼ Training Serviceì— ì „ë‹¬
- Training Serviceê°€ train.pyì— --project_id ì „ë‹¬
- Adapterê°€ Callbacksì— project_id ì „ë‹¬
- Callbacksê°€ upload_checkpoint()ì— project_id ì „ë‹¬
- R2ì— ì˜¬ë°”ë¥¸ ê²½ë¡œë¡œ ì—…ë¡œë“œ

### ë‹¤ìŒ ë‹¨ê³„

#### Phase 2: Frontend Integration (ì˜ˆì •)
- [ ] Training Job ìƒì„± UI
- [ ] Real-time training monitoring
- [ ] Checkpoint download interface
- [ ] Project selection in training form

#### Testing
- [ ] Job #14 ì‹¤í–‰ ë° ê²½ë¡œ ê²€ì¦
- [ ] Project job vs test job ê²½ë¡œ ì°¨ì´ í™•ì¸
- [ ] R2 Storageì—ì„œ ê²½ë¡œ êµ¬ì¡° í™•ì¸

### ê´€ë ¨ ë¬¸ì„œ
- **êµ¬í˜„ í˜„í™©**: [docs/trainer/IMPLEMENTATION_STATUS.md](../trainer/IMPLEMENTATION_STATUS.md)
- **Adapter ì„¤ê³„**: [docs/trainer/ADAPTER_DESIGN.md](../trainer/ADAPTER_DESIGN.md)
- **ì´ì „ ì„¸ì…˜**: [2025-11-04 17:30] Training Service Microservice ì¸í”„ë¼ êµ¬ì¶•

### í•µì‹¬ ì›ì¹™ ì¤€ìˆ˜

1. **No Shortcuts** âœ…
   - í•˜ë“œì½”ë”© ì—†ìŒ (project_idë¥¼ ë™ì ìœ¼ë¡œ ì „ë‹¬)
   - ì„ì‹œ ë°©í¸ ì—†ìŒ (ì „ì²´ chain êµ¬í˜„)

2. **Production = Local** âœ…
   - ë™ì¼í•œ ì½”ë“œë² ì´ìŠ¤
   - í™˜ê²½ë³€ìˆ˜ë§Œ ì°¨ì´
   - R2 Storage ê³µí†µ ì‚¬ìš©

3. **Dependency Isolation** âœ…
   - Backend: project_idë§Œ ì „ë‹¬ (training ë¡œì§ ë¬´ê´€)
   - Training Service: ë…ë¦½ì ìœ¼ë¡œ checkpoint ê´€ë¦¬

---

## [2025-11-04 17:30] Training Service Microservice ì¸í”„ë¼ êµ¬ì¶• ë° ë°ì´í„° ì ‘ê·¼ ì „ëµ ìˆ˜ë¦½

### ë…¼ì˜ ì£¼ì œ
- Training Service Microservice ì•„í‚¤í…ì²˜ êµ¬í˜„
- Frameworkë³„ ë…ë¦½ ì„œë¹„ìŠ¤ êµ¬ì„± (timm, ultralytics, huggingface)
- R2 Storage ì§ì ‘ ì ‘ê·¼ ì „ëµ
- DICE Format â†’ Framework Format ë³€í™˜ ì„¤ê³„
- ë°ì´í„°ì…‹-ëª¨ë¸ í˜¸í™˜ì„± ê²€ì¦ ì „ëµ

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. Microservice ì•„í‚¤í…ì²˜ êµ¬í˜„ (Railway í™˜ê²½ê³¼ ë™ì¼)
- **ë°°ê²½**:
  - ë¡œì»¬ í…ŒìŠ¤íŠ¸ê°€ subprocess ë°©ì‹ìœ¼ë¡œ ë™ì‘
  - Railway ë°°í¬ í™˜ê²½ì€ microserviceë¡œ êµ¬ì„±
  - ë¡œì»¬ê³¼ ë°°í¬ í™˜ê²½ì˜ ë¶ˆì¼ì¹˜ ë¬¸ì œ

- **ê²°ì •**: ë¡œì»¬ì—ì„œë„ microserviceë¡œ ì‹¤í–‰ âœ…
  ```
  Backend (Port 8000)
    â†“ HTTP
  ultralytics-service (Port 8001) â† UPDATED 2025-11-13
  timm-service (Port 8002) â† UPDATED 2025-11-13
  huggingface-service (Port 8003)
  ```

  **âš ï¸ Port Change Log (2025-11-13)**:
  - Original plan: timm=8001, ultralytics=8002
  - Current: ultralytics=8001, timm=8002 (planned)
  - Reason: Ultralytics implemented first on 8001, kept for stability

- **êµ¬í˜„ ë‚´ìš©**:
  - Frameworkë³„ ë…ë¦½ venv ìƒì„± (`venv-ultralytics`, `venv-timm`)
  - ë…ë¦½ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (`scripts/start-ultralytics-service.bat`)
  - Backend `.env`ì— frameworkë³„ URL ì„¤ì •
  - `TrainingServiceClient`ê°€ framework ê¸°ë°˜ ë¼ìš°íŒ… ì§€ì›

#### 2. R2 Storage ì§ì ‘ ì ‘ê·¼ (Option A ì„ íƒ)
- **ì§ˆë¬¸**: Training Serviceê°€ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì ‘ê·¼í•  ê²ƒì¸ê°€?
  - Option A: Training Serviceê°€ R2 ì§ì ‘ ì ‘ê·¼ (ì¶”ì²œ âœ…)
  - Option B: Backend API í†µí•´ ë‹¤ìš´ë¡œë“œ

- **ê²°ì •**: Option A - R2 ì§ì ‘ ì ‘ê·¼
- **ì´ìœ **:
  - Microservice ì² í•™ì— ë§ìŒ (ë…ë¦½ì  ë™ì‘)
  - Backend ë¶€ë‹´ ê°ì†Œ
  - `platform_sdk/storage.py` ì´ë¯¸ êµ¬í˜„ë¨
  - R2 credentials ê³µìœ  í•„ìš”í•˜ì§€ë§Œ ë¬¸ì œì—†ìŒ

- **êµ¬í˜„ ë°©ì‹**:
  ```python
  # Training Service .env
  AWS_S3_ENDPOINT_URL=https://...r2.cloudflarestorage.com
  AWS_ACCESS_KEY_ID=...
  AWS_SECRET_ACCESS_KEY=...
  S3_BUCKET=vision-platform-prod

  # platform_sdk/storage.py
  get_dataset(dataset_id) â†’ R2 ë‹¤ìš´ë¡œë“œ â†’ ë¡œì»¬ ìºì‹œ
  ```

#### 3. Dataset ID ê¸°ë°˜ ì ‘ê·¼ (Path ë°©ì‹ì—ì„œ ì „í™˜)
- **í˜„ì¬ ë¬¸ì œ**:
  - ê¸°ì¡´: `dataset_path` (íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œ)
  - Frontend íë¦„: Userê°€ ë°ì´í„°ì…‹ ì„ íƒ (ID ê¸°ë°˜)
  - R2 êµ¬ì¡°: `datasets/{id}/` (UUID ê¸°ë°˜)

- **ê²°ì •**: `dataset_id` ê¸°ë°˜ìœ¼ë¡œ ì „í™˜
  ```python
  # Frontend â†’ Backend
  {"dataset_id": "uuid-123"}

  # Backend â†’ Training Service
  {"dataset_id": "uuid-123"}

  # Training Service
  dataset_path = get_dataset("uuid-123")
  # â†’ R2: datasets/uuid-123/ ë‹¤ìš´ë¡œë“œ
  # â†’ Local: /workspace/data/.cache/datasets/uuid-123/
  ```

#### 4. DICE Format ë³€í™˜ ì „ëµ
- **ë°°ê²½**:
  - R2ì— DICE Formatìœ¼ë¡œ ì €ì¥ë¨ (`annotations.json`)
  - ê° frameworkëŠ” ê³ ìœ  í¬ë§· í•„ìš” (YOLO, COCO, ImageFolder ë“±)

- **ë³€í™˜ ì „ëµ**:
  ```
  Training Service
    â†“ 1. Download
    datasets/{id}/annotations.json (DICE Format)

    â†“ 2. Convert
    dice_to_yolo()      â†’ data.yaml, labels/*.txt
    dice_to_imagefolder() â†’ train/class1/, val/class1/
    dice_to_coco()      â†’ annotations/instances.json

    â†“ 3. Train
    UltralyticsAdapter(converted_path)
  ```

- **êµ¬í˜„ ìœ„ì¹˜**: `mvp/training/converters/`
  - `dice_to_yolo.py`
  - `dice_to_imagefolder.py`
  - `dice_to_coco.py`

#### 5. ë°ì´í„°ì…‹-ëª¨ë¸ í˜¸í™˜ì„± ê²€ì¦ (3-Tier ì „ëµ)
- **ë¬¸ì œ**:
  - Classification ë°ì´í„°ë¡œ Detection í•™ìŠµ ë¶ˆê°€
  - Segmentation â†’ Detection ë³€í™˜ ê°€ëŠ¥
  - Detection â†’ Classification ë³€í™˜ ì• ë§¤

- **3-Tier ê²€ì¦ ì „ëµ**:
  ```
  Tier 1: Frontend (UX Hint) [P2]
    â†’ ë°ì´í„°ì…‹ ì„ íƒ ì‹œ í˜¸í™˜ì„± íŒíŠ¸ í‘œì‹œ

  Tier 2: Backend API (ì‚¬ì „ ê²€ì¦) [P1]
    â†’ GET /datasets/{id}/compatibility?task_type=...
    â†’ DB ë©”íƒ€ë°ì´í„° or annotations.json íŒŒì‹±

  Tier 3: Training Service (ì‹¤í–‰ ì‹œ ê²€ì¦) [P0] âœ…
    â†’ prepare_dataset()ì—ì„œ ìƒì„¸ ê²€ì¦
    â†’ ë³€í™˜ ê°€ëŠ¥í•˜ë©´ ë³€í™˜, ë¶ˆê°€ëŠ¥í•˜ë©´ ëª…í™•í•œ ì—ëŸ¬
  ```

- **MVP ìš°ì„ ìˆœìœ„**: Tier 3ë§Œ êµ¬í˜„ (í•„ìˆ˜)
  - ì´ìœ : ì¼ë‹¨ ë™ì‘í•˜ëŠ” ê²ƒ ë¨¼ì €, UXëŠ” ë‚˜ì¤‘ì—

- **ë³€í™˜ ê·œì¹™ í…Œì´ë¸”**:
  ```python
  CONVERSION_MATRIX = {
      ("instance_segmentation", "object_detection"): polygon_to_bbox,
      ("instance_segmentation", "image_classification"): use_dominant_class,
      ("object_detection", "image_classification"): use_dominant_class,
      ("image_classification", "object_detection"): None,  # âŒ ë¶ˆê°€ëŠ¥
  }
  ```

### êµ¬í˜„ ë‚´ìš©

#### Microservice ì¸í”„ë¼
**ìŠ¤í¬ë¦½íŠ¸ ìƒì„±**:
- `mvp/scripts/setup-ultralytics-service.bat` - venv ìƒì„± ë° ì˜ì¡´ì„± ì„¤ì¹˜
- `mvp/scripts/start-ultralytics-service.bat` - ì„œë¹„ìŠ¤ ì‹œì‘ (Port 8001) â† **UPDATED 2025-11-13**
- `mvp/scripts/setup-timm-service.bat` - timm ì„œë¹„ìŠ¤ ì…‹ì—…
- `mvp/scripts/start-timm-service.bat` - timm ì„œë¹„ìŠ¤ ì‹œì‘ (Port 8002) â† **UPDATED 2025-11-13**

**Backend ì„¤ì •** (Updated 2025-11-13):
```bash
# platform/backend/.env
ULTRALYTICS_SERVICE_URL=http://localhost:8001  # UPDATED: was 8002
TIMM_SERVICE_URL=http://localhost:8002  # UPDATED: was 8001
HUGGINGFACE_SERVICE_URL=http://localhost:8003
TRAINING_SERVICE_URL=http://localhost:8001  # Fallback (Ultralytics)
```

**ultralytics-service ì‹¤í–‰ í™•ì¸** (Updated 2025-11-13):
- âœ… Port 8001ì—ì„œ ì •ìƒ ë™ì‘
- âœ… Health Check: `{"status":"healthy"}`
- âœ… Models API: 5ê°œ ëª¨ë¸ (yolo11n, yolo11n-seg, yolo11n-pose, yolo_world_v2_s, sam2_t)

#### ê¸°ì¡´ ì½”ë“œ ë¶„ì„
**platform_sdk/storage.py**:
- âœ… `get_dataset(dataset_id)` ì´ë¯¸ êµ¬í˜„ë¨
- âœ… 3-tier ìºì‹±: Local â†’ R2 â†’ Original source
- âœ… ìë™ ì••ì¶• í•´ì œ ë° ë””ë ‰í† ë¦¬ ë°˜í™˜

**ultralytics_adapter.py**:
- âœ… `_resolve_dataset_path()` ë©”ì„œë“œ ì¡´ì¬
- âœ… Simple name ê°ì§€ â†’ `get_dataset()` í˜¸ì¶œ
- âš ï¸ í˜„ì¬ëŠ” path ê¸°ë°˜, dataset_id ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì • í•„ìš”

### ë‹¤ìŒ ë‹¨ê³„ (ìš°ì„ ìˆœìœ„ ìˆœ)

#### Phase 1: í™˜ê²½ ì„¤ì • ë° ê¸°ë³¸ ì—°ë™
- [x] ultralytics-service venv ìƒì„± ë° ì˜ì¡´ì„± ì„¤ì¹˜
- [x] ultralytics-service ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
- [x] Backend .env ì—…ë°ì´íŠ¸ (frameworkë³„ URL)
- [ ] Training Service .env ì—…ë°ì´íŠ¸ (R2 credentials)
- [ ] Backend ì‹¤í–‰ ë° Training Service ì—°ê²° í…ŒìŠ¤íŠ¸

#### Phase 2: DICE Format ë³€í™˜ê¸° êµ¬í˜„
- [ ] `mvp/training/converters/dice_to_yolo.py` êµ¬í˜„
  - annotations.json íŒŒì‹±
  - Polygon â†’ Bounding box ë³€í™˜
  - data.yaml ìƒì„±
  - labels/*.txt ìƒì„±
- [ ] `platform_sdk/storage.py` í™•ì¥
  - `get_dataset_from_r2(dataset_id)` ë””ë ‰í† ë¦¬ ë‹¤ìš´ë¡œë“œ
- [ ] í˜¸í™˜ì„± ê²€ì¦ ë¡œì§
  - `check_detailed_compatibility()` í•¨ìˆ˜
  - CONVERSION_MATRIX ì •ì˜

#### Phase 3: í•™ìŠµ íŒŒì´í”„ë¼ì¸ E2E í…ŒìŠ¤íŠ¸
- [ ] R2ì— í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì—…ë¡œë“œ (sample-det-coco32)
- [ ] Backend â†’ ultralytics-service í•™ìŠµ ì‹œì‘
- [ ] ë°ì´í„° ë‹¤ìš´ë¡œë“œ â†’ ë³€í™˜ â†’ í•™ìŠµ ì „ì²´ íë¦„ ê²€ì¦
- [ ] ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¡œê¹… í™•ì¸

#### Phase 4: Checkpoint R2 ì €ì¥
- [ ] `platform_sdk/storage.py`ì— `upload_checkpoint()` ì¶”ê°€
- [ ] Adapter `save_checkpoint()` ìˆ˜ì •
- [ ] R2 ê²½ë¡œ: `checkpoints/{job_id}/epoch_{epoch}.pth`

### í•µì‹¬ ì„¤ê³„ ì›ì¹™

1. **No Shortcuts, No Hardcoding** (CLAUDE.md)
   - âœ… ë™ì  ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (Training Service API)
   - âœ… R2 Storage ê¸°ë°˜ (ë¡œì»¬ íŒŒì¼ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì œê±°)
   - âœ… Database ê¸°ë°˜ ë©”íƒ€ë°ì´í„° (í•˜ë“œì½”ë”© ìƒ˜í”Œ ì—†ìŒ)

2. **Dependency Isolation**
   - âœ… Backend: PyTorch ì—†ìŒ
   - âœ… Training Services: Frameworkë³„ ë…ë¦½ venv
   - âœ… HTTP/JSON í†µì‹ ë§Œ

3. **Production = Local**
   - âœ… Microservice ì•„í‚¤í…ì²˜ ë™ì¼
   - âœ… R2 Storage ì‚¬ìš©
   - âœ… í™˜ê²½ë³€ìˆ˜ë§Œ ì°¨ì´ (URL, credentials)

### ê´€ë ¨ ë¬¸ì„œ
- **ì¸í”„ë¼**: [docs/planning/TRAINER_IMPLEMENTATION_PLAN.md](../planning/TRAINER_IMPLEMENTATION_PLAN.md)
- **ë°ì´í„°ì…‹ ì„¤ê³„**: [docs/datasets/DATASET_MANAGEMENT_DESIGN.md](../datasets/DATASET_MANAGEMENT_DESIGN.md)
- **DICE Format ìŠ¤í™**: [docs/datasets/PLATFORM_DATASET_FORMAT.md](../datasets/PLATFORM_DATASET_FORMAT.md)
- **í˜„ì¬ ìƒíƒœ**: [docs/datasets/CURRENT_STATUS.md](../datasets/CURRENT_STATUS.md)

### ê¸°ìˆ  ë…¸íŠ¸

#### R2 Storage êµ¬ì¡°
```
vision-platform-prod/
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ {id}/
â”‚       â”œâ”€â”€ images/          # ì›ë³¸ í´ë” êµ¬ì¡° ìœ ì§€
â”‚       â””â”€â”€ annotations.json # DICE Format v1.0
â”œâ”€â”€ models/
â”‚   â””â”€â”€ pretrained/{framework}/{model_name}.pt
â””â”€â”€ checkpoints/
    â””â”€â”€ {job_id}/
        â””â”€â”€ epoch_{n}.pth
```

#### Training Service ë°ì´í„° íë¦„
```
1. Backend â†’ POST /training/start
   {"dataset_id": "uuid-123", "model_name": "yolo11n", ...}

2. Training Service â†’ get_dataset("uuid-123")
   - Check local: /workspace/data/.cache/datasets/uuid-123/
   - Download R2: datasets/uuid-123/ â†’ local cache
   - Return: local_path

3. DICE Format ë³€í™˜
   - Parse: annotations.json
   - Check: compatibility with task_type
   - Convert: dice_to_yolo() â†’ data.yaml + labels/
   - Return: converted_path

4. í•™ìŠµ ì‹¤í–‰
   - UltralyticsAdapter(converted_path)
   - Train + Validate
   - Save checkpoint â†’ R2
   - Log metrics â†’ Backend
```

#### Frameworkë³„ Port í• ë‹¹ (Updated 2025-11-13)
```
Backend:             8000
ultralytics-service: 8001  â† UPDATED (was 8002)
timm-service:        8002  â† UPDATED (was 8001, planned)
huggingface-service: 8003
Frontend:            3000
```

**Change Log**: Ultralytics implemented first on 8001, timm moved to 8002 to avoid conflict

---

## [2025-11-04 16:00] ë°ì´í„°ì…‹ ì¸ì¦/ê¶Œí•œ êµ¬í˜„ ë° í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„

### ë…¼ì˜ ì£¼ì œ
- ë°ì´í„°ì…‹ ì¸ì¦ ë° ê¶Œí•œ ì²´í¬ êµ¬í˜„
- í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ vs ìŠ¤ëƒ…ìƒ· êµ¬í˜„ ìš°ì„ ìˆœìœ„
- YOLO segmentation â†’ DICE Format ë³€í™˜
- í”„ë¡ íŠ¸ì—”ë“œ UX ê°œì„  (ìë™ ë„¤ë¹„ê²Œì´ì…˜ ì œê±°)
- PR ìƒì„± ë° ë¬¸ì„œí™”

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. ë°ì´í„°ì…‹ ì¸ì¦ ì‹œìŠ¤í…œ êµ¬í˜„
- **ë°°ê²½**: ë°ì´í„°ì…‹ì„ ì•„ë¬´ë‚˜ ë³¼ ìˆ˜ ìˆëŠ” ë³´ì•ˆ ë¬¸ì œ ë°œê²¬
- **êµ¬í˜„ ë‚´ìš©**:
  - Backend: ëª¨ë“  dataset APIì— `Depends(get_current_user)` ì¶”ê°€
  - Frontend: ëª¨ë“  API í˜¸ì¶œì— Bearer token ì¶”ê°€
  - Sidebar: ì¸ì¦ëœ ì‚¬ìš©ìë§Œ "ë°ì´í„°ì…‹", "í”„ë¡œì íŠ¸" ë©”ë‰´ í‘œì‹œ
- **ê¶Œí•œ ê·œì¹™**:
  - ì†Œìœ ì(owner)ë§Œ ì‚­ì œ/ì—…ë¡œë“œ ê°€ëŠ¥
  - Public ë°ì´í„°ì…‹ì€ ëª¨ë“  ì¸ì¦ ì‚¬ìš©ì ì¡°íšŒ ê°€ëŠ¥
  - Private ë°ì´í„°ì…‹ì€ ì†Œìœ ìë§Œ ì ‘ê·¼

#### 2. ìŠ¤ëƒ…ìƒ· êµ¬í˜„ ì‹œê¸° ê²°ì •
- **ì§ˆë¬¸**: í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì „ì— ìŠ¤ëƒ…ìƒ· êµ¬í˜„ì´ í•„ìš”í•œê°€?
- **ê²°ì •**: í•™ìŠµ íŒŒì´í”„ë¼ì¸ ë¨¼ì € í…ŒìŠ¤íŠ¸ (Option A) âœ…
- **ì´ìœ **:
  - ìŠ¤ëƒ…ìƒ· ì—†ì´ë„ í•™ìŠµ ê°€ëŠ¥ (`dataset_snapshot_id`ëŠ” nullable)
  - í•™ìŠµì´ ì œëŒ€ë¡œ ëŒì•„ê°€ì•¼ ìŠ¤ëƒ…ìƒ·ë„ ì˜ë¯¸ ìˆìŒ
  - DB ëª¨ë¸ì€ ì´ë¯¸ ì¤€ë¹„ë¨ (ë¹ ë¥¸ ì „í™˜ ê°€ëŠ¥)
  - MVP ë‹¨ê³„ì—ì„œëŠ” í•µì‹¬ ê¸°ëŠ¥ ê²€ì¦ ìš°ì„ 
- **ìœ„í—˜ ê´€ë¦¬**: ì´ˆê¸° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì€ ìˆ˜ì •í•˜ì§€ ì•Šê¸°

#### 3. DICE Format ë³€í™˜ ì¤€ë¹„
- **ëª©ì **: í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ ì¤€ë¹„
- **ì‘ì—…**: YOLO segmentation â†’ DICE Format v1.0 ë³€í™˜
- **ì…ë ¥**: `C:\datasets\seg-coco32` (YOLO format)
- **ì¶œë ¥**: `C:\datasets\dice_format\seg-coco32` (DICE format)
- **ê²°ê³¼**:
  - 32 images, 209 annotations
  - 43 COCO classes (person, car, cup ë“±)
  - instance_segmentation íƒœìŠ¤í¬

#### 4. í”„ë¡ íŠ¸ì—”ë“œ UX ê°œì„ 
- **ë¬¸ì œ**: ë°ì´í„°ì…‹ ìƒì„± í›„ ìƒì„¸ í˜ì´ì§€ë¡œ ìë™ ì „í™˜
- **í•´ê²°**: ìë™ ë„¤ë¹„ê²Œì´ì…˜ ì œê±°, í…Œì´ë¸”ë§Œ ìƒˆë¡œê³ ì¹¨
- **ì´ìœ **:
  - ì—¬ëŸ¬ ë°ì´í„°ì…‹ ì—°ì† ìƒì„± ì‹œ í¸ë¦¬
  - ë¶ˆí•„ìš”í•œ í™”ë©´ ì „í™˜ ê°ì†Œ
  - ì‚¬ìš©ìê°€ ì›í•˜ë©´ ìˆ˜ë™ìœ¼ë¡œ í´ë¦­ ê°€ëŠ¥

### êµ¬í˜„ ë‚´ìš©

#### Backend (ì¸ì¦ ì¶”ê°€)

**`mvp/backend/app/api/datasets.py`**:
```python
# ì¶”ê°€ëœ imports
from app.db.models import Dataset, User
from app.utils.dependencies import get_current_user

# ìˆ˜ì •ëœ ì—”ë“œí¬ì¸íŠ¸
@router.get("/available")
async def list_sample_datasets(
    current_user: User = Depends(get_current_user),  # ì¶”ê°€
    db: Session = Depends(get_db)
):
    # Owner OR public í•„í„°ë§
    query = db.query(Dataset).filter(
        or_(
            Dataset.owner_id == current_user.id,
            Dataset.visibility == 'public'
        )
    )

@router.post("")
async def create_dataset(
    current_user: User = Depends(get_current_user),  # ì¶”ê°€
    ...
):
    new_dataset = Dataset(
        owner_id=current_user.id,  # ìë™ ì„¤ì •
        ...
    )

@router.delete("/{dataset_id}")
async def delete_dataset(
    current_user: User = Depends(get_current_user),  # ì¶”ê°€
    ...
):
    # ì†Œìœ ì í™•ì¸
    if dataset.owner_id != current_user.id:
        raise HTTPException(403, "Permission denied")
```

**`mvp/backend/app/api/datasets_images.py`**:
- ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ì— `current_user` íŒŒë¼ë¯¸í„° ì¶”ê°€
- ì†Œìœ ì í™•ì¸ ë¡œì§ ì¶”ê°€
- Public dataset ì¡°íšŒ í—ˆìš© ë¡œì§

**`mvp/backend/app/api/datasets_folder.py`**:
- í´ë” ì—…ë¡œë“œ APIì— ì¸ì¦ ì¶”ê°€
- ì†Œìœ ìë§Œ ì—…ë¡œë“œ ê°€ëŠ¥

#### Frontend (ì¸ì¦ í† í° ì¶”ê°€)

**`mvp/frontend/components/Sidebar.tsx`**:
```tsx
{/* ì¸ì¦ëœ ì‚¬ìš©ìë§Œ í‘œì‹œ */}
{isAuthenticated && (
  <div>
    <button onClick={onOpenDatasets}>ë°ì´í„°ì…‹</button>
  </div>
)}

{isAuthenticated && (
  <div>í”„ë¡œì íŠ¸ ëª©ë¡</div>
)}
```

**`mvp/frontend/components/DatasetPanel.tsx`**:
```typescript
const fetchDatasets = async () => {
  const token = localStorage.getItem('access_token')

  if (!token) {
    console.error('No access token found')
    return
  }

  const response = await fetch(`${baseUrl}/datasets/available`, {
    headers: {
      'Authorization': `Bearer ${token}`
    }
  })
}

const handleDeleteConfirm = async () => {
  const token = localStorage.getItem('access_token')

  const response = await fetch(`${baseUrl}/datasets/${id}`, {
    method: 'DELETE',
    headers: {
      'Authorization': `Bearer ${token}`
    }
  })
}
```

**`mvp/frontend/components/datasets/CreateDatasetModal.tsx`**:
```typescript
// useRouter import ì œê±°
// router.push() ì œê±°
// ì„±ê³µ í›„ ëª¨ë‹¬ë§Œ ë‹«ê¸°
setTimeout(() => {
  handleClose()  // ë„¤ë¹„ê²Œì´ì…˜ ì—†ì´ ë‹«ê¸°ë§Œ
}, 1000)
```

**ê¸°íƒ€ ì»´í¬ë„ŒíŠ¸**:
- `DatasetImageUpload.tsx`: Bearer token ì¶”ê°€
- `DatasetImageGallery.tsx`: Bearer token ì¶”ê°€
- `ProjectDetail.tsx`: handleSaveEditì— token ì¶”ê°€
- `datasets/[id]/page.tsx`: Bearer token ì¶”ê°€

#### ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸

**`mvp/backend/convert_yolo_seg_to_platform.py`** (ìƒˆ íŒŒì¼):
- YOLO segmentation â†’ DICE Format ë³€í™˜
- Normalized coordinates â†’ ì ˆëŒ€ pixel coordinates
- Polygon segmentation ë°ì´í„° ë³´ì¡´
- Bounding box ìë™ ê³„ì‚°
- Area ê³„ì‚° (shoelace formula)
- Content hash ìƒì„±

### Git ì‘ì—…

#### Commits (7ê°œ)
```
8996157 docs(datasets): add current status and next steps document
744fb3e chore: update gitignore for test files and database backups
99a5ef5 fix(frontend): remove auto-navigation after dataset creation
ae26d92 feat(mvp): implement authentication and authorization for datasets
ab28012 feat(datasets): enhance folder upload and add dataset deletion
d527411 feat(datasets): implement Create-then-Upload architecture
b1677fd feat(datasets): add individual image management with R2 presigned URLs
```

#### Pull Request
- **PR #12**: "feat(datasets): implement Dataset Entity with R2 Storage and Authentication"
- **Base**: main
- **28 commits** total in this feature branch
- **Status**: Ready for review

### ìƒì„±ëœ ë¬¸ì„œ

#### `docs/datasets/CURRENT_STATUS.md` (ìƒˆ íŒŒì¼)
**ëª©ì **: ë‹¤ìŒ ì„¸ì…˜ì„ ìœ„í•œ ì¢…í•© ìƒíƒœ ë¬¸ì„œ

**í¬í•¨ ë‚´ìš©**:
- âœ… ì™„ë£Œëœ ê¸°ëŠ¥ (Phase 1 & 2)
  - Core Infrastructure
  - Backend API (CRUD, Images, Folder)
  - Frontend Components
  - DICE Format v2.0
  - Training Integration
  - Authentication

- â³ ë‚¨ì€ ì‘ì—… (Phase 3 & 4)
  - Sprint 1: ë²„ì „ë‹/ìŠ¤ëƒ…ìƒ· (2-3ì¼)
  - Sprint 2: UI/UX ê°œì„  (1-2ì¼)
  - Sprint 3: ë¬´ê²°ì„± ê´€ë¦¬ (2-3ì¼)

- ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
  - seg-coco32 (DICE Format)
  - ìœ„ì¹˜, êµ¬ì¡°, ë©”íƒ€ë°ì´í„°, ì‚¬ìš©ë²•

- ğŸ¯ ë‹¤ìŒ ì„¸ì…˜ ì‹œì‘ ê°€ì´ë“œ
  - **Option A**: í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (ì¶”ì²œ)
  - Option B: ìŠ¤ëƒ…ìƒ· êµ¬í˜„
  - Quick Start ëª…ë ¹ì–´

- ğŸ” ì¤‘ìš” íŒŒì¼ ê²½ë¡œ ë§µ

### í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹

**seg-coco32 (DICE Format v1.0)**:
- **ìœ„ì¹˜**: `C:\datasets\dice_format\seg-coco32`
- **êµ¬ì¡°**:
  ```
  seg-coco32/
  â”œâ”€â”€ annotations.json    # DICE Format v1.0
  â””â”€â”€ images/             # 32 images
  ```
- **ë©”íƒ€ë°ì´í„°**:
  - Format: instance_segmentation
  - Images: 32ì¥
  - Annotations: 209ê°œ polygon segmentations
  - Classes: 43ê°œ COCO í´ë˜ìŠ¤
  - Avg annotations per image: 6.53ê°œ
- **Top 5 classes**: person (56), car (19), cup (15), giraffe (9), bird (8)

### ë‹¤ìŒ ë‹¨ê³„

#### Option A: í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (ì¶”ì²œ âœ…)
**ë¸Œëœì¹˜**: `feature/training-pipeline-test`

**ëª©í‘œ**:
1. seg-coco32 ë°ì´í„°ì…‹ Frontendì—ì„œ ì—…ë¡œë“œ
2. Training API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
3. Backend â†” Training Service í†µì‹  ê²€ì¦
4. í•™ìŠµ ì‹œì‘/ì¤‘ì§€/ëª¨ë‹ˆí„°ë§ í™•ì¸
5. MLflow ì—°ë™ í™•ì¸

**Quick Start**:
```bash
# ìƒˆ ë¸Œëœì¹˜ ìƒì„±
git checkout main
git pull
git checkout -b feature/training-pipeline-test

# Backend ì‹œì‘
cd mvp/backend
source venv/bin/activate
uvicorn app.main:app --reload --port 8000

# Frontend ì‹œì‘
cd mvp/frontend
npm run dev

# ë°ì´í„°ì…‹ ì—…ë¡œë“œ
# http://localhost:3000 â†’ ë¡œê·¸ì¸ â†’ ë°ì´í„°ì…‹ â†’ Create
# C:\datasets\dice_format\seg-coco32 í´ë” ì„ íƒ

# í•™ìŠµ ì‹œì‘
# ì±„íŒ…: "seg-coco32 ë°ì´í„°ì…‹ìœ¼ë¡œ yolo11n-seg ëª¨ë¸ í•™ìŠµì‹œì‘"
```

#### Option B: ìŠ¤ëƒ…ìƒ· êµ¬í˜„
**ë¸Œëœì¹˜**: `feature/dataset-snapshots`

**ì‘ì—… ë‚´ìš©**:
- POST `/datasets/{id}/snapshots` API
- í•™ìŠµ ì‹œì‘ ì‹œ ìë™ ìŠ¤ëƒ…ìƒ·
- ìŠ¤ëƒ…ìƒ· ëª©ë¡ UI
- ë²„ì „ ë¹„êµ ë·°

### ê´€ë ¨ ë¬¸ì„œ

- **ìƒíƒœ ë¬¸ì„œ**: [CURRENT_STATUS.md](./datasets/CURRENT_STATUS.md)
- **ì„¤ê³„ ë¬¸ì„œ**: [DATASET_MANAGEMENT_DESIGN.md](./datasets/DATASET_MANAGEMENT_DESIGN.md)
- **êµ¬í˜„ ê³„íš**: [IMPLEMENTATION_PLAN.md](./datasets/IMPLEMENTATION_PLAN.md)
- **í¬ë§· ìŠ¤í™**: [PLATFORM_DATASET_FORMAT.md](./datasets/PLATFORM_DATASET_FORMAT.md)

### ê¸°ìˆ  ë…¸íŠ¸

#### ì¸ì¦ íë¦„
```
User â†’ Frontend (localStorage.getItem('access_token'))
     â†’ Backend API (Authorization: Bearer {token})
     â†’ Depends(get_current_user)
     â†’ JWT ê²€ì¦ ë° User ê°ì²´ ë°˜í™˜
     â†’ ê¶Œí•œ ì²´í¬ (owner_id ë¹„êµ)
```

#### ë°ì´í„°ì…‹ ê¶Œí•œ ê·œì¹™
- **Public datasets**:
  - ëª¨ë“  ì¸ì¦ ì‚¬ìš©ì ì¡°íšŒ ê°€ëŠ¥
  - ì†Œìœ ìë§Œ ìˆ˜ì •/ì‚­ì œ
- **Private datasets**:
  - ì†Œìœ ìë§Œ ì¡°íšŒ/ìˆ˜ì •/ì‚­ì œ
- **ì—…ë¡œë“œ/ì‚­ì œ**:
  - í•­ìƒ ì†Œìœ ìë§Œ ê°€ëŠ¥

#### .gitignore ì—…ë°ì´íŠ¸
ì¶”ê°€ëœ íŒ¨í„´:
- `*.db.backup*` - DB ë°±ì—… íŒŒì¼
- `test_*.py` - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- `convert_*.py` - ë³€í™˜ ìœ í‹¸ë¦¬í‹°
- `migrate_*.py` - ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

### í•µì‹¬ íŒŒì¼

#### Backend
```
mvp/backend/app/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ datasets.py              # âœ… ì¸ì¦ ì¶”ê°€
â”‚   â”œâ”€â”€ datasets_folder.py       # âœ… ì¸ì¦ ì¶”ê°€
â”‚   â”œâ”€â”€ datasets_images.py       # âœ… ì¸ì¦ ì¶”ê°€
â”‚   â””â”€â”€ training.py              # dataset_id ì§€ì›
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ r2_storage.py
â”‚   â””â”€â”€ dependencies.py          # get_current_user
â””â”€â”€ convert_yolo_seg_to_platform.py  # ìƒˆ íŒŒì¼ (gitignore)
```

#### Frontend
```
mvp/frontend/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ DatasetPanel.tsx          # âœ… í† í° ì¶”ê°€
â”‚   â”œâ”€â”€ Sidebar.tsx               # âœ… ì¡°ê±´ë¶€ ë Œë”ë§
â”‚   â”œâ”€â”€ ProjectDetail.tsx         # âœ… í† í° ì¶”ê°€
â”‚   â””â”€â”€ datasets/
â”‚       â”œâ”€â”€ CreateDatasetModal.tsx    # âœ… ë„¤ë¹„ê²Œì´ì…˜ ì œê±°
â”‚       â”œâ”€â”€ DatasetImageUpload.tsx    # âœ… í† í° ì¶”ê°€
â”‚       â””â”€â”€ DatasetImageGallery.tsx   # âœ… í† í° ì¶”ê°€
â””â”€â”€ app/datasets/[id]/page.tsx    # âœ… í† í° ì¶”ê°€
```

#### Documentation
```
docs/datasets/
â”œâ”€â”€ CURRENT_STATUS.md             # ìƒˆ íŒŒì¼ â­
â”œâ”€â”€ DATASET_MANAGEMENT_DESIGN.md
â”œâ”€â”€ IMPLEMENTATION_PLAN.md
â””â”€â”€ PLATFORM_DATASET_FORMAT.md
```

---

## [2025-01-04 13:00] ë°ì´í„°ì…‹ ê´€ë¦¬ UI í†µí•© ë° ì„¤ê³„ ë…¼ì˜

### ë…¼ì˜ ì£¼ì œ
- ë°ì´í„°ì…‹ UI ë ˆì´ì•„ì›ƒ í†µí•© ë¬¸ì œ
- í•˜ë“œì½”ë”© ë°ì´í„° ì œê±°
- ë°ì´í„°ì…‹ ì—…ë¡œë“œ ë°©ì‹ ì„¤ê³„
- ë²„ì „ë‹ ì „ëµ
- ë¬´ê²°ì„± ê´€ë¦¬

### ì£¼ìš” ê²°ì •ì‚¬í•­

#### 1. UI ë ˆì´ì•„ì›ƒ í†µí•©
- **ë¬¸ì œ**: ë°ì´í„°ì…‹ ë²„íŠ¼ í´ë¦­ ì‹œ ì „ì²´ í™”ë©´ìœ¼ë¡œ ë‚˜ì™€ì„œ ê¸°ì¡´ ë ˆì´ì•„ì›ƒ(ì‚¬ì´ë“œë°”, ì±„íŒ…, ì‘ì—…ê³µê°„) ë¬´ì‹œ
- **í•´ê²°**:
  - ìƒˆ `DatasetPanel` ì»´í¬ë„ŒíŠ¸ ìƒì„± (ì»´íŒ©íŠ¸ í…Œì´ë¸” ë””ìì¸)
  - `app/page.tsx`ì— ìƒíƒœ ê´€ë¦¬ ì¶”ê°€
  - Sidebarì—ì„œ ë¼ìš°íŒ… ëŒ€ì‹  í•¸ë“¤ëŸ¬ í˜¸ì¶œ
- **ê²°ê³¼**: AdminProjectsPanelê³¼ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ì‘ì—…ê³µê°„ì— í†µí•©

#### 2. í•˜ë“œì½”ë”© ë°ì´í„° ì œê±°
- **ë¬¸ì œ**: DBì— 6ê°œ ìƒ˜í”Œ ë°ì´í„°ì…‹ í•˜ë“œì½”ë”©ë¨ (cls-imagenet-10 ë“±)
- **ì›ì¹™ ìœ„ë°˜**: CLAUDE.md - "no shortcut, no hardcoding, no dummy data"
- **í•´ê²°**: DBì—ì„œ ëª¨ë“  ìƒ˜í”Œ ë°ì´í„° ì‚­ì œ
- **ê²°ê³¼**: ì‹¤ì œ ì—…ë¡œë“œí•œ ë°ì´í„°ë§Œ í‘œì‹œ

#### 3. task_typeì€ ë°ì´í„°ì…‹ ì†ì„±ì´ ì•„ë‹ˆë‹¤
- **í•µì‹¬ í†µì°°**: ê°™ì€ ì´ë¯¸ì§€ë¥¼ classification, detection, segmentation ë“± ë‹¤ì–‘í•˜ê²Œ í™œìš© ê°€ëŠ¥
- **ê²°ì •**:
  - âŒ Dataset.task_type ì‚­ì œ
  - âœ… TrainingJob.task_type ì¶”ê°€
  - ë°ì´í„°ì…‹ì€ ì´ë¯¸ì§€ ì €ì¥ì†Œ, í•™ìŠµ ì‘ì—…ì´ ìš©ë„ ê²°ì •

#### 4. í´ë” êµ¬ì¡° ìœ ì§€
- **ê²°ì •**: ì—…ë¡œë“œ ì‹œ í´ë” êµ¬ì¡° í•­ìƒ ìœ ì§€
- **R2 ê²½ë¡œ**: `datasets/{id}/images/{original_path}`
- **ì´ìœ **:
  - ì›ë³¸ êµ¬ì¡° ë³´ì¡´
  - íŒŒì¼ëª… ì¶©ëŒ ë°©ì§€
  - ìœ ì—°ì„± í™•ë³´

#### 5. labeledì˜ ì •ì˜
- **ì •ì˜**: `labeled = annotation.json ì¡´ì¬ ì—¬ë¶€`
- **ê·œì¹™**:
  - labeled ì—…ë¡œë“œëŠ” í´ë”ë§Œ ê°€ëŠ¥ (annotation.json í•„ìš”)
  - unlabeledëŠ” í´ë”/ê°œë³„ íŒŒì¼ ëª¨ë‘ ê°€ëŠ¥
  - labeled ë°ì´í„°ì…‹ì— labeled í´ë” ë³‘í•© **ê¸ˆì§€**

#### 6. meta.json ìƒì„± ì‹œì 
- **unlabeled**: meta.json ì—†ìŒ (DBë§Œ)
- **labeled ì „í™˜**: annotation.json + meta.json í•¨ê»˜ ìƒì„±
- **export**: í•­ìƒ meta.json í¬í•¨
- **Single Source of Truth**: DB

#### 7. ë²„ì „ë‹ ì „ëµ: Mutable + Snapshot
- **ì›ì¹™**:
  - ë°ì´í„°ì…‹ì€ ê¸°ë³¸ì ìœ¼ë¡œ ê°€ë³€(mutable)
  - í•™ìŠµ ì‹œì‘ ì‹œ ìë™ ìŠ¤ëƒ…ìƒ· ìƒì„±
  - ì‚¬ìš©ìê°€ ëª…ì‹œì  ë²„ì „ ìƒì„± ê°€ëŠ¥ (v1, v2...)
- **íš¨ìœ¨ì„±**:
  - ì´ë¯¸ì§€ëŠ” ëª¨ë“  ë²„ì „ì´ ê³µìœ 
  - ìŠ¤ëƒ…ìƒ·ì€ annotation.jsonë§Œ ì €ì¥
  - ì €ì¥ ê³µê°„ 99% ì ˆì•½ (10GB + 10MB + 10MB vs 30GB)

#### 8. ì´ë¯¸ì§€ ì‚­ì œ í—ˆìš© + ë¬´ê²°ì„± ê´€ë¦¬
- **ì´ë¯¸ì§€ ì‚­ì œ**: í—ˆìš©
- **ì˜í–¥ë°›ëŠ” ìŠ¤ëƒ…ìƒ· ì²˜ë¦¬**:
  - ì˜µì…˜ A: Broken í‘œì‹œ (ì¬í˜„ ë¶ˆê°€)
  - ì˜µì…˜ B: ìë™ ë³µêµ¬ (annotation ìˆ˜ì •)
- **ì£¼ê¸°ì  ë¬´ê²°ì„± ì²´í¬**: Celery taskë¡œ êµ¬í˜„

### êµ¬í˜„ ë‚´ìš©

#### Frontend
- `components/DatasetPanel.tsx`: ì»´íŒ©íŠ¸ í…Œì´ë¸” UI (ìƒˆ íŒŒì¼)
  - ê²€ìƒ‰, ì •ë ¬ ê¸°ëŠ¥
  - í™•ì¥ ê°€ëŠ¥í•œ í–‰ (ì´ë¯¸ì§€ ê°¤ëŸ¬ë¦¬)
  - ì´ë¯¸ì§€ ì—…ë¡œë“œ/ì¡°íšŒ

- `app/page.tsx`: ìƒíƒœ ê´€ë¦¬ ì¶”ê°€
  - `showDatasets` state
  - `handleOpenDatasets()` í•¸ë“¤ëŸ¬
  - ì‘ì—…ê³µê°„ì— DatasetPanel ë Œë”ë§

- `components/Sidebar.tsx`: ë¼ìš°íŒ… ì œê±°
  - `router.push('/datasets')` â†’ `onOpenDatasets()` í˜¸ì¶œ

#### Backend
- ê¸°ì¡´ ê°œë³„ ì´ë¯¸ì§€ ì—…ë¡œë“œ API ìœ ì§€
  - POST `/datasets/{id}/images`
  - GET `/datasets/{id}/images`

#### Database
- í•˜ë“œì½”ë”©ëœ 6ê°œ ìƒ˜í”Œ ë°ì´í„°ì…‹ ì‚­ì œ

### ê´€ë ¨ ë¬¸ì„œ

- **ì„¤ê³„ ë¬¸ì„œ**: [DATASET_MANAGEMENT_DESIGN.md](./datasets/DATASET_MANAGEMENT_DESIGN.md)
  - ë°ì´í„° ëª¨ë¸
  - ìŠ¤í† ë¦¬ì§€ êµ¬ì¡°
  - 12ê°€ì§€ ì—…ë¡œë“œ ì‹œë‚˜ë¦¬ì˜¤
  - ë²„ì „ë‹ ì „ëµ
  - ë¬´ê²°ì„± ê´€ë¦¬

- **ê¸°ì¡´ ë¬¸ì„œ**:
  - [DICE_FORMAT_v2.md](./datasets/DICE_FORMAT_v2.md)
  - [STORAGE_ACCESS_PATTERNS.md](./datasets/STORAGE_ACCESS_PATTERNS.md)

### ë‹¤ìŒ ë‹¨ê³„

#### Phase 2: í´ë” ì—…ë¡œë“œ (ë‹¤ìŒ êµ¬í˜„)
- [ ] í´ë” êµ¬ì¡° ìœ ì§€ ì—…ë¡œë“œ (`webkitdirectory`)
- [ ] labeled ë°ì´í„°ì…‹ ìƒì„± (annotation.json í¬í•¨)
- [ ] DB ëª¨ë¸ í™•ì¥ (labeled, class_names, is_snapshot ë“±)

#### Phase 3: ë²„ì „ë‹
- [ ] í•™ìŠµ ì‹œ ìë™ ìŠ¤ëƒ…ìƒ·
- [ ] ëª…ì‹œì  ë²„ì „ ìƒì„±
- [ ] ìŠ¤ëƒ…ìƒ· ëª©ë¡ UI

#### Phase 4: ë¬´ê²°ì„± ê´€ë¦¬
- [ ] ì´ë¯¸ì§€ ì‚­ì œ ì‹œ ì˜í–¥ ë¶„ì„
- [ ] Broken/ë³µêµ¬ ë¡œì§
- [ ] ì£¼ê¸°ì  ë¬´ê²°ì„± ì²´í¬

### ê¸°ìˆ  ìŠ¤íƒ
- Frontend: Next.js 14, TypeScript, Tailwind CSS
- Backend: FastAPI, Python, SQLAlchemy
- Storage: Cloudflare R2 (S3-compatible)
- Database: SQLite (local), PostgreSQL (production)

### í•µì‹¬ íŒŒì¼
- `mvp/frontend/components/DatasetPanel.tsx` (ìƒˆë¡œ ìƒì„±)
- `mvp/frontend/app/page.tsx` (ìˆ˜ì •)
- `mvp/frontend/components/Sidebar.tsx` (ìˆ˜ì •)
- `mvp/backend/app/api/datasets_images.py` (ê¸°ì¡´)
- `mvp/backend/app/utils/r2_storage.py` (ê¸°ì¡´)

---

