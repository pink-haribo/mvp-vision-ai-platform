# ClearML Migration Plan

**ì‘ì„±ì¼**: 2025-11-27
**ì—…ë°ì´íŠ¸**: 2025-11-27 (Temporal Workflow í†µí•©)
**ëª©í‘œ**: MLflowì—ì„œ ClearMLë¡œ ì™„ì „ ì „í™˜í•˜ì—¬ ë” ê°•ë ¥í•œ MLOps í”Œë«í¼ êµ¬ì¶•

**âš ï¸ IMPORTANT**: ì´ ë§ˆì´ê·¸ë ˆì´ì…˜ì€ **Temporal Workflowì™€ í•¨ê»˜** ì§„í–‰ë©ë‹ˆë‹¤.
ClearML Task ìƒì„±ì€ Temporal Activityì—ì„œ ìˆ˜í–‰ë˜ë©°, ê¸°ì¡´ Backend API ì§ì ‘ í˜¸ì¶œ ë°©ì‹ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

---

## ğŸ“‹ Executive Summary

### Why ClearML?

**MLflowì˜ í•œê³„**:
- ì œí•œì ì¸ ì‹¤í—˜ ë¹„êµ ê¸°ëŠ¥
- UI/UXê°€ ë°ì´í„° ê³¼í•™ì ì¤‘ì‹¬ (ì—”ì§€ë‹ˆì–´ë§ íŒ€ì—ê²Œ ë¶ˆì¹œì ˆ)
- ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê¸°ëŠ¥ ë¶€ì¡±
- ë¶„ì‚° í•™ìŠµ ì§€ì› ë¯¸í¡
- íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì—†ìŒ

**ClearMLì˜ ì¥ì **:
- ğŸ¯ **ì™„ì „í•œ ì‹¤í—˜ ì¶”ì **: ìë™ Git/dependency ì¶”ì , í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¹„êµ
- ğŸš€ **ê°•ë ¥í•œ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬**: ëª¨ë¸ ë²„ì „ ê´€ë¦¬, ë©”íƒ€ë°ì´í„°, lineage ì¶”ì 
- ğŸ“Š **í’ë¶€í•œ ì‹œê°í™”**: ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­, ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ë¡œê¹…, ì»¤ìŠ¤í…€ í”Œë¡¯
- ğŸ”„ **íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: ClearML Pipelinesë¡œ ML workflow ìë™í™”
- ğŸŒ **ë©€í‹° í´ë¼ìš°ë“œ/í•˜ì´ë¸Œë¦¬ë“œ**: ì˜¨í”„ë ˆë¯¸ìŠ¤ + í´ë¼ìš°ë“œ ë™ì‹œ ì§€ì›
- ğŸ¨ **ì§ê´€ì ì¸ UI**: ì—”ì§€ë‹ˆì–´ì™€ ë°ì´í„° ê³¼í•™ì ëª¨ë‘ë¥¼ ìœ„í•œ ì„¤ê³„
- ğŸ”Œ **ì˜¤í”ˆì†ŒìŠ¤ + ì—”í„°í”„ë¼ì´ì¦ˆ**: Self-hosted ê°€ëŠ¥, ìƒìš© ê¸°ëŠ¥ í™•ì¥ ê°€ëŠ¥

---

## ğŸ¯ Migration Goals

### Primary Objectives
1. âœ… **Zero Data Loss**: ëª¨ë“  ê¸°ì¡´ MLflow ì‹¤í—˜ ë°ì´í„°ë¥¼ ClearMLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
2. âœ… **Zero Downtime**: ë‹¨ê³„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì—†ìŒ
3. âœ… **Enhanced Features**: ClearMLì˜ ê³ ê¸‰ ê¸°ëŠ¥ í™œìš© (ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, íŒŒì´í”„ë¼ì¸)

### Success Metrics
- ëª¨ë“  Training/Inference/Export Jobì´ ClearML Taskë¡œ ì¶”ì ë¨
- ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ (<5ì´ˆ ì§€ì—°)
- Checkpoint ìë™ ì—…ë¡œë“œ (100% ì„±ê³µë¥ )
- ì‚¬ìš©ì ë§Œì¡±ë„ ì¦ê°€ (ë” ë‚˜ì€ UI/UX)

---

## ğŸ—ï¸ ClearML Architecture

### Components

```
ClearML Server (Self-hosted)
â”œâ”€â”€ API Server (port 8008)       - REST API for Task management
â”œâ”€â”€ Web UI (port 8080)            - User interface
â”œâ”€â”€ File Server (port 8081)       - Artifact storage
â”œâ”€â”€ PostgreSQL                    - Metadata storage
â”œâ”€â”€ MongoDB                       - Experiment data
â””â”€â”€ Elasticsearch                 - Search and analytics
```

### Integration with Platform

**âš ï¸ UPDATED**: Temporal Workflow í†µí•©

```
Training Job (API Request)
    â†“
Temporal Workflow (orchestration)
    â†“
Activity: create_clearml_task  â† ClearML Task ìƒì„±
    â†“
Activity: execute_training
    â†“
TrainingManager (Subprocess/K8s)
    â†“
Trainer Container
    â†“
Training SDK (Task.current_task() + metrics logging)
    â†“
ClearML Server (stores and displays)
    â†“
Web UI / API (query and visualize)
```

**Key Changes from Original Plan**:
1. **ClearML Task ìƒì„±**: Backend API â†’ Temporal Activity
2. **Training ì‹¤í–‰**: TrainingManagerë¥¼ Temporal Activityì—ì„œ í˜¸ì¶œ
3. **Metrics ë¡œê¹…**: SDK â†’ ClearML (ê¸°ì¡´ê³¼ ë™ì¼)
4. **Workflow ê´€ë¦¬**: Temporalì´ timeout, retry, heartbeat ëª¨ë‘ ì²˜ë¦¬

---

## ğŸ“… Migration Phases

### Phase 1: ClearML Setup (Day 1-2)

**Goal**: ClearML Server ë°°í¬ ë° ê¸°ë³¸ êµ¬ì„±

#### 1.1 Local Development (Docker Compose)

```yaml
# infrastructure/docker-compose.tier0.yaml ì—…ë°ì´íŠ¸
services:
  clearml-apiserver:
    image: allegroai/clearml:latest
    container_name: clearml-apiserver
    restart: unless-stopped
    volumes:
      - C:/platform-data/clearml/logs:/var/log/clearml
      - C:/platform-data/clearml/config:/opt/clearml/config
    depends_on:
      - postgres
      - mongo
      - elasticsearch
    environment:
      CLEARML_HOST_IP: localhost
      CLEARML_WEB_HOST: http://localhost:8080
      CLEARML_API_HOST: http://localhost:8008
      CLEARML_FILES_HOST: http://localhost:8081
    ports:
      - "8008:8008"

  clearml-webserver:
    image: allegroai/clearml:latest
    container_name: clearml-webserver
    restart: unless-stopped
    depends_on:
      - clearml-apiserver
    environment:
      CLEARML_SERVER_API_HOST: http://clearml-apiserver:8008
    ports:
      - "8080:80"

  clearml-fileserver:
    image: allegroai/clearml:latest
    container_name: clearml-fileserver
    restart: unless-stopped
    volumes:
      - C:/platform-data/clearml/fileserver:/mnt/fileserver
    ports:
      - "8081:8081"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.9
    container_name: clearml-elastic
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - C:/platform-data/clearml/elasticsearch:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"

  mongo:
    image: mongo:7.0
    container_name: clearml-mongo
    restart: unless-stopped
    volumes:
      - C:/platform-data/clearml/mongo:/data/db
    ports:
      - "27018:27017"  # Avoid conflict with existing MongoDB
```

**Configuration**:
```bash
# platform/backend/.env ì—…ë°ì´íŠ¸
CLEARML_API_HOST=http://localhost:8008
CLEARML_WEB_HOST=http://localhost:8080
CLEARML_FILES_HOST=http://localhost:8081
CLEARML_API_ACCESS_KEY=<generated-key>
CLEARML_API_SECRET_KEY=<generated-secret>
```

#### 1.2 Kind Kubernetes

```yaml
# infrastructure/kind/clearml/values.yaml
clearml:
  apiserver:
    service:
      type: LoadBalancer
      port: 8008
  webserver:
    service:
      type: LoadBalancer
      port: 8080
  fileserver:
    service:
      type: LoadBalancer
      port: 8081

  elasticsearch:
    enabled: true
    volumeClaimTemplate:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi

  mongodb:
    enabled: true
    persistence:
      size: 10Gi
```

```bash
# ë°°í¬
helm repo add allegroai https://allegroai.github.io/clearml-helm-charts
helm install clearml allegroai/clearml -f infrastructure/kind/clearml/values.yaml -n platform
```

#### 1.3 Access Configuration

```bash
# ClearML Web UI ì ‘ì†
http://localhost:8080

# API í‚¤ ìƒì„±
1. Web UI ë¡œê·¸ì¸ (admin/admin)
2. Settings â†’ Workspace â†’ Create new credentials
3. Access Key + Secret Key ë³µì‚¬
4. .envì— ì„¤ì •
```

**Checklist**:
- [ ] Docker Composeë¡œ ClearML Server ì‹¤í–‰
- [ ] Web UI ì ‘ì† í™•ì¸ (http://localhost:8080)
- [ ] API í‚¤ ìƒì„± ë° .env ì„¤ì •
- [ ] Kindì— ClearML Helm chart ë°°í¬
- [ ] Health check í™•ì¸

---

### Phase 2: ClearMLService Implementation (Day 2-3)

**Goal**: Backend ClearML ì„œë¹„ìŠ¤ êµ¬í˜„

#### 2.1 Service Class

```python
# platform/backend/app/services/clearml_service.py
from typing import Optional, Dict, List, Any
from clearml import Task, Model
from sqlalchemy.orm import Session
from app.db import models
from app.core.config import settings

class ClearMLService:
    """ClearML integration service for experiment tracking"""

    def __init__(self, db: Session):
        self.db = db
        self.api_host = settings.CLEARML_API_HOST
        self.web_host = settings.CLEARML_WEB_HOST
        self.files_host = settings.CLEARML_FILES_HOST

    def create_task(
        self,
        job_id: int,
        task_name: str,
        task_type: str,
        project_name: str = "Platform Training"
    ) -> Optional[str]:
        """Create ClearML task for training job"""
        try:
            task = Task.init(
                project_name=project_name,
                task_name=task_name,
                task_type=task_type,  # 'training', 'testing', 'inference', 'data_processing'
                reuse_last_task_id=False,
                auto_connect_frameworks=False  # Manual logging for full control
            )

            # Store task ID in database
            job = self.db.query(models.TrainingJob).filter(
                models.TrainingJob.id == job_id
            ).first()
            if job:
                job.clearml_task_id = task.id
                self.db.commit()

            return task.id
        except Exception as e:
            print(f"Failed to create ClearML task: {e}")
            return None

    def get_task(self, task_id: str) -> Optional[Task]:
        """Get ClearML task by ID"""
        try:
            return Task.get_task(task_id=task_id)
        except Exception as e:
            print(f"Failed to get ClearML task: {e}")
            return None

    def log_metrics(
        self,
        task_id: str,
        metrics: Dict[str, float],
        iteration: int
    ):
        """Log metrics to ClearML task"""
        try:
            task = self.get_task(task_id)
            if task:
                for metric_name, value in metrics.items():
                    # Parse metric name (e.g., "train/loss" -> series="train", title="loss")
                    parts = metric_name.split('/')
                    if len(parts) == 2:
                        series, title = parts
                    else:
                        series = "metrics"
                        title = metric_name

                    task.logger.report_scalar(
                        title=title,
                        series=series,
                        value=value,
                        iteration=iteration
                    )
        except Exception as e:
            print(f"Failed to log metrics: {e}")

    def upload_artifact(
        self,
        task_id: str,
        artifact_name: str,
        artifact_object: Any,
        metadata: Optional[Dict] = None
    ):
        """Upload artifact (checkpoint, model, etc.)"""
        try:
            task = self.get_task(task_id)
            if task:
                task.upload_artifact(
                    name=artifact_name,
                    artifact_object=artifact_object,
                    metadata=metadata
                )
        except Exception as e:
            print(f"Failed to upload artifact: {e}")

    def mark_completed(self, task_id: str, status: str = "completed"):
        """Mark task as completed"""
        try:
            task = self.get_task(task_id)
            if task:
                task.mark_completed()
        except Exception as e:
            print(f"Failed to mark task completed: {e}")

    def mark_failed(self, task_id: str, status_reason: str):
        """Mark task as failed"""
        try:
            task = self.get_task(task_id)
            if task:
                task.mark_failed(status_reason=status_reason)
        except Exception as e:
            print(f"Failed to mark task failed: {e}")

    def get_task_metrics(self, task_id: str) -> Dict[str, List]:
        """Get all metrics from task"""
        try:
            task = self.get_task(task_id)
            if task:
                metrics = task.get_last_scalar_metrics()
                return metrics
            return {}
        except Exception as e:
            print(f"Failed to get task metrics: {e}")
            return {}

    def register_model(
        self,
        task_id: str,
        model_path: str,
        model_name: str,
        tags: Optional[List[str]] = None
    ) -> Optional[str]:
        """Register model in ClearML Model Repository"""
        try:
            task = self.get_task(task_id)
            if task:
                output_model = Model(
                    task=task,
                    name=model_name,
                    tags=tags or [],
                    framework="PyTorch"  # or detect automatically
                )
                output_model.update_weights(
                    weights_filename=model_path,
                    auto_delete_file=False
                )
                return output_model.id
            return None
        except Exception as e:
            print(f"Failed to register model: {e}")
            return None
```

**Checklist**:
- [ ] ClearMLService í´ë˜ìŠ¤ êµ¬í˜„
- [ ] Task ìƒì„±/ì¡°íšŒ ë©”ì„œë“œ
- [ ] Metrics ë¡œê¹… ë©”ì„œë“œ
- [ ] Artifact ì—…ë¡œë“œ ë©”ì„œë“œ
- [ ] Model registration ë©”ì„œë“œ
- [ ] Unit tests ì‘ì„±

#### 2.2 Database Schema Update

```python
# Migration: add clearml_task_id column
def upgrade():
    op.add_column('training_jobs', sa.Column('clearml_task_id', sa.String(255), nullable=True))
    op.add_column('inference_jobs', sa.Column('clearml_task_id', sa.String(255), nullable=True))
    op.add_column('export_jobs', sa.Column('clearml_task_id', sa.String(255), nullable=True))

    # Add index for faster lookups
    op.create_index('ix_training_jobs_clearml_task_id', 'training_jobs', ['clearml_task_id'])
    op.create_index('ix_inference_jobs_clearml_task_id', 'inference_jobs', ['clearml_task_id'])
    op.create_index('ix_export_jobs_clearml_task_id', 'export_jobs', ['clearml_task_id'])

def downgrade():
    op.drop_index('ix_export_jobs_clearml_task_id', 'export_jobs')
    op.drop_index('ix_inference_jobs_clearml_task_id', 'inference_jobs')
    op.drop_index('ix_training_jobs_clearml_task_id', 'training_jobs')

    op.drop_column('export_jobs', 'clearml_task_id')
    op.drop_column('inference_jobs', 'clearml_task_id')
    op.drop_column('training_jobs', 'clearml_task_id')
```

**Checklist**:
- [ ] Migration script ì‘ì„±
- [ ] í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ migration ì‹¤í–‰
- [ ] ë¡¤ë°± í…ŒìŠ¤íŠ¸
- [ ] Production migration ê³„íš

---

### Phase 3: Backend API Migration (Day 4-5)

**Goal**: MLflowServiceë¥¼ ClearMLServiceë¡œ êµì²´

#### 3.1 Training API Updates

```python
# platform/backend/app/api/training.py (Before)
from app.utils.mlflow_client import get_mlflow_client

@router.get("/jobs/{job_id}")
def get_training_job(job_id: int, db: Session = Depends(get_db)):
    job = db.query(models.TrainingJob).filter(models.TrainingJob.id == job_id).first()
    if not job:
        raise HTTPException(404)

    # Get MLflow metrics
    mlflow_client = get_mlflow_client()
    mlflow_run = mlflow_client.get_run_by_job_id(job_id)
    # ...

# platform/backend/app/api/training.py (After)
from app.services.clearml_service import ClearMLService

@router.get("/jobs/{job_id}")
def get_training_job(job_id: int, db: Session = Depends(get_db)):
    job = db.query(models.TrainingJob).filter(models.TrainingJob.id == job_id).first()
    if not job:
        raise HTTPException(404)

    # Get ClearML metrics
    clearml_service = ClearMLService(db)
    if job.clearml_task_id:
        metrics = clearml_service.get_task_metrics(job.clearml_task_id)
    # ...
```

**ë³€ê²½ ìœ„ì¹˜**:
1. `get_training_job()` - Line ~332
2. `get_mlflow_metrics()` â†’ `get_clearml_metrics()` - Line ~834
3. `get_mlflow_summary()` â†’ `get_clearml_summary()` - Line ~864
4. Training job ìƒì„± ì‹œ ClearML Task ìƒì„±

#### 3.2 Experiments API Updates

```python
# platform/backend/app/api/experiments.py
# MLflow Experiment â†’ ClearML Project ë§¤í•‘

@router.post("/experiments")
def create_experiment(
    request: schemas.ExperimentCreate,
    db: Session = Depends(get_db),
    current_user: models.User = Depends(get_current_user)
):
    # Create ClearML project (replaces MLflow experiment)
    clearml_service = ClearMLService(db)
    project_id = clearml_service.create_project(
        project_name=request.name,
        description=request.description
    )

    experiment = models.Experiment(
        name=request.name,
        description=request.description,
        clearml_project_id=project_id,  # Was: mlflow_experiment_id
        created_by=current_user.id
    )
    db.add(experiment)
    db.commit()
    return experiment
```

**Checklist**:
- [ ] `training.py` 4ê³³ ì—…ë°ì´íŠ¸
- [ ] `experiments.py` ClearML Project ì—°ë™
- [ ] API response schema ì—…ë°ì´íŠ¸
- [ ] Integration tests ì—…ë°ì´íŠ¸

---

### Phase 4: Training SDK Updates (Day 6)

**Goal**: Trainerì—ì„œ ClearML Task ì‚¬ìš©

#### 4.1 SDK Metrics Logging

```python
# platform/trainers/ultralytics/trainer_sdk.py (Before)
def report_progress(self, epoch: int, total_epochs: int, metrics: TrainingCallbackMetrics):
    """Report training progress to backend"""
    # Callback to backend
    callback_data = {
        "operation_type": "training",
        "epoch": epoch,
        "total_epochs": total_epochs,
        "metrics": metrics.dict()
    }
    response = self.http_client.post(
        f"{self.callback_url}/progress",
        json=callback_data
    )

# platform/trainers/ultralytics/trainer_sdk.py (After)
from clearml import Task

def report_progress(self, epoch: int, total_epochs: int, metrics: TrainingCallbackMetrics):
    """Report training progress to backend and ClearML"""
    # Callback to backend (for DB update, WebSocket)
    callback_data = {
        "operation_type": "training",
        "epoch": epoch,
        "total_epochs": total_epochs,
        "metrics": metrics.dict()
    }
    response = self.http_client.post(
        f"{self.callback_url}/progress",
        json=callback_data
    )

    # Log to ClearML (if task exists)
    task = Task.current_task()
    if task:
        for metric_name, value in metrics.dict().items():
            if value is not None:
                # Parse metric name (e.g., "train_loss" -> series="train", title="loss")
                if "_" in metric_name:
                    series, title = metric_name.split("_", 1)
                else:
                    series = "metrics"
                    title = metric_name

                task.logger.report_scalar(
                    title=title,
                    series=series,
                    value=value,
                    iteration=epoch
                )
```

#### 4.2 Checkpoint Upload

```python
# platform/trainers/ultralytics/trainer_sdk.py
def upload_checkpoint(self, local_path: str, checkpoint_type: str, is_best: bool = False):
    """Upload checkpoint to S3 and register in ClearML"""
    # 1. Upload to S3 (existing logic)
    s3_key = f"checkpoints/{self.job_id}/{checkpoint_type}.pt"
    self.internal_storage.upload_file(local_path, s3_key)

    # 2. Register in ClearML
    task = Task.current_task()
    if task:
        task.upload_artifact(
            name=f"checkpoint_{checkpoint_type}",
            artifact_object=local_path,
            metadata={
                "checkpoint_type": checkpoint_type,
                "is_best": is_best,
                "s3_key": s3_key
            }
        )

        # If best checkpoint, register as output model
        if is_best:
            from clearml import Model
            output_model = Model(task=task)
            output_model.update_weights(weights_filename=local_path)

    # 3. Callback to backend
    # ... (existing callback logic)
```

**Checklist**:
- [ ] SDKì— ClearML Task í†µí•©
- [ ] Metrics logging êµ¬í˜„
- [ ] Checkpoint upload êµ¬í˜„
- [ ] Model registration êµ¬í˜„
- [ ] train.pyì—ì„œ Task.init() í˜¸ì¶œ ì¶”ê°€

#### 4.3 Trainer Script Update

```python
# platform/trainers/ultralytics/train.py
from clearml import Task
from trainer_sdk import TrainerSDK

def main():
    sdk = TrainerSDK()

    # Initialize ClearML Task
    task = Task.init(
        project_name=f"Project {sdk.project_id}",
        task_name=f"Training Job {sdk.job_id}",
        task_type=Task.TaskTypes.training,
        reuse_last_task_id=False
    )

    # Connect configuration
    task.connect_configuration(sdk.get_full_config())

    # Training loop
    for epoch in range(total_epochs):
        # ... training logic ...

        # Report progress (to backend + ClearML)
        sdk.report_progress(epoch, total_epochs, metrics)

    # Complete
    sdk.report_completed(...)
    task.mark_completed()
```

---

### Phase 5: MLflow Data Migration (Day 7)

**Goal**: ê¸°ì¡´ MLflow ë°ì´í„°ë¥¼ ClearMLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

#### 5.1 Migration Script

```python
# scripts/clearml/migrate_mlflow_to_clearml.py
import mlflow
from clearml import Task
from sqlalchemy.orm import Session
from app.db.database import SessionLocal
from app.db import models

def migrate_training_job(job: models.TrainingJob, db: Session):
    """Migrate single training job from MLflow to ClearML"""
    print(f"Migrating Job {job.id}...")

    # 1. Get MLflow run
    if not job.mlflow_run_id:
        print(f"  No MLflow run for Job {job.id}, skipping")
        return

    mlflow_client = mlflow.tracking.MlflowClient()
    try:
        run = mlflow_client.get_run(job.mlflow_run_id)
    except Exception as e:
        print(f"  Failed to get MLflow run: {e}")
        return

    # 2. Create ClearML task
    task = Task.create(
        project_name=f"Project {job.project_id}",
        task_name=f"Training Job {job.id} (Migrated)",
        task_type=Task.TaskTypes.training
    )

    # 3. Migrate metrics
    metrics = mlflow_client.get_metric_history(run.info.run_id, "train/loss")
    for metric in metrics:
        task.logger.report_scalar(
            title="loss",
            series="train",
            value=metric.value,
            iteration=metric.step
        )

    # 4. Migrate artifacts (checkpoints)
    artifacts = mlflow_client.list_artifacts(run.info.run_id)
    for artifact in artifacts:
        local_path = mlflow_client.download_artifacts(run.info.run_id, artifact.path)
        task.upload_artifact(
            name=artifact.path,
            artifact_object=local_path
        )

    # 5. Update database
    job.clearml_task_id = task.id
    db.commit()

    # 6. Mark task as completed
    task.mark_completed()

    print(f"  âœ“ Migrated to ClearML Task {task.id}")

def main():
    db = SessionLocal()

    # Get all training jobs with MLflow runs
    jobs = db.query(models.TrainingJob).filter(
        models.TrainingJob.mlflow_run_id.isnot(None)
    ).all()

    print(f"Found {len(jobs)} jobs to migrate")

    for job in jobs:
        try:
            migrate_training_job(job, db)
        except Exception as e:
            print(f"  âœ— Failed to migrate Job {job.id}: {e}")
            continue

    db.close()
    print("\nMigration complete!")

if __name__ == "__main__":
    main()
```

**Checklist**:
- [ ] Migration script ì‘ì„±
- [ ] í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ì‹¤í–‰
- [ ] ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
- [ ] Production migration ì‹¤í–‰

---

### Phase 6: Frontend Updates (Day 8)

**Goal**: ClearML Web UI í†µí•©

#### 6.1 Embedded ClearML UI

```typescript
// platform/frontend/components/training/ClearMLPanel.tsx
import { useState, useEffect } from 'react';

interface ClearMLPanelProps {
  taskId: string;
}

export function ClearMLPanel({ taskId }: ClearMLPanelProps) {
  const clearmlWebHost = process.env.NEXT_PUBLIC_CLEARML_WEB_HOST || 'http://localhost:8080';
  const iframeUrl = `${clearmlWebHost}/projects/*/experiments/${taskId}`;

  return (
    <div className="clearml-panel h-full">
      <iframe
        src={iframeUrl}
        className="w-full h-full border-0"
        title="ClearML Task View"
      />
    </div>
  );
}
```

#### 6.2 Metrics Chart Update

```typescript
// platform/frontend/components/training/MetricsChart.tsx
// Replace MLflow metrics API with ClearML API

const fetchMetrics = async (taskId: string) => {
  const response = await fetch(`/api/v1/training/clearml/${taskId}/metrics`);
  const data = await response.json();

  // Transform ClearML metrics format to chart format
  // ...
};
```

**Checklist**:
- [ ] ClearMLPanel ì»´í¬ë„ŒíŠ¸ ìƒì„±
- [ ] TrainingPanelì— ClearML UI íƒ­ ì¶”ê°€
- [ ] Metrics chart ClearML API ì—°ë™
- [ ] Experiment í˜ì´ì§€ UI ì—…ë°ì´íŠ¸

---

### Phase 7: MLflow Cleanup (Day 9)

**Goal**: MLflow ì™„ì „íˆ ì œê±°

#### 7.1 Code Removal

```bash
# Remove MLflow files
rm platform/backend/app/utils/mlflow_client.py
rm platform/backend/app/services/mlflow_service.py

# Update imports
grep -r "mlflow" platform/backend/app/ --include="*.py" | cut -d: -f1 | sort -u
# Manually review and remove each import
```

#### 7.2 Infrastructure Cleanup

```yaml
# infrastructure/docker-compose.tier0.yaml
# Remove MLflow service
services:
  # mlflow:  # REMOVE THIS
  #   image: ghcr.io/mlflow/mlflow:v2.9.2
  #   ...
```

```bash
# Kind cleanup
kubectl delete deployment mlflow -n platform
kubectl delete service mlflow -n platform
```

#### 7.3 Database Cleanup

```python
# Migration: remove mlflow columns
def upgrade():
    # Keep columns for backward compatibility, but mark as deprecated
    # Can be removed in future version after all data migrated
    pass

def downgrade():
    pass
```

**Checklist**:
- [ ] MLflow ì½”ë“œ íŒŒì¼ ì œê±°
- [ ] Import ì •ë¦¬
- [ ] Docker Composeì—ì„œ MLflow ì œê±°
- [ ] Kindì—ì„œ MLflow ì œê±°
- [ ] í™˜ê²½ë³€ìˆ˜ ì •ë¦¬

---

## ğŸ§ª Testing Strategy

### Unit Tests
- [ ] ClearMLService ëª¨ë“  ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
- [ ] Task ìƒì„±/ì¡°íšŒ/ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸
- [ ] Metrics logging í…ŒìŠ¤íŠ¸
- [ ] Artifact upload í…ŒìŠ¤íŠ¸

### Integration Tests
- [ ] Training lifecycle with ClearML (create â†’ progress â†’ complete)
- [ ] Inference job ClearML í†µí•©
- [ ] Export job ClearML í†µí•©
- [ ] Callback endpoint ClearML ì—°ë™

### E2E Tests
- [ ] Complete training flow
- [ ] Metrics visualization in ClearML Web UI
- [ ] Checkpoint download from ClearML
- [ ] Model registration and deployment

### Performance Tests
- [ ] ClearML API response time (<100ms)
- [ ] Metrics logging latency (<50ms)
- [ ] Artifact upload speed (>10MB/s)

---

## ğŸ“Š Rollback Plan

### If Migration Fails

**Immediate Rollback**:
```bash
# 1. Revert code changes
git revert <migration-commit-hash>

# 2. Restore MLflow service
docker-compose -f infrastructure/docker-compose.tier0.yaml up -d mlflow

# 3. Database rollback
alembic downgrade -1

# 4. Restart backend
docker-compose restart backend
```

**Data Recovery**:
- MLflow dataëŠ” ì‚­ì œí•˜ì§€ ì•Šê³  ë³´ê´€ (ìµœì†Œ 3ê°œì›”)
- ClearML ì‹¤íŒ¨ ì‹œ MLflowë¡œ í´ë°± ê°€ëŠ¥
- Dual-write ê¸°ê°„ ë™ì•ˆ ë‘ ì‹œìŠ¤í…œ ëª¨ë‘ ë°ì´í„° ê¸°ë¡

---

## ğŸ“‹ Success Criteria Checklist

### Infrastructure
- [ ] ClearML Server ì•ˆì •ì ìœ¼ë¡œ ì‹¤í–‰ (99.9% uptime)
- [ ] Web UI ì ‘ê·¼ ê°€ëŠ¥ (<500ms ë¡œë”©)
- [ ] API ì‘ë‹µ ì‹œê°„ <100ms

### Backend
- [ ] ClearMLService ëª¨ë“  ê¸°ëŠ¥ êµ¬í˜„
- [ ] ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ ClearML ì—°ë™
- [ ] MLflow ì½”ë“œ 100% ì œê±°

### Trainer SDK
- [ ] ClearML Task ìë™ ìƒì„±
- [ ] ì‹¤ì‹œê°„ metrics logging
- [ ] Checkpoint ìë™ ì—…ë¡œë“œ ë° ë“±ë¡

### Data Migration
- [ ] ëª¨ë“  ê¸°ì¡´ MLflow ë°ì´í„° ClearMLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] ë°ì´í„° ë¬´ê²°ì„± 100% ê²€ì¦
- [ ] Zero data loss

### Frontend
- [ ] ClearML Web UI ì„ë² ë“œ
- [ ] Metrics ì°¨íŠ¸ ì •ìƒ ì‘ë™
- [ ] Experiment í˜ì´ì§€ ì—…ë°ì´íŠ¸

### Testing
- [ ] ëª¨ë“  Unit tests í†µê³¼
- [ ] ëª¨ë“  Integration tests í†µê³¼
- [ ] ëª¨ë“  E2E tests í†µê³¼
- [ ] Performance tests í†µê³¼

### Documentation
- [ ] ARCHITECTURE.md ì—…ë°ì´íŠ¸
- [ ] API_SPECIFICATION.md ì—…ë°ì´íŠ¸
- [ ] DEVELOPMENT.md ClearML ê°€ì´ë“œ ì¶”ê°€
- [ ] Migration guide ì‘ì„±

---

## ğŸ¯ Post-Migration Enhancements

**ClearML ê³ ê¸‰ ê¸°ëŠ¥ í™œìš©** (Phase 13 ì´í›„):

1. **ClearML Pipelines**
   - Training â†’ Evaluation â†’ Export â†’ Deployment ìë™í™”
   - íŒŒì´í”„ë¼ì¸ ë²„ì „ ê´€ë¦¬
   - ì¡°ê±´ë¶€ ì‹¤í–‰ (accuracy > 0.9 â†’ auto-deploy)

2. **ClearML Agents**
   - GPU ìë™ í• ë‹¹
   - ë¶„ì‚° í•™ìŠµ ì§€ì›
   - Queue ê¸°ë°˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§

3. **Model Registry**
   - ëª¨ë¸ ë²„ì „ ê´€ë¦¬
   - Lineage tracking (ì–´ë–¤ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆëŠ”ì§€)
   - A/B testing ì§€ì›

4. **Advanced Monitoring**
   - ì»¤ìŠ¤í…€ ëŒ€ì‹œë³´ë“œ
   - ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ë¡œê¹…
   - 3D plot ì§€ì›

---

## ğŸ“ Notes

### ClearML vs MLflow ë¹„êµ

| Feature | MLflow | ClearML | Winner |
|---------|--------|---------|--------|
| ì‹¤í—˜ ì¶”ì  | â­â­â­ | â­â­â­â­â­ | ClearML |
| ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ | â­â­â­ | â­â­â­â­â­ | ClearML |
| UI/UX | â­â­ | â­â­â­â­ | ClearML |
| íŒŒì´í”„ë¼ì¸ | âŒ | â­â­â­â­â­ | ClearML |
| ë¶„ì‚° í•™ìŠµ | â­ | â­â­â­â­ | ClearML |
| ì»¤ë®¤ë‹ˆí‹° | â­â­â­â­â­ | â­â­â­ | MLflow |
| ì˜¤í”ˆì†ŒìŠ¤ | â­â­â­â­â­ | â­â­â­â­ | MLflow |
| Self-hosting | â­â­â­ | â­â­â­â­â­ | ClearML |

### Migration Risks

**High Risk**:
- ClearML Server ì•ˆì •ì„± (ì‹ ê·œ ë„ì…)
- ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨

**Mitigation**:
- Staging í™˜ê²½ì—ì„œ ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸
- Rollback plan ì² ì €íˆ ì¤€ë¹„
- Dual-write ê¸°ê°„ ì„¤ì • (2ì£¼)

**Medium Risk**:
- Frontend UI ë³€ê²½ì— ë”°ë¥¸ ì‚¬ìš©ì ì ì‘

**Mitigation**:
- ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±
- ì ì§„ì  ë¡¤ì•„ì›ƒ (admin â†’ all users)

---

**ì‘ì„±ì**: Claude
**ê²€í†  í•„ìš”**: Phase 2 ClearMLService êµ¬í˜„ ê²€ì¦
**ë‹¤ìŒ ë‹¨ê³„**: Phase 1 ì‹¤í–‰ ìŠ¹ì¸ ëŒ€ê¸°
