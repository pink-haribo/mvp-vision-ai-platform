# Week 1 P0 Implementation - Final Plan (with YOLO-World)

**Document Version:** 4.0
**Updated:** 2025-10-30
**Status:** Ready to Execute

---

## P0 ëª¨ë¸ ì„ ì • (6ê°œ)

### ì „ëµì  ì„ íƒ ì´ìœ 

**í™•ì¥ì„± ì¡°ê¸° ê²€ì¦**:
- âœ… Classic CNN (ResNet-50)
- âœ… Modern Efficient (EfficientNetV2-S)
- âœ… Latest Lightweight (YOLOv11n)
- âœ… Latest Balanced (YOLOv11m)
- âœ… **í˜ì‹ ì  íŒ¨ëŸ¬ë‹¤ì„ (YOLO-World)** ğŸ†•

**YOLO-World ì¶”ê°€ ì´ìœ **:
1. ğŸš€ **ìƒˆë¡œìš´ Task Type ê²€ì¦**: Open-vocabulary detection
2. ğŸ¨ **UI í™•ì¥ì„± ê²€ì¦**: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥
3. ğŸ“š **ê°€ì´ë“œ ì‹œìŠ¤í…œ í™•ì¥**: Special Features ì„¹ì…˜
4. ğŸ”§ **Adapter ìœ ì—°ì„± ê²€ì¦**: Custom config ì²˜ë¦¬
5. ğŸ’¡ **ì°¨ë³„í™” ìš”ì†Œ**: Zero-shot detection ì‹¤ì œ êµ¬í˜„

---

## P0 ëª¨ë¸ ìƒì„¸ (6ê°œ)

### timm (2ê°œ)

#### 1. ResNet-50 â­ **Baseline Standard**
```python
"resnet50": {
    "display_name": "ResNet-50",
    "description": "Most popular baseline CNN - Industry standard for benchmarking",
    "params": "25.6M",
    "input_size": 224,
    "pretrained_available": True,
    "recommended_batch_size": 32,
    "recommended_lr": 0.001,
    "tags": ["baseline", "classic", "standard", "popular"],

    "benchmark": {
        "imagenet_top1": 80.4,
        "imagenet_top5": 95.1,
        "inference_speed_v100": "140 img/s",
        "training_time_epoch": "~2 hours (ImageNet, 8x V100)"
    },

    "use_cases": [
        "Baseline comparison",
        "Transfer learning starting point",
        "Educational purposes",
        "Production-ready classification"
    ],

    "pros": [
        "Well-documented and tested",
        "Excellent transfer learning",
        "Balanced accuracy/speed",
        "Widely supported"
    ],

    "cons": [
        "Not the most efficient",
        "Larger than modern mobile models",
        "Lower accuracy than ViT"
    ],

    "when_to_use": "When you need a reliable, well-understood baseline or starting point for transfer learning",

    "alternatives": [
        "EfficientNetV2-S (more efficient)",
        "ViT-Base (higher accuracy)"
    ]
}
```

#### 2. EfficientNetV2-Small â­ **Modern Efficient**
```python
"efficientnetv2_s": {
    "display_name": "EfficientNetV2-Small",
    "description": "Modern efficient CNN - Best accuracy/speed trade-off",
    "params": "21.5M",
    "input_size": 384,
    "pretrained_available": True,
    "recommended_batch_size": 64,
    "recommended_lr": 0.001,
    "tags": ["modern", "efficient", "balanced", "2021"],

    "benchmark": {
        "imagenet_top1": 84.3,
        "imagenet_top5": 97.0,
        "inference_speed_v100": "200 img/s",
        "training_time_epoch": "~1.5 hours (ImageNet, 8x V100)",
        "training_speedup": "11x faster than EfficientNet-B7"
    },

    "use_cases": [
        "Production deployment",
        "Resource-constrained environments",
        "Fast training required",
        "High accuracy needed"
    ],

    "pros": [
        "Training up to 11x faster than EfficientNet-B7",
        "Better accuracy than ResNet-50 with fewer params",
        "Progressive learning for stability",
        "Optimized for modern hardware"
    ],

    "cons": [
        "Larger input size (384) vs ResNet (224)",
        "Slightly more memory during training",
        "Less documentation than ResNet"
    ],

    "when_to_use": "When you want state-of-the-art efficiency and are willing to use modern architectures",

    "alternatives": [
        "ResNet-50 (more stable)",
        "MobileNetV4 (even lighter)"
    ]
}
```

---

### Ultralytics (4ê°œ)

#### 3. YOLOv11n â­ **Latest Lightweight**
```python
"yolo11n": {
    "display_name": "YOLOv11 Nano",
    "description": "Latest YOLO (Sep 2024) - Ultra-lightweight real-time detection",
    "params": "2.6M",
    "input_size": 640,
    "task_type": "object_detection",
    "pretrained_available": True,
    "recommended_batch_size": 64,
    "recommended_lr": 0.01,
    "tags": ["latest", "2024", "ultralight", "realtime", "edge"],

    "benchmark": {
        "coco_map50": 52.1,
        "coco_map50_95": 39.5,
        "inference_speed_v100": "120 FPS",
        "inference_speed_jetson_nano": "15 FPS",
        "inference_speed_cpu": "25 FPS",
        "model_size_mb": 5.8,
        "vs_yolov8n": "-22% params, +1.2 mAP"
    },

    "use_cases": [
        "Edge devices (Raspberry Pi, Jetson)",
        "Mobile deployment (iOS, Android)",
        "Real-time video processing",
        "Resource-constrained servers"
    ],

    "pros": [
        "22% fewer params than YOLOv8n",
        "Latest architecture (Sep 2024)",
        "Fast inference even on CPU",
        "Very small model size (5.8 MB)"
    ],

    "cons": [
        "Lower accuracy than larger models",
        "May struggle with small objects",
        "Less suitable for high-precision tasks"
    ],

    "when_to_use": "When deployment on edge/mobile devices is critical, or when real-time speed is more important than accuracy",

    "alternatives": [
        "YOLOv11m (better accuracy)",
        "YOLOv8n (more stable)"
    ]
}
```

#### 4. YOLOv11m â­ **Latest Balanced**
```python
"yolo11m": {
    "display_name": "YOLOv11 Medium",
    "description": "Latest YOLO (Sep 2024) - Best accuracy/speed balance",
    "params": "20.1M",
    "input_size": 640,
    "task_type": "object_detection",
    "pretrained_available": True,
    "recommended_batch_size": 16,
    "recommended_lr": 0.01,
    "tags": ["latest", "2024", "balanced", "production", "sota"],

    "benchmark": {
        "coco_map50": 67.8,
        "coco_map50_95": 51.5,
        "inference_speed_v100": "60 FPS",
        "inference_speed_t4": "35 FPS",
        "inference_speed_cpu": "5 FPS",
        "model_size_mb": 40.2,
        "vs_yolov8m": "-22% params, +1.3 mAP"
    },

    "use_cases": [
        "Production object detection",
        "Autonomous vehicles",
        "Security/surveillance",
        "Quality inspection",
        "Retail analytics"
    ],

    "pros": [
        "Best accuracy/speed trade-off in YOLO series",
        "22% fewer params than YOLOv8m",
        "Higher mAP than YOLOv8m (+1.3)",
        "Production-ready and battle-tested"
    ],

    "cons": [
        "Requires GPU for real-time",
        "Larger model size than nano (40 MB)",
        "Higher compute requirements"
    ],

    "when_to_use": "When you need the best balance of accuracy and speed for production deployment with GPU available",

    "alternatives": [
        "YOLOv11n (faster, edge)",
        "YOLOv11l (more accurate)"
    ]
}
```

#### 5. YOLO-World-v2-s ğŸ†• â­ **Open-Vocabulary Small**
```python
"yolo_world_v2_s": {
    "display_name": "YOLO-World v2 Small",
    "description": "Open-vocabulary detection (CVPR 2024) - Detect ANY object with text prompts",
    "params": "22M",
    "input_size": 640,
    "task_type": "open_vocabulary_detection",  # ğŸ†• New Task Type!
    "pretrained_available": True,
    "recommended_batch_size": 16,
    "recommended_lr": 0.01,
    "tags": ["cvpr2024", "open-vocab", "zero-shot", "innovative", "text-prompt"],

    "benchmark": {
        "lvis_map": 26.2,
        "lvis_map_rare": 17.8,  # Rare classes performance
        "coco_map50_95": 44.3,  # Zero-shot on COCO
        "inference_speed_v100": "52 FPS",
        "custom_classes_support": "Unlimited",
        "vs_traditional": "No retraining needed for new classes"
    },

    # ğŸ†• Special configuration for open-vocabulary
    "special_features": {
        "type": "open_vocabulary",
        "capabilities": [
            "Detect objects without training",
            "Custom text prompts as classes",
            "Zero-shot detection",
            "Dynamic class definition"
        ],
        "example_prompts": [
            "a red apple",
            "damaged product",
            "person wearing a hat",
            "car with license plate"
        ]
    },

    "use_cases": [
        "Retail: Detect new products without retraining",
        "Security: Custom threat detection",
        "Quality control: Find specific defects",
        "Research: Rapid prototyping with new classes",
        "E-commerce: Flexible product detection"
    ],

    "pros": [
        "No retraining for new object classes",
        "Natural language class definition",
        "Fast adaptation to new scenarios",
        "Handles rare/custom objects well"
    ],

    "cons": [
        "Lower accuracy than specialized models",
        "Requires careful prompt engineering",
        "Slower than standard YOLO (text encoding)",
        "Limited to detection (no segmentation yet)"
    ],

    "when_to_use": "When you need flexibility to detect new object types without retraining, or when dealing with long-tail/rare objects",

    "alternatives": [
        "YOLOv11m (higher accuracy, fixed classes)",
        "YOLO-World-v2-m (larger, more accurate)"
    ],

    # ğŸ†• How to use
    "usage_example": {
        "traditional_yolo": "model.predict('image.jpg')  # Detects 80 COCO classes",
        "yolo_world": "model.set_classes(['cat', 'dog', 'my custom object']).predict('image.jpg')  # Detects custom classes!"
    }
}
```

#### 6. YOLO-World-v2-m ğŸ†• â­ **Open-Vocabulary Medium**
```python
"yolo_world_v2_m": {
    "display_name": "YOLO-World v2 Medium",
    "description": "Open-vocabulary detection (CVPR 2024) - More accurate zero-shot detection",
    "params": "42M",
    "input_size": 640,
    "task_type": "open_vocabulary_detection",
    "pretrained_available": True,
    "recommended_batch_size": 8,
    "recommended_lr": 0.01,
    "tags": ["cvpr2024", "open-vocab", "zero-shot", "accurate"],

    "benchmark": {
        "lvis_map": 35.4,  # State-of-the-art on LVIS
        "lvis_map_rare": 26.8,
        "coco_map50_95": 48.1,
        "inference_speed_v100": "52 FPS",
        "custom_classes_support": "Unlimited",
        "vs_yolo_world_s": "+9.2 mAP on LVIS"
    },

    "special_features": {
        "type": "open_vocabulary",
        "capabilities": [
            "State-of-the-art open-vocab performance",
            "Better rare object detection",
            "Robust to prompt variations",
            "Multi-language support (experimental)"
        ],
        "example_prompts": [
            "vintage car from 1950s",
            "person with blue backpack",
            "damaged packaging box",
            "ripe banana vs unripe banana"
        ]
    },

    "use_cases": [
        "Large-scale retail inventory",
        "Advanced security systems",
        "Medical imaging (custom conditions)",
        "Autonomous vehicles (rare scenarios)",
        "Wildlife monitoring (species detection)"
    ],

    "pros": [
        "Best-in-class open-vocabulary accuracy",
        "Excellent rare object detection",
        "More robust prompt understanding",
        "Still real-time (52 FPS)"
    ],

    "cons": [
        "2x params vs small version",
        "Higher memory usage",
        "Slower than standard YOLO",
        "Requires more compute"
    ],

    "when_to_use": "When you need maximum accuracy for open-vocabulary detection and have sufficient GPU resources",

    "alternatives": [
        "YOLO-World-v2-s (faster, lighter)",
        "YOLOv11l (higher fixed-class accuracy)"
    ]
}
```

---

## ì‹œìŠ¤í…œ í™•ì¥ í•„ìš” ì‚¬í•­

### 1. TaskType ì¶”ê°€

```python
# mvp/training/adapters/base.py

class TaskType(Enum):
    IMAGE_CLASSIFICATION = "image_classification"
    OBJECT_DETECTION = "object_detection"
    INSTANCE_SEGMENTATION = "instance_segmentation"
    SEMANTIC_SEGMENTATION = "semantic_segmentation"
    POSE_ESTIMATION = "pose_estimation"
    OBB_DETECTION = "obb_detection"
    OPEN_VOCABULARY_DETECTION = "open_vocabulary_detection"  # ğŸ†• ì¶”ê°€!
```

### 2. TrainingConfig í™•ì¥

```python
# mvp/backend/app/schemas/training.py

class TrainingConfig(BaseModel):
    """Training configuration schema."""

    framework: str = Field("timm", description="Framework")
    model_name: str = Field(..., description="Model name")
    task_type: str = Field(..., description="Task type")

    # ... existing fields ...

    # ğŸ†• Open-vocabulary ì „ìš© ì„¤ì •
    custom_prompts: Optional[List[str]] = Field(
        None,
        description="Custom text prompts for open-vocabulary detection (YOLO-World only)"
    )
    prompt_mode: Optional[str] = Field(
        "offline",
        description="Prompt mode: 'offline' (pre-computed) or 'dynamic' (runtime)"
    )
```

### 3. UltralyticsAdapter í™•ì¥

```python
# mvp/training/adapters/ultralytics_adapter.py

class UltralyticsAdapter(TrainingAdapter):
    """Adapter for Ultralytics YOLO models."""

    def prepare_model(self) -> None:
        """Initialize model."""
        from ultralytics import YOLO

        model_name = self.model_config.model_name
        task_type = self.model_config.task_type

        # Standard YOLO models
        if task_type != TaskType.OPEN_VOCABULARY_DETECTION:
            model_file = self._get_model_file(model_name, task_type)
            self.model = YOLO(model_file)

        # ğŸ†• YOLO-World special handling
        else:
            from ultralytics import YOLOWorld

            # Load YOLO-World model
            self.model = YOLOWorld(f"{model_name}.pt")

            # Set custom classes if provided
            if self.model_config.custom_prompts:
                self.model.set_classes(self.model_config.custom_prompts)
                print(f"[YOLOWorld] Custom classes: {self.model_config.custom_prompts}")
            else:
                # Use default COCO classes
                print("[YOLOWorld] Using default COCO classes")

        # Move to device
        device = self.training_config.device if torch.cuda.is_available() else 'cpu'
        self.model.to(device)
```

### 4. Frontend UI í™•ì¥

#### ModelSelector.tsx ìˆ˜ì •

```typescript
// mvp/frontend/components/training/ModelSelector.tsx

interface ModelSelectorProps {
  onSelect: (model: ModelInfo, config?: ModelConfig) => void;
}

export default function ModelSelector({ onSelect }: ModelSelectorProps) {
  const [selectedModel, setSelectedModel] = useState<ModelInfo | null>(null);
  const [showPromptModal, setShowPromptModal] = useState(false);

  const handleModelSelect = (model: ModelInfo) => {
    // ğŸ†• Open-vocabulary model requires prompt input
    if (model.task_type === "open_vocabulary_detection") {
      setSelectedModel(model);
      setShowPromptModal(true);
    } else {
      onSelect(model);
    }
  };

  return (
    <div>
      {/* Model grid */}
      <ModelGrid onSelect={handleModelSelect} />

      {/* ğŸ†• Prompt input modal for YOLO-World */}
      {showPromptModal && selectedModel && (
        <CustomPromptsModal
          model={selectedModel}
          onConfirm={(prompts) => {
            onSelect(selectedModel, { custom_prompts: prompts });
            setShowPromptModal(false);
          }}
          onCancel={() => setShowPromptModal(false)}
        />
      )}
    </div>
  );
}
```

#### CustomPromptsModal.tsx (ì‹ ê·œ)

```typescript
// mvp/frontend/components/training/CustomPromptsModal.tsx

interface CustomPromptsModalProps {
  model: ModelInfo;
  onConfirm: (prompts: string[]) => void;
  onCancel: () => void;
}

export default function CustomPromptsModal({ model, onConfirm, onCancel }: CustomPromptsModalProps) {
  const [prompts, setPrompts] = useState<string[]>(['']);

  const addPrompt = () => setPrompts([...prompts, '']);
  const removePrompt = (index: number) => setPrompts(prompts.filter((_, i) => i !== index));
  const updatePrompt = (index: number, value: string) => {
    const newPrompts = [...prompts];
    newPrompts[index] = value;
    setPrompts(newPrompts);
  };

  return (
    <div className="modal">
      <h2>Define Custom Classes for {model.display_name}</h2>

      <div className="prompt-info">
        <p>YOLO-World can detect any objects you describe!</p>
        <p>Enter natural language descriptions of objects to detect:</p>
      </div>

      <div className="prompt-examples">
        <strong>Examples:</strong>
        <ul>
          <li>"red apple"</li>
          <li>"person wearing a hat"</li>
          <li>"damaged product"</li>
          <li>"car with license plate"</li>
        </ul>
      </div>

      <div className="prompt-inputs">
        {prompts.map((prompt, index) => (
          <div key={index} className="prompt-input-row">
            <input
              type="text"
              placeholder={`Class ${index + 1}: e.g., "red apple"`}
              value={prompt}
              onChange={(e) => updatePrompt(index, e.target.value)}
            />
            {prompts.length > 1 && (
              <button onClick={() => removePrompt(index)}>Remove</button>
            )}
          </div>
        ))}
      </div>

      <button onClick={addPrompt}>+ Add Another Class</button>

      <div className="modal-actions">
        <button onClick={onCancel}>Cancel</button>
        <button
          onClick={() => onConfirm(prompts.filter(p => p.trim()))}
          disabled={prompts.filter(p => p.trim()).length === 0}
        >
          Use These Classes
        </button>
      </div>

      <div className="tip">
        ğŸ’¡ Tip: Be specific! "red apple" works better than just "apple"
      </div>
    </div>
  );
}
```

### 5. ê°€ì´ë“œ ì‹œìŠ¤í…œ í™•ì¥

#### Special Features ì„¹ì…˜ ì¶”ê°€

```typescript
// mvp/frontend/components/training/guide/SpecialFeaturesSection.tsx

interface SpecialFeaturesSectionProps {
  features: {
    type: string;
    capabilities: string[];
    example_prompts?: string[];
    usage_example?: {
      traditional_yolo: string;
      yolo_world: string;
    };
  };
}

export default function SpecialFeaturesSection({ features }: SpecialFeaturesSectionProps) {
  return (
    <div className="special-features-section">
      <h3>ğŸŒŸ Special Features</h3>

      <div className="feature-type">
        <strong>Type:</strong> {features.type}
      </div>

      <div className="capabilities">
        <strong>Capabilities:</strong>
        <ul>
          {features.capabilities.map((cap, i) => (
            <li key={i}>{cap}</li>
          ))}
        </ul>
      </div>

      {features.example_prompts && (
        <div className="example-prompts">
          <strong>Example Prompts:</strong>
          <div className="prompt-chips">
            {features.example_prompts.map((prompt, i) => (
              <span key={i} className="prompt-chip">"{prompt}"</span>
            ))}
          </div>
        </div>
      )}

      {features.usage_example && (
        <div className="usage-comparison">
          <strong>How to Use:</strong>

          <div className="code-comparison">
            <div className="traditional">
              <span className="label">Traditional YOLO:</span>
              <code>{features.usage_example.traditional_yolo}</code>
              <p className="note">Fixed 80 COCO classes</p>
            </div>

            <div className="arrow">â†’</div>

            <div className="yolo-world">
              <span className="label">YOLO-World:</span>
              <code>{features.usage_example.yolo_world}</code>
              <p className="note">Any custom classes!</p>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}
```

---

## êµ¬í˜„ ìŠ¤ì¼€ì¤„ (Day 1-2 ì¬ì¡°ì •)

### Day 1: Infrastructure + P0 Models (6ê°œ)

#### Morning (4h)
```
09:00-10:00  ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
             - mvp/training/model_registry/
             - __init__.py, timm_models.py, ultralytics_models.py

10:00-11:30  P0 6ê°œ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì‘ì„± (full guide í¬í•¨)
             - ResNet-50, EfficientNetV2-S (timm)
             - YOLOv11n, YOLOv11m, YOLO-World s/m (ultralytics)
             - special_features ì •ë³´ í¬í•¨

11:30-13:00  ğŸ†• TaskType í™•ì¥ ë° Config ìˆ˜ì •
             - base.py: OPEN_VOCABULARY_DETECTION ì¶”ê°€
             - training.py: custom_prompts í•„ë“œ ì¶”ê°€
             - enums.py: TaskType ì—…ë°ì´íŠ¸
```

#### Afternoon (4h)
```
14:00-15:30  API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
             - GET /models/list
             - GET /models/{framework}/{model_name}
             - GET /models/{framework}/{model_name}/guide
             - Responseì— special_features í¬í•¨

15:30-17:00  ğŸ†• UltralyticsAdapter í™•ì¥
             - YOLO-World ì²˜ë¦¬ ë¡œì§
             - set_classes() í˜¸ì¶œ
             - custom_prompts ì „ë‹¬

17:00-18:00  ê¸°ë³¸ UI ì»´í¬ë„ŒíŠ¸
             - ModelCard.tsx (ê¸°ë³¸)
             - ModelSelector.tsx (ê·¸ë¦¬ë“œ)
```

### Day 2: Guide System + YOLO-World UI

#### Morning (4h)
```
09:00-10:30  ModelGuideDrawer ì»´í¬ë„ŒíŠ¸ (ìŠ¬ë¼ì´ë“œ íŒ¨ë„)
             - 6ê°œ ì„¹ì…˜ ë ˆì´ì•„ì›ƒ
             - ì• ë‹ˆë©”ì´ì…˜, ë°˜ì‘í˜•

10:30-12:00  ê°€ì´ë“œ ì„¹ì…˜ 1-3 êµ¬í˜„
             - QuickStats.tsx
             - BenchmarkSection.tsx
             - UsageGuidance.tsx

12:00-13:00  ğŸ†• SpecialFeaturesSection.tsx
             - YOLO-World capabilities í‘œì‹œ
             - Example prompts chips
             - Usage comparison
```

#### Afternoon (4h)
```
14:00-15:00  ê°€ì´ë“œ ì„¹ì…˜ 4-6 êµ¬í˜„
             - ModelComparisonTable.tsx
             - PerformanceChart.tsx (scatter plot)
             - RecommendedSettings.tsx

15:00-16:30  ğŸ†• CustomPromptsModal.tsx
             - í”„ë¡¬í”„íŠ¸ ì…ë ¥ UI
             - Add/Remove prompts
             - Example suggestions

16:30-18:00  P0 í†µí•© í…ŒìŠ¤íŠ¸
             - 6ê°œ ëª¨ë¸ UI ë™ì‘ í™•ì¸
             - YOLO-World í”„ë¡¬í”„íŠ¸ ì…ë ¥ í…ŒìŠ¤íŠ¸
             - ê°€ì´ë“œ ì •ë³´ í‘œì‹œ í™•ì¸
```

---

## ê²€ì¦ ê¸°ì¤€ (Day 2 ì¢…ë£Œ ì‹œ)

### ê¸°ëŠ¥ ê²€ì¦

- [ ] **ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬**: 6ê°œ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì™„ì„±
- [ ] **API**: `/models/list`, `/models/{}/guide` ì •ìƒ ë™ì‘
- [ ] **UI - ê¸°ë³¸**: ëª¨ë¸ ì¹´ë“œ ê·¸ë¦¬ë“œ í‘œì‹œ
- [ ] **UI - ê°€ì´ë“œ**: ìŠ¬ë¼ì´ë“œ íŒ¨ë„ë¡œ 6ê°œ ì„¹ì…˜ í‘œì‹œ
- [ ] **UI - YOLO-World**: í”„ë¡¬í”„íŠ¸ ì…ë ¥ ëª¨ë‹¬ ë™ì‘
- [ ] **Adapter**: YOLO-World custom_prompts ì²˜ë¦¬

### YOLO-World íŠ¹ìˆ˜ ê²€ì¦

- [ ] TaskType.OPEN_VOCABULARY_DETECTION ì¶”ê°€ë¨
- [ ] TrainingConfig.custom_prompts ë™ì‘
- [ ] UltralyticsAdapterê°€ YOLOWorld ë¡œë“œ
- [ ] set_classes() í˜¸ì¶œ í™•ì¸
- [ ] CustomPromptsModal UI ë™ì‘
- [ ] SpecialFeaturesSection í‘œì‹œ

### í•™ìŠµ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨)

**Standard Models**:
- [ ] ResNet-50: ImageFolder ë°ì´í„°ë¡œ 3 epochs
- [ ] YOLOv11n: COCO subsetìœ¼ë¡œ 3 epochs

**YOLO-World**:
- [ ] Custom prompts: ["cat", "dog", "car"]ë¡œ inference í…ŒìŠ¤íŠ¸
- [ ] Zero-shot detection ë™ì‘ í™•ì¸

---

## P0 ì™„ë£Œ ì‹œ ë‹¬ì„± ëª©í‘œ

### 1. ì‹œìŠ¤í…œ ìœ íš¨ì„± ê²€ì¦ âœ…

- Adapter íŒ¨í„´ì´ ë‹¤ì–‘í•œ ëª¨ë¸ì— ë™ì‘
- Classic CNN (ResNet) âœ…
- Modern CNN (EfficientNetV2) âœ…
- Latest YOLO (v11) âœ…
- Open-vocab (YOLO-World) âœ…

### 2. í™•ì¥ì„± ê²€ì¦ âœ…

- ìƒˆë¡œìš´ TaskType ì¶”ê°€ ê°€ëŠ¥ (OPEN_VOCABULARY_DETECTION)
- Config í™•ì¥ ê°€ëŠ¥ (custom_prompts)
- Adapter ìœ ì—°ì„± (íŠ¹ìˆ˜ ëª¨ë¸ ì²˜ë¦¬)
- UI í™•ì¥ ê°€ëŠ¥ (CustomPromptsModal)

### 3. ê°€ì´ë“œ ì‹œìŠ¤í…œ ê²€ì¦ âœ…

- 6ê°œ ì„¹ì…˜ ì™„ì„±
- íŠ¹ìˆ˜ ê¸°ëŠ¥ í‘œì‹œ (Special Features)
- ì¸í„°ë™í‹°ë¸Œ ìš”ì†Œ (í”„ë¡¬í”„íŠ¸ ì…ë ¥)
- ë¹„êµ ê¸°ëŠ¥ (Similar Models)

### 4. ì°¨ë³„í™” ìš”ì†Œ êµ¬í˜„ âœ…

- **YOLO-World**: ì—…ê³„ ìµœì´ˆ ì‹¤ì‹œê°„ open-vocabulary
- Zero-shot detection ì‹¤ì œ ë™ì‘
- í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ í´ë˜ìŠ¤ ì •ì˜
- ì¬í•™ìŠµ ì—†ì´ ìƒˆ ê°ì²´ ê²€ì¶œ

---

## Week 1 ë‚˜ë¨¸ì§€ ê³„íš (Day 3-7)

### Day 3-4: P1 (12ê°œ ëª¨ë¸)
- timm 6ê°œ: Mobile, ViT, Classic
- ultralytics 6ê°œ: Detection, Seg, Pose í™•ì¥

### Day 5: P2 (15ê°œ ëª¨ë¸)
- ëª¨ë“  ë³€í˜• í¬í•¨
- YOLOv10 (NMS-free)
- OBB, MaxViT ë“±

### Day 6-7: Polish & Docs
- ì „ì²´ ê²€ì¦
- ë¦¬í¬íŠ¸ ì‘ì„±
- Week 2 ì¤€ë¹„

---

## ê¸°ëŒ€ íš¨ê³¼

### ì¡°ê¸° ê²€ì¦ (Day 2)
- âœ… ì‹œìŠ¤í…œ ë™ì‘ í™•ì¸
- âœ… YOLO-Worldë¡œ í™•ì¥ì„± ì…ì¦
- âœ… ê°€ì´ë“œ ì‹œìŠ¤í…œ ì™„ì„±

### ì°¨ë³„í™” (Day 2)
- ğŸš€ Zero-shot detection ì œê³µ
- ğŸ¨ í…ìŠ¤íŠ¸ ê¸°ë°˜ í´ë˜ìŠ¤ ì •ì˜
- ğŸ’¡ í˜ì‹ ì  UX (í”„ë¡¬í”„íŠ¸ ì…ë ¥)

### ì‹ ë¢°ì„± (Day 2)
- ğŸ“Š ìƒì„¸í•œ ê°€ì´ë“œ ì •ë³´
- ğŸ” ëª¨ë¸ ë¹„êµ ê¸°ëŠ¥
- ğŸ’¬ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€

---

## ë‹¤ìŒ ë‹¨ê³„

**ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤!**

1. **ë¸Œëœì¹˜ ìƒì„±**
   ```bash
   git checkout -b feat/model-registry-p0-yoloworld
   ```

2. **Day 1 Morning ì‹œì‘** (09:00)
   ```python
   # 1. TaskType í™•ì¥
   # mvp/training/adapters/base.py
   class TaskType(Enum):
       # ... existing
       OPEN_VOCABULARY_DETECTION = "open_vocabulary_detection"

   # 2. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì‘ì„±
   # mvp/training/model_registry/ultralytics_models.py
   ULTRALYTICS_MODEL_REGISTRY = {
       "yolo11n": { ... },
       "yolo11m": { ... },
       "yolo_world_v2_s": { ... },  # ğŸ†•
       "yolo_world_v2_m": { ... },  # ğŸ†•
   }
   ```

---

*Document Version: 4.0*
*Created: 2025-10-30*
*Ready to Execute!* ğŸš€
