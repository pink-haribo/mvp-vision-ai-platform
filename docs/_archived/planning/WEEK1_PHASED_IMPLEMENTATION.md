# Week 1 Phased Implementation Plan

**Document Version:** 3.0
**Updated:** 2025-10-30
**Status:** Implementation Ready

---

## ì „ëµ: ì ì§„ì  ê²€ì¦ ë° í™•ì¥

### í•µì‹¬ ì•„ì´ë””ì–´

```
P0 (Quick Win, Day 1-2)
  â†“ ê²€ì¦: ì‹œìŠ¤í…œ ë™ì‘ í™•ì¸

P1 (Core Expansion, Day 3-4)
  â†“ ê²€ì¦: ë‹¤ì–‘í•œ ëª¨ë¸ íƒ€ì…

P2 (Full Coverage, Day 5-7)
  â†“ ì™„ì„±: ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì»¤ë²„
```

**ì¥ì **:
1. âœ… ë¹ ë¥¸ í”¼ë“œë°± (Day 1-2)
2. âœ… ì ì§„ì  ìœ„í—˜ ê´€ë¦¬
3. âœ… ê° ë‹¨ê³„ë§ˆë‹¤ í•™ìŠµ ë°˜ì˜
4. âœ… ì¤‘ë‹¨ ì‹œì  ì„ íƒ ê°€ëŠ¥

---

## Priority 0: Quick Win (í•„ìˆ˜, Day 1-2)

**ëª©í‘œ**: ì‹œìŠ¤í…œ ìœ íš¨ì„± ê²€ì¦ + ëª¨ë¸ ê°€ì´ë“œ UI êµ¬ì¶•

**ëª¨ë¸ ì„ ì •** (ì´ 4ê°œ):

### timm (2ê°œ)

#### 1. ResNet-50 â­ **Baseline Standard**
```python
"resnet50": {
    "display_name": "ResNet-50",
    "description": "Most popular baseline CNN - Industry standard for benchmarking",
    "params": "25.6M",
    "input_size": 224,
    "pretrained_available": True,
    "recommended_batch_size": 32,
    "recommended_lr": 0.001,
    "tags": ["baseline", "classic", "standard", "popular"],

    # ê°€ì´ë“œ ì •ë³´
    "benchmark": {
        "imagenet_top1": 80.4,
        "imagenet_top5": 95.1,
        "inference_speed_v100": "140 img/s",
        "training_time_epoch": "~2 hours (ImageNet, 8x V100)"
    },
    "use_cases": [
        "Baseline comparison",
        "Transfer learning starting point",
        "Educational purposes",
        "Production-ready classification"
    ],
    "pros": [
        "Well-documented and tested",
        "Excellent transfer learning",
        "Balanced accuracy/speed",
        "Widely supported"
    ],
    "cons": [
        "Not the most efficient",
        "Larger than modern mobile models",
        "Lower accuracy than ViT"
    ],
    "when_to_use": "When you need a reliable, well-understood baseline or starting point for transfer learning",
    "alternatives": ["EfficientNetV2-S (more efficient)", "ViT-Base (higher accuracy)"]
}
```

#### 2. EfficientNetV2-Small â­ **Modern Efficient**
```python
"efficientnetv2_s": {
    "display_name": "EfficientNetV2-Small",
    "description": "Modern efficient CNN - Best accuracy/speed trade-off",
    "params": "21.5M",
    "input_size": 384,
    "pretrained_available": True,
    "recommended_batch_size": 64,
    "recommended_lr": 0.001,
    "tags": ["modern", "efficient", "balanced", "2021"],

    "benchmark": {
        "imagenet_top1": 84.3,
        "imagenet_top5": 97.0,
        "inference_speed_v100": "200 img/s",
        "training_time_epoch": "~1.5 hours (ImageNet, 8x V100)"
    },
    "use_cases": [
        "Production deployment",
        "Resource-constrained environments",
        "Fast training required",
        "High accuracy needed"
    ],
    "pros": [
        "Training up to 11x faster than EfficientNet-B7",
        "Better accuracy than ResNet-50 with fewer params",
        "Progressive learning for stability",
        "Optimized for modern hardware"
    ],
    "cons": [
        "Larger input size (384) vs ResNet (224)",
        "Slightly more memory during training",
        "Less documentation than ResNet"
    ],
    "when_to_use": "When you want state-of-the-art efficiency and are willing to use modern architectures",
    "alternatives": ["ResNet-50 (more stable)", "MobileNetV4 (even lighter)"]
}
```

### Ultralytics (2ê°œ)

#### 3. YOLOv11n â­ **Latest Lightweight**
```python
"yolo11n": {
    "display_name": "YOLOv11 Nano",
    "description": "Latest YOLO (Sep 2024) - Ultra-lightweight real-time detection",
    "params": "2.6M",
    "input_size": 640,
    "task_type": "object_detection",
    "pretrained_available": True,
    "recommended_batch_size": 64,
    "recommended_lr": 0.01,
    "tags": ["latest", "2024", "ultralight", "realtime", "edge"],

    "benchmark": {
        "coco_map50": 52.1,
        "coco_map50_95": 39.5,
        "inference_speed_v100": "120 FPS",
        "inference_speed_jetson_nano": "15 FPS",
        "model_size_mb": 5.8
    },
    "use_cases": [
        "Edge devices (Raspberry Pi, Jetson)",
        "Mobile deployment",
        "Real-time video processing",
        "Resource-constrained servers"
    ],
    "pros": [
        "22% fewer params than YOLOv8n",
        "Latest architecture (Sep 2024)",
        "Fast inference even on CPU",
        "Very small model size (5.8 MB)"
    ],
    "cons": [
        "Lower accuracy than larger models",
        "May struggle with small objects",
        "Less suitable for high-precision tasks"
    ],
    "when_to_use": "When deployment on edge/mobile devices is critical, or when real-time speed is more important than accuracy",
    "alternatives": ["YOLOv11m (better accuracy)", "YOLOv8n (more stable)"]
}
```

#### 4. YOLOv11m â­ **Latest Balanced**
```python
"yolo11m": {
    "display_name": "YOLOv11 Medium",
    "description": "Latest YOLO (Sep 2024) - Best accuracy/speed balance",
    "params": "20.1M",
    "input_size": 640,
    "task_type": "object_detection",
    "pretrained_available": True,
    "recommended_batch_size": 16,
    "recommended_lr": 0.01,
    "tags": ["latest", "2024", "balanced", "production", "sota"],

    "benchmark": {
        "coco_map50": 67.8,
        "coco_map50_95": 51.5,
        "inference_speed_v100": "60 FPS",
        "inference_speed_t4": "35 FPS",
        "model_size_mb": 40.2
    },
    "use_cases": [
        "Production object detection",
        "Autonomous vehicles",
        "Security/surveillance",
        "Quality inspection"
    ],
    "pros": [
        "Best accuracy/speed trade-off",
        "22% fewer params than YOLOv8m",
        "Higher mAP than YOLOv8m",
        "Production-ready"
    ],
    "cons": [
        "Requires GPU for real-time",
        "Larger model size than nano",
        "Higher compute requirements"
    ],
    "when_to_use": "When you need the best balance of accuracy and speed for production deployment",
    "alternatives": ["YOLOv11n (faster)", "YOLOv11l (more accurate)"]
}
```

---

## Priority 1: Core Expansion (Day 3-4)

**ëª©í‘œ**: ì£¼ìš” ì¹´í…Œê³ ë¦¬ ì»¤ë²„

**ëª¨ë¸ ì„ ì •** (ì´ 12ê°œ):

### timm (6ê°œ)

#### Mobile ê³„ì—´ (2ê°œ)
- **MobileNetV4-Medium**: ìµœì‹  mobile (2024)
- **MobileNetV3-Large**: Baseline mobile

#### ViT ê³„ì—´ (2ê°œ)
- **ViT-Base/16**: Standard transformer
- **SigLIP-2 (ViT-SO150M)**: SOTA ViT (88.1%)

#### Classic CNN (2ê°œ)
- **ResNet-18**: Lightweight baseline
- **ConvNeXt-Tiny**: Modern CNN

### Ultralytics (6ê°œ)

#### Detection (2ê°œ)
- **YOLOv11s**: Small (9.4M params)
- **YOLOv11l**: Large (25.3M params)

#### Segmentation (2ê°œ)
- **YOLOv11n-seg**: Lightweight segmentation
- **YOLOv11m-seg**: Balanced segmentation

#### Pose (2ê°œ)
- **YOLOv11m-pose**: Balanced pose
- **YOLOv11l-pose**: Accurate pose

---

## Priority 2: Full Coverage (Day 5-7)

**ëª©í‘œ**: ëª¨ë“  íŠ¹ìˆ˜ ê¸°ëŠ¥ ë° ì¹´í…Œê³ ë¦¬

**ëª¨ë¸ ì„ ì •** (ì´ 15ê°œ):

### timm (8ê°œ)
- **EfficientNet-B0, B4**: Original EfficientNet
- **EfficientNetV2-M**: Larger V2
- **ResNet-101**: Deep ResNet
- **ViT-Large/16**: Large transformer
- **MobileNetV5-Large**: Latest mobile (2024)
- **ConvNeXt-Base**: Larger modern CNN
- **MaxViT-Tiny**: Hybrid CNN+ViT

### Ultralytics (7ê°œ)
- **YOLOv11x**: Maximum accuracy detection
- **YOLOv11x-seg**: Maximum accuracy segmentation
- **YOLO-World-v2-s**: Open-vocabulary (í˜ì‹ !)
- **YOLO-World-v2-m**: Larger open-vocab
- **YOLOv10n, YOLOv10s**: NMS-free
- **YOLOv11n-obb**: Oriented bounding box

---

## ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ ì‹œìŠ¤í…œ ì„¤ê³„

### UX êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Selection Page                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  [Filters: Framework â–¼  Task â–¼  Tags â–¼]  [Search: ___]     â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  ResNet-50     â”‚  â”‚ EfficientNetV2 â”‚  â”‚  YOLOv11n      â”‚â”‚
â”‚  â”‚  25.6M params  â”‚  â”‚ 21.5M params   â”‚  â”‚  2.6M params   â”‚â”‚
â”‚  â”‚  â­â­â­â­       â”‚  â”‚ â­â­â­â­â­     â”‚  â”‚  â­â­â­â­â­    â”‚â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚                â”‚â”‚
â”‚  â”‚  [Select]      â”‚  â”‚  [Select]      â”‚  â”‚  [Select]      â”‚â”‚
â”‚  â”‚  [ğŸ“– Guide]    â”‚  â”‚  [ğŸ“– Guide]    â”‚  â”‚  [ğŸ“– Guide]    â”‚â”‚ â† ê°€ì´ë“œ ë²„íŠ¼
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“ Click [ğŸ“– Guide]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â† Back                   ResNet-50 Guide               [Ã—]  â”‚ â† Slide Panel
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  ğŸ“Š Quick Stats                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Accuracy:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  80.4%                          â”‚ â”‚
â”‚  â”‚  Speed:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  140 img/s                      â”‚ â”‚
â”‚  â”‚  Size:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘  25.6M params                   â”‚ â”‚
â”‚  â”‚  Difficulty: â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  Easy                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                               â”‚
â”‚  ğŸ“ˆ Benchmark Performance                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ImageNet-1k:     80.4% top-1, 95.1% top-5            â”‚ â”‚
â”‚  â”‚  Inference (V100): 140 img/s                           â”‚ â”‚
â”‚  â”‚  Training Time:    ~2h/epoch (8x V100)                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                               â”‚
â”‚  ğŸ¯ When to Use                                              â”‚
â”‚  Use ResNet-50 when you need a reliable, well-understood    â”‚
â”‚  baseline or starting point for transfer learning.          â”‚
â”‚                                                               â”‚
â”‚  âœ… Pros                          âŒ Cons                    â”‚
â”‚  â€¢ Well-documented               â€¢ Not most efficient       â”‚
â”‚  â€¢ Excellent transfer learning   â€¢ Larger than mobile       â”‚
â”‚  â€¢ Balanced accuracy/speed       â€¢ Lower than ViT           â”‚
â”‚                                                               â”‚
â”‚  ğŸ’¡ Use Cases                                                â”‚
â”‚  â€¢ Baseline comparison                                       â”‚
â”‚  â€¢ Transfer learning                                         â”‚
â”‚  â€¢ Educational purposes                                      â”‚
â”‚  â€¢ Production classification                                 â”‚
â”‚                                                               â”‚
â”‚  ğŸ”„ Similar Models                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model          Accuracy  Speed   Size   Best For   â”‚   â”‚
â”‚  â”‚  ResNet-50      80.4%     140     25.6M  Baseline   â”‚ â† Current
â”‚  â”‚  EfficientNetV2 84.3%     200     21.5M  Efficiency â”‚   â”‚
â”‚  â”‚  ViT-Base       84.5%     110     86M    Accuracy   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  ğŸ“Š Accuracy vs Speed Plot                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 90%â”‚                        ViT-L â—                    â”‚ â”‚
â”‚  â”‚    â”‚                                                   â”‚ â”‚
â”‚  â”‚ 85%â”‚          ViT-B â—   EfficientNetV2 â—              â”‚ â”‚
â”‚  â”‚    â”‚                                                   â”‚ â”‚
â”‚  â”‚ 80%â”‚    ResNet-50 â—                                    â”‚ â”‚
â”‚  â”‚    â”‚                                                   â”‚ â”‚
â”‚  â”‚ 75%â”‚  MobileNetV3 â—                                    â”‚ â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”‚
â”‚  â”‚        50    100   150   200   250 (img/s)            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                               â”‚
â”‚  ğŸ”§ Recommended Settings                                     â”‚
â”‚  Batch Size: 32  |  Learning Rate: 0.001  |  Epochs: 50     â”‚
â”‚                                                               â”‚
â”‚  [Select this Model]  [Compare with Another]                â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ê°€ì´ë“œ ì‹œìŠ¤í…œ ìƒì„¸ ì„¤ê³„

### 1. ì •ë³´ ì•„í‚¤í…ì²˜ (6 Sections)

#### Section 1: Quick Stats (í•œëˆˆì— íŒŒì•…)
```typescript
interface QuickStats {
  accuracy: {
    value: number;      // 80.4
    max: number;        // 90 (for bar visualization)
    label: string;      // "ImageNet Top-1"
  };
  speed: {
    value: number;      // 140
    unit: string;       // "img/s"
    device: string;     // "V100"
  };
  size: {
    params: string;     // "25.6M"
    modelSizeMB: number; // 98
  };
  difficulty: "Easy" | "Medium" | "Hard";
}
```

**ì‹œê°í™”**:
- Progress bars (ìƒ‰ìƒ: ì´ˆë¡ > 80%, ë…¸ë‘ 60-80%, ë¹¨ê°• < 60%)
- Icons: ğŸ¯ Accuracy, âš¡ Speed, ğŸ“¦ Size, ğŸ“ Difficulty

#### Section 2: Benchmark Performance (êµ¬ì²´ì  ìˆ˜ì¹˜)
```typescript
interface Benchmark {
  dataset: string;           // "ImageNet-1k"
  metrics: {
    top1: number;            // 80.4
    top5?: number;           // 95.1
    map50?: number;          // For detection
    map50_95?: number;       // For detection
  };
  inference: {
    device: string;          // "V100"
    speed: number;           // 140
    unit: string;            // "img/s"
    batchSize?: number;      // 32
  };
  training: {
    timePerEpoch: string;    // "~2 hours"
    hardware: string;        // "8x V100"
  };
}
```

**í‘œì‹œ í˜•ì‹**:
```
ğŸ“Š ImageNet-1k:  80.4% top-1  â€¢  95.1% top-5
âš¡ Inference:    140 img/s (V100, batch=32)
â±ï¸ Training:     ~2h/epoch (ImageNet, 8x V100)
```

#### Section 3: When to Use (ì‹¤ìš©ì  ì¡°ì–¸)
```typescript
interface UsageGuidance {
  summary: string;  // 1-2 ë¬¸ì¥ ìš”ì•½
  pros: string[];   // 3-5ê°œ ì¥ì 
  cons: string[];   // 3-5ê°œ ë‹¨ì 
  useCases: string[]; // 4-6ê°œ êµ¬ì²´ì  use case
  whenToUse: string;  // ëª…í™•í•œ ì‚¬ìš© ì‹œì 
  whenNotToUse?: string; // ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ë•Œ
}
```

**ì˜ˆì‹œ**:
```markdown
ğŸ¯ **When to Use**
Use ResNet-50 when you need a reliable, well-understood baseline
or starting point for transfer learning.

âœ… **Pros**
â€¢ Well-documented and widely tested
â€¢ Excellent transfer learning performance
â€¢ Balanced accuracy/speed trade-off

âŒ **Cons**
â€¢ Not the most parameter-efficient
â€¢ Lower accuracy than Vision Transformers
```

#### Section 4: Similar Models (ë¹„êµ í…Œì´ë¸”)
```typescript
interface ModelComparison {
  models: Array<{
    name: string;
    accuracy: number;
    speed: number;
    size: string;
    bestFor: string;
    isCurrent?: boolean;  // Highlight current model
  }>;
}
```

**í…Œì´ë¸” í˜•ì‹**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model            â”‚ Accuracy â”‚ Speed â”‚ Size   â”‚ Best For    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ResNet-50 â­     â”‚ 80.4%    â”‚ 140   â”‚ 25.6M  â”‚ Baseline    â”‚
â”‚ EfficientNetV2-S â”‚ 84.3%    â”‚ 200   â”‚ 21.5M  â”‚ Efficiency  â”‚
â”‚ ViT-Base         â”‚ 84.5%    â”‚ 110   â”‚ 86M    â”‚ Accuracy    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Section 5: Visualization (ì‹œê°ì  ë¹„êµ)
```typescript
interface PerformancePlot {
  type: "scatter" | "bar" | "radar";
  xAxis: {
    label: string;     // "Speed (img/s)"
    min: number;
    max: number;
  };
  yAxis: {
    label: string;     // "Accuracy (%)"
    min: number;
    max: number;
  };
  points: Array<{
    name: string;
    x: number;
    y: number;
    isCurrent?: boolean;
    color?: string;
  }>;
}
```

**Scatter Plot** (Accuracy vs Speed):
- Xì¶•: Speed (img/s)
- Yì¶•: Accuracy (%)
- í¬ê¸°: Model size (ì‘ì€ ì› = ì‘ì€ ëª¨ë¸)
- ìƒ‰ìƒ: Framework (timm=íŒŒë‘, ultralytics=ì£¼í™©)
- í˜„ì¬ ëª¨ë¸: í…Œë‘ë¦¬ ê°•ì¡°

**ì˜ˆì‹œ**:
```
Accuracy
   â†‘
90%â”‚                    â— ViT-Large
   â”‚
85%â”‚        â— ViT-Base    â— EfficientNetV2
   â”‚
80%â”‚  â—‰ ResNet-50
   â”‚
75%â”‚ â— MobileNetV3
   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Speed
       50    100    150    200   (img/s)

â—‰ = Current model
â— = Other models
```

#### Section 6: Recommended Settings (ì‹¤ìš© ì •ë³´)
```typescript
interface RecommendedSettings {
  batchSize: {
    value: number;
    range: [number, number];  // [min, max]
    note?: string;
  };
  learningRate: {
    value: number;
    range: [number, number];
    note?: string;
  };
  epochs: {
    value: number;
    range: [number, number];
    note?: string;
  };
  imageSize: number;
  optimizer?: string;
  scheduler?: string;
}
```

**í‘œì‹œ í˜•ì‹**:
```
ğŸ”§ Recommended Settings

Batch Size:     32    (range: 16-64)
Learning Rate:  0.001 (range: 0.0001-0.01)
Epochs:         50    (range: 20-100)
Image Size:     224Ã—224
Optimizer:      Adam or AdamW
Scheduler:      Cosine annealing

ğŸ’¡ Tip: Start with default values and adjust based on your dataset
```

---

## Frontend êµ¬í˜„ ê³„íš

### Component êµ¬ì¡°

```typescript
// 1. ModelCard Component (ì¹´ë“œ)
interface ModelCardProps {
  model: ModelInfo;
  onSelect: (model: ModelInfo) => void;
  onShowGuide: (model: ModelInfo) => void;
}

// 2. ModelGuideDrawer Component (ìŠ¬ë¼ì´ë“œ íŒ¨ë„)
interface ModelGuideDrawerProps {
  model: ModelInfo;
  isOpen: boolean;
  onClose: () => void;
  onSelect: (model: ModelInfo) => void;
  similarModels: ModelInfo[];
}

// 3. ModelComparisonTable Component
interface ModelComparisonTableProps {
  models: ModelInfo[];
  currentModel: string;
  onModelClick: (model: ModelInfo) => void;
}

// 4. PerformanceScatterPlot Component
interface PerformanceScatterPlotProps {
  models: ModelInfo[];
  currentModel: string;
  xMetric: "speed" | "size";
  yMetric: "accuracy";
}
```

### íŒŒì¼ êµ¬ì¡°

```
mvp/frontend/components/training/
â”œâ”€â”€ ModelSelector.tsx              # ë©”ì¸ ëª¨ë¸ ì„ íƒ í˜ì´ì§€
â”œâ”€â”€ ModelCard.tsx                  # ëª¨ë¸ ì¹´ë“œ
â”œâ”€â”€ ModelGuideDrawer.tsx          # ìŠ¬ë¼ì´ë“œ íŒ¨ë„ (ê°€ì´ë“œ)
â”‚
â”œâ”€â”€ guide/                         # ê°€ì´ë“œ ì„œë¸Œ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ QuickStats.tsx            # Section 1
â”‚   â”œâ”€â”€ BenchmarkSection.tsx      # Section 2
â”‚   â”œâ”€â”€ UsageGuidance.tsx         # Section 3
â”‚   â”œâ”€â”€ ModelComparisonTable.tsx  # Section 4
â”‚   â”œâ”€â”€ PerformanceChart.tsx      # Section 5
â”‚   â””â”€â”€ RecommendedSettings.tsx   # Section 6
â”‚
â””â”€â”€ hooks/
    â”œâ”€â”€ useModelGuide.ts          # ê°€ì´ë“œ ë°ì´í„° fetch
    â””â”€â”€ useModelComparison.ts     # ë¹„êµ ëª¨ë¸ ê³„ì‚°
```

### API í™•ì¥

```typescript
// GET /api/v1/models/{framework}/{model_name}/guide
interface ModelGuideResponse {
  model: ModelInfo;
  quickStats: QuickStats;
  benchmark: Benchmark;
  usageGuidance: UsageGuidance;
  similarModels: ModelInfo[];
  recommendedSettings: RecommendedSettings;
  performanceData: {
    allModels: Array<{
      name: string;
      accuracy: number;
      speed: number;
      size: number;
    }>;
  };
}
```

---

## êµ¬í˜„ ìŠ¤ì¼€ì¤„ (Dayë³„)

### Day 1: P0 Infrastructure
```
Morning (4h):
- [ ] ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
- [ ] P0 4ê°œ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì‘ì„± (full guide í¬í•¨)
- [ ] API ì—”ë“œí¬ì¸íŠ¸: /models/list

Afternoon (4h):
- [ ] ModelCard ì»´í¬ë„ŒíŠ¸ (ê¸°ë³¸)
- [ ] ModelSelector í˜ì´ì§€ (ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒ)
- [ ] ê¸°ë³¸ í•„í„°ë§ (framework, tags)
```

### Day 2: P0 Guide System
```
Morning (4h):
- [ ] ModelGuideDrawer ì»´í¬ë„ŒíŠ¸ (ìŠ¬ë¼ì´ë“œ íŒ¨ë„)
- [ ] QuickStats ì„¹ì…˜
- [ ] BenchmarkSection ì„¹ì…˜
- [ ] UsageGuidance ì„¹ì…˜

Afternoon (4h):
- [ ] ModelComparisonTable ì„¹ì…˜
- [ ] PerformanceChart ì„¹ì…˜ (scatter plot)
- [ ] RecommendedSettings ì„¹ì…˜
- [ ] P0 4ê°œ ëª¨ë¸ë¡œ í†µí•© í…ŒìŠ¤íŠ¸
```

### Day 3: P0 Validation + P1 Start
```
Morning (3h):
- [ ] P0 4ê°œ ëª¨ë¸ í•™ìŠµ í…ŒìŠ¤íŠ¸
- [ ] UI/UX ê°œì„  (í”¼ë“œë°± ë°˜ì˜)
- [ ] ê°€ì´ë“œ ì •ë³´ ê²€ì¦

Afternoon (5h):
- [ ] P1 12ê°œ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì‘ì„±
- [ ] ê°€ì´ë“œ ì •ë³´ ì‘ì„± (ê°„ëµí™” ê°€ëŠ¥)
- [ ] APIì— P1 ëª¨ë¸ ì¶”ê°€
```

### Day 4: P1 Completion
```
All day (8h):
- [ ] P1 ëª¨ë¸ UI í†µí•©
- [ ] í•„í„°ë§ ê³ ë„í™” (ë‹¤ì¤‘ íƒœê·¸, ê²€ìƒ‰)
- [ ] ì •ë ¬ ê¸°ëŠ¥ (accuracy, speed, size)
- [ ] P1 ì£¼ìš” ëª¨ë¸ í•™ìŠµ í…ŒìŠ¤íŠ¸
```

### Day 5: P2 Models
```
All day (8h):
- [ ] P2 15ê°œ ëª¨ë¸ ë©”íƒ€ë°ì´í„°
- [ ] YOLO-World íŠ¹ìˆ˜ ì²˜ë¦¬ (open-vocab)
- [ ] YOLOv10, OBB ë“± íŠ¹ìˆ˜ task ì§€ì›
- [ ] UIì— P2 ëª¨ë¸ í†µí•©
```

### Day 6-7: Polish & Documentation
```
Day 6:
- [ ] ëª¨ë“  ëª¨ë¸ ì¹´í…Œê³ ë¦¬ ê²€ì¦
- [ ] ê°€ì´ë“œ ì •ë³´ ì™„ì„±ë„ í™•ì¸
- [ ] UI/UX ìµœì¢… ê°œì„ 
- [ ] ì„±ëŠ¥ ìµœì í™” (lazy loading, caching)

Day 7:
- [ ] Week 1 ê²€ì¦ ë¦¬í¬íŠ¸ ì‘ì„±
- [ ] ì‚¬ìš©ì ê°€ì´ë“œ ë¬¸ì„œ ì‘ì„±
- [ ] ìŠ¤í¬ë¦°ìƒ· ë° ë°ëª¨ ì˜ìƒ
- [ ] Week 2 (Docker) ì¤€ë¹„
```

---

## íš¨ê³¼ì ì¸ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ ì „ëµ

### 1. ì‚¬ìš©ì ì—¬ì • (User Journey)

```
Step 1: ëª©ì  íŒŒì•…
"ì–´ë–¤ ì‘ì—…ì„ í•˜ì‹œë‚˜ìš”?"
â†’ Classification / Detection / Segmentation

Step 2: ì œì•½ ì¡°ê±´ í™•ì¸
"ì–´ë–¤ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ì‹œë‚˜ìš”?"
â†’ Cloud / Edge / Mobile
â†’ GPU available? Memory limit?

Step 3: ìš°ì„ ìˆœìœ„ ì„¤ì •
"ë¬´ì—‡ì´ ê°€ì¥ ì¤‘ìš”í•œê°€ìš”?"
â†’ Accuracy / Speed / Size

Step 4: ëª¨ë¸ ì¶”ì²œ
Top 3 ëª¨ë¸ ì œì‹œ (ì´ìœ ì™€ í•¨ê»˜)

Step 5: ìƒì„¸ ë¹„êµ
ê°€ì´ë“œ íŒ¨ë„ë¡œ ì‹¬ì¸µ ì •ë³´ í™•ì¸
```

### 2. ì¸í„°ë™í‹°ë¸Œ í•„í„° (Smart Filtering)

```typescript
// ì§ˆë¬¸ ê¸°ë°˜ í•„í„°
interface SmartFilter {
  questions: [
    {
      id: "purpose",
      question: "What's your use case?",
      options: [
        { label: "Image Classification", filter: { task: "classification" } },
        { label: "Object Detection", filter: { task: "detection" } },
        { label: "Segmentation", filter: { task: "segmentation" } }
      ]
    },
    {
      id: "environment",
      question: "Where will you deploy?",
      options: [
        { label: "Cloud (GPU)", filter: { tags: ["production", "accurate"] } },
        { label: "Edge Device", filter: { tags: ["mobile", "lightweight"] } },
        { label: "Desktop (CPU)", filter: { tags: ["efficient", "balanced"] } }
      ]
    },
    {
      id: "priority",
      question: "What matters most?",
      options: [
        { label: "Accuracy", sort: "accuracy", desc: true },
        { label: "Speed", sort: "speed", desc: true },
        { label: "Small Size", sort: "size", desc: false }
      ]
    }
  ];
}
```

**UI Flow**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¯ Find the Right Model                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  What's your use case?                          â”‚
â”‚  â—‹ Image Classification                         â”‚
â”‚  â—‹ Object Detection                             â”‚
â”‚  â—‹ Segmentation                                 â”‚
â”‚                                                  â”‚
â”‚  Where will you deploy?                         â”‚
â”‚  â—‹ Cloud (GPU available)                        â”‚
â”‚  â—‹ Edge Device (limited resources)              â”‚
â”‚  â—‹ Desktop (CPU only)                           â”‚
â”‚                                                  â”‚
â”‚  What matters most?                             â”‚
â”‚  â—‹ Accuracy  â—‹ Speed  â—‹ Small Size              â”‚
â”‚                                                  â”‚
â”‚  [Show Recommended Models]                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Recommended for You                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  1ï¸âƒ£ YOLOv11m (â­ Best Match)                    â”‚
â”‚     Why: Balanced accuracy/speed for cloud GPU  â”‚
â”‚     [Select]  [Learn More]                      â”‚
â”‚                                                  â”‚
â”‚  2ï¸âƒ£ YOLOv11n                                    â”‚
â”‚     Why: If you need faster inference           â”‚
â”‚     [Select]  [Learn More]                      â”‚
â”‚                                                  â”‚
â”‚  3ï¸âƒ£ YOLOv11l                                    â”‚
â”‚     Why: If accuracy is critical                â”‚
â”‚     [Select]  [Learn More]                      â”‚
â”‚                                                  â”‚
â”‚  [See All Models]                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. ì‹œê°ì  ì˜ì‚¬ê²°ì • ë„êµ¬

#### Decision Tree Visualization
```
Start
  â”‚
  â”œâ”€ Classification?
  â”‚   â”œâ”€ Mobile? â†’ MobileNetV3/V4
  â”‚   â”œâ”€ Accurate? â†’ ViT, EfficientNetV2
  â”‚   â””â”€ Baseline? â†’ ResNet-50
  â”‚
  â””â”€ Detection?
      â”œâ”€ Edge? â†’ YOLOv11n
      â”œâ”€ Balanced? â†’ YOLOv11m
      â”œâ”€ Accurate? â†’ YOLOv11l
      â””â”€ Custom objects? â†’ YOLO-World
```

#### Performance Quadrant
```
        High Accuracy
            â†‘
            â”‚
    Slow    â”‚    Fast
    â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â†’
            â”‚
            â”‚
        Low Accuracy
```

ëª¨ë¸ë“¤ì„ quadrantì— ë°°ì¹˜í•˜ì—¬ ì‹œê°í™”

### 4. ì»¨í…ìŠ¤íŠ¸ ë„ì›€ë§ (Tooltips)

ëª¨ë“  ìš©ì–´ì— hover tooltip:
```typescript
const glossary = {
  "mAP": "Mean Average Precision - Primary metric for object detection",
  "Top-1 Accuracy": "Percentage where the model's #1 prediction is correct",
  "Top-5 Accuracy": "Percentage where correct answer is in top 5 predictions",
  "FPS": "Frames Per Second - How many images processed per second",
  "Params": "Number of trainable parameters - Roughly indicates model size",
  "Transfer Learning": "Using a pre-trained model as starting point",
  // ... more terms
};
```

### 5. Real-world Examples (ì‹¤ì œ ì‚¬ë¡€)

ê° ëª¨ë¸ë§ˆë‹¤ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€:
```typescript
interface RealWorldExample {
  title: string;
  description: string;
  company?: string;
  metrics: {
    before?: string;
    after: string;
  };
  link?: string;
}

// ResNet-50 ì˜ˆì‹œ
const resnet50Examples = [
  {
    title: "Medical Image Classification",
    description: "Stanford University used ResNet-50 for pneumonia detection from chest X-rays",
    metrics: {
      after: "93% accuracy, comparable to radiologists"
    },
    link: "https://..."
  },
  {
    title: "E-commerce Product Categorization",
    description: "Major retailer uses ResNet-50 for automatic product tagging",
    metrics: {
      before: "Manual tagging: 100 products/hour",
      after: "Automated: 10,000 products/hour"
    }
  }
];
```

---

## ì„±ê³µ ì§€í‘œ

### Week 1 ì¢…ë£Œ ì‹œ

**ì •ëŸ‰ì **:
- [ ] P0 4ê°œ ëª¨ë¸ 100% ë™ì‘
- [ ] P1 12ê°œ ëª¨ë¸ 100% ë™ì‘
- [ ] P2 15ê°œ ëª¨ë¸ 80% ì´ìƒ ë™ì‘
- [ ] ê°€ì´ë“œ ì‹œìŠ¤í…œ ì™„ì„±ë„ 90%

**ì •ì„±ì **:
- [ ] ëª¨ë¸ ì„ íƒì´ ì§ê´€ì 
- [ ] ê°€ì´ë“œ ì •ë³´ê°€ ìœ ìš©í•¨
- [ ] ë¹„êµ ê¸°ëŠ¥ì´ íš¨ê³¼ì 
- [ ] ì¶”ì²œ ê¸°ëŠ¥ì´ ì •í™•í•¨

---

## ë‹¤ìŒ ë‹¨ê³„ (Week 2)

Week 1 ì™„ë£Œ í›„:
1. **ê²€ì¦ ë¦¬í¬íŠ¸**
   - ê° ëª¨ë¸ ì„±ëŠ¥ ê¸°ë¡
   - ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
   - ê°€ì´ë“œ ì‹œìŠ¤í…œ íš¨ê³¼ ë¶„ì„

2. **Docker ë¶„ë¦¬ ì¤€ë¹„**
   - Week 1 ê²½í—˜ ë°˜ì˜
   - ì˜ì¡´ì„± ë²„ì „ í™•ì¸
   - Platform SDK ì„¤ê³„ ê°œì„ 

---

*Document Version: 3.0*
*Created: 2025-10-30*
*Author: Vision AI Platform Team*
