# Vision AI Training Platform

> ìì—°ì–´ë¡œ Vision ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” AI í”Œë«í¼

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/)
[![Node](https://img.shields.io/badge/node-20.x-green.svg)](https://nodejs.org/)

## ğŸ¯ ê°œìš”

Vision AI Training Platformì€ ê°œë°œìê°€ ìì—°ì–´ë¡œ ëŒ€í™”í•˜ë“¯ Vision ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- ğŸ—£ï¸ ìì—°ì–´ ê¸°ë°˜ ëª¨ë¸ ì„¤ì •
- ğŸš€ ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì§€ì› (timm, Ultralytics YOLO ë“±)
- ğŸ“Š ì‹¤ì‹œê°„ í•™ìŠµ ëª¨ë‹ˆí„°ë§ (ClearML, MLflow, W&B, Database - ì„ íƒ ê°€ëŠ¥)
- ğŸ”„ Temporal ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- ğŸ”Œ ì›í´ë¦­ ì¶”ë¡  API ìƒì„±
- ğŸ¨ ì§ê´€ì ì¸ UI/UX

**í˜„ì¬ ìƒíƒœ:**
- âœ… **Production-ready Platform** - Temporal orchestration, multi-backend observability, microservice architecture
- ğŸš€ **Active Development** - Continuous improvements and feature additions

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### Platform ì•„í‚¤í…ì²˜
```
3-Tier Environment Support:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 1: Subprocess (Local Dev)                 â”‚
â”‚   - Training in subprocess                     â”‚
â”‚   - MinIO (local), MLflow (local)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 2: Kind (K8s Dev)                         â”‚
â”‚   - Training in Kubernetes Jobs               â”‚
â”‚   - MinIO (cluster), MLflow (cluster)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 3: Production (AWS/GCP)                   â”‚
â”‚   - Training in Kubernetes Jobs               â”‚
â”‚   - S3/R2, MLflow (production)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

[Platform ì•„í‚¤í…ì²˜ ìƒì„¸ â†’](platform/docs/architecture/)

## ğŸš€ Quick Start

> **ì²˜ìŒ ì‹œì‘í•˜ì‹œë‚˜ìš”?** [Platform ì‹œì‘ ê°€ì´ë“œ](platform/README.md)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### Prerequisites
```bash
- Docker Desktop 4.26+
- Python 3.11+
- Node.js 20.x+
- Poetry (Python package manager)
- pnpm (Node package manager)
```

### Installation (Windows)
```powershell
# Python & Poetry
winget install Python.Python.3.11
pip install poetry

# Node.js & pnpm
winget install OpenJS.NodeJS
npm install -g pnpm
```

### Development Environment

**Tier 0: Docker Compose (Recommended for local dev)**
```bash
# 1. Clone repository
git clone https://github.com/your-org/mvp-vision-ai-platform.git
cd mvp-vision-ai-platform/platform

# 2. Start infrastructure
cd infrastructure
docker-compose up -d

# 3. Initialize database
cd ../backend
python init_db.py

# 4. Start backend
poetry install
poetry run uvicorn app.main:app --reload --port 8000

# 5. Start frontend (new terminal)
cd ../frontend
pnpm install
pnpm dev

# Access:
# - Frontend:  http://localhost:3000
# - Backend:   http://localhost:8000
# - ClearML:   http://localhost:8080
# - MLflow:    http://localhost:5000
# - Grafana:   http://localhost:3200
```

[Full Development Guide â†’](platform/README.md)

## ğŸ“¦ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
mvp-vision-ai-platform/
â”œâ”€â”€ platform/                 # âœ… Production Platform (Active Development)
â”‚   â”œâ”€â”€ backend/              # FastAPI backend with Temporal orchestration
â”‚   â”œâ”€â”€ frontend/             # Next.js 14 frontend
â”‚   â”œâ”€â”€ trainers/             # Framework trainers (timm, ultralytics)
â”‚   â”œâ”€â”€ infrastructure/       # Docker Compose, K8s configs
â”‚   â”œâ”€â”€ charts/               # Helm charts for K8s deployment
â”‚   â””â”€â”€ docs/                 # Platform documentation
â”‚
â”œâ”€â”€ docs/                     # Project-wide documentation
â”‚   â”œâ”€â”€ todo/                 # Implementation tracking
â”‚   â”œâ”€â”€ architecture/         # System design docs
â”‚   â”œâ”€â”€ planning/             # Feature plans
â”‚   â””â”€â”€ CONVERSATION_LOG.md   # Development history
â”‚
â”œâ”€â”€ infrastructure/           # Shared infrastructure configs
â””â”€â”€ README.md                 # This file
```

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

**Core Technologies:**
- Frontend: Next.js 14, React 18, TailwindCSS, Zustand
- Backend: FastAPI, Python 3.11, PostgreSQL
- Training: PyTorch, timm, Ultralytics YOLO
- Orchestration: Temporal Workflow Engine
- Storage: PostgreSQL, Redis, MinIO/S3/R2
- Observability: ClearML, MLflow, Database (multi-backend adapter pattern)
- Monitoring: Prometheus, Grafana
- Infrastructure: Docker Compose, Kubernetes, Helm

[Full Tech Stack Details â†’](platform/README.md)

## ğŸ“– ë¬¸ì„œ

### Platform Documentation
- [Platform README](platform/README.md) - Overview and quick start
- [Backend Guide](platform/backend/README.md) - Backend development
- [Implementation Tracking](docs/todo/IMPLEMENTATION_TO_DO_LIST.md) - Progress tracking
- [Architecture](platform/docs/architecture/) - System design
- [Development Guides](platform/docs/development/) - Development workflows
- [ì„¤ê³„ ë¦¬ë·°](platform/docs/reviews/)

### ê³µìš© ë¬¸ì„œ
- [ê°œë°œ íˆìŠ¤í† ë¦¬](docs/CONVERSATION_LOG.md)

## ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ

### ìì—°ì–´ë¡œ ëª¨ë¸ í•™ìŠµ

```
User: "YOLO11nìœ¼ë¡œ ê°ì²´ íƒì§€ ëª¨ë¸ ë§Œë“¤ì–´ì¤˜. í´ë˜ìŠ¤ëŠ” person, car, dog"

AI: ì•Œê² ìŠµë‹ˆë‹¤! ë‹¤ìŒ ì„¤ì •ìœ¼ë¡œ ì§„í–‰í• ê²Œìš”:
    - Model: yolo11n
    - Task: Object Detection
    - Classes: person, car, dog (3ê°œ)
    - Epochs: 100 (ê¶Œì¥)
    - Image Size: 640x640

    ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. (YOLO format)

User: "data/coco-subset"

AI: í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤! ğŸš€
    MLflow Run: http://localhost:30500/#/experiments/1/runs/abc123
```

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

- ğŸ“Š Epoch ì§„í–‰ë¥ , Loss/mAP ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- ğŸ’» GPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (Prometheus + Grafana)
- ğŸ“ˆ Training Metrics ì‹œê°í™” (MLflow)
- ğŸ”” í•™ìŠµ ì™„ë£Œ WebSocket ì•Œë¦¼

### ì¶”ë¡  API ìƒì„± (planned)

í•™ìŠµ ì™„ë£Œ í›„ ì›í´ë¦­ìœ¼ë¡œ REST API ìƒì„±:

```bash
curl -X POST https://api.vision-platform.com/inference/{job_id}/predict \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "image=@sample.jpg"

# Response
{
  "predictions": [
    {"class": "person", "confidence": 0.95, "bbox": [10, 20, 100, 200]},
    {"class": "car", "confidence": 0.87, "bbox": [150, 30, 300, 250]}
  ]
}
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤! [CONTRIBUTING.md](CONTRIBUTING.md)ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“Š ê°œë°œ í˜„í™©

### âœ… MVP Phase (ì™„ë£Œ)
- [x] ê¸°ë³¸ UI/UX (Chat ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤)
- [x] ìì—°ì–´ íŒŒì‹± (Gemini LLM)
- [x] timm ëª¨ë¸ ì§€ì› (ResNet, EfficientNet)
- [x] Ultralytics YOLO ì§€ì› (Detection, Segmentation, Pose)
- [x] Kubernetes í•™ìŠµ ì‹¤í–‰ (Kind)
- [x] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (MLflow + Prometheus + Grafana)
- [x] ì½œë°± ê¸°ë°˜ í•™ìŠµ ìƒíƒœ ì—…ë°ì´íŠ¸

### âœ… Platform Phase (ì§„í–‰ ì¤‘)
- [x] 3-Tier í™˜ê²½ ê²©ë¦¬ ì„¤ê³„
- [x] ì—ëŸ¬ í•¸ë“¤ë§ ì„¤ê³„
- [x] í†µí•© ì‹¤íŒ¨ ì²˜ë¦¬ ì„¤ê³„
- [x] ìš´ì˜ ê°€ì´ë“œ ì‘ì„±
- [x] Framework-specific Training Services (Ultralytics, timm)
- [x] Temporal ì›Œí¬í”Œë¡œìš° í†µí•© (Phase 12)
- [x] Observability ë©€í‹°ë°±ì—”ë“œ ì§€ì› (Phase 13: ClearML, MLflow, W&B, Database)
- [x] ë°ì´í„°ì…‹ ìµœì í™” ë° ìºì‹± (Phase 12.9)
- [ ] í”„ë¡œë•ì…˜ ë°°í¬ (AWS/GCP)
- [ ] Auto-scaling
- [ ] Multi-tenancy

### ğŸ”® Future (ê³„íš)
- [ ] HuggingFace Transformers ì§€ì›
- [ ] MMDetection/MMSegmentation ì§€ì›
- [ ] ë¶„ì‚° í•™ìŠµ (multi-GPU, multi-node)
- [ ] Cost optimization
- [ ] Enterprise ê¸°ëŠ¥

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License - [LICENSE](LICENSE) íŒŒì¼ ì°¸ê³ 

## ğŸ“§ ë¬¸ì˜

- ì´ìŠˆ: [GitHub Issues](https://github.com/your-org/mvp-vision-ai-platform/issues)
- ì´ë©”ì¼: team@vision-platform.com

## ğŸ™ ê°ì‚¬ì˜ ë§

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë“¤ì˜ ë„ì›€ì„ ë°›ì•˜ìŠµë‹ˆë‹¤:

- [PyTorch](https://pytorch.org/)
- [timm](https://github.com/huggingface/pytorch-image-models)
- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- [MLflow](https://mlflow.org/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Next.js](https://nextjs.org/)
- [Prometheus](https://prometheus.io/)
- [Grafana](https://grafana.com/)

---

Made with â¤ï¸ by Vision AI Team
