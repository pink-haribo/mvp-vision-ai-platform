"""
MMSegmentation Default Config Template

This module provides the default MMEngine config template for MMSegmentation training.
The template is used by train.py to generate runtime config files.

Usage:
    from default_config import get_config_template
    config_str = get_config_template(
        model_name='segformer_mit-b2',
        dataset_dir='/path/to/dataset',
        work_dir='/path/to/work_dir',
        ...
    )
"""


def get_config_template(
    model_name: str,
    dataset_dir: str,
    work_dir: str,
    num_classes: int,
    base_config: str,
    pretrained_url: str = None,
    # Training parameters
    epochs: int = 80,
    batch_size: int = 4,
    learning_rate: float = 0.01,
    weight_decay: float = 0.0005,
    val_interval: int = 1,
    crop_size: tuple = (512, 512),
    iters_per_epoch: int = 250,
) -> str:
    """
    Generate MMSegmentation config content.

    Args:
        model_name: Model name (e.g., 'segformer_mit-b2')
        dataset_dir: Path to dataset directory
        work_dir: Working directory for outputs
        num_classes: Number of classes
        base_config: Base config file path
        pretrained_url: URL to pretrained weights
        epochs: Number of training epochs
        batch_size: Batch size per GPU
        learning_rate: Base learning rate
        weight_decay: Weight decay for optimizer
        val_interval: Validation interval (epochs)
        crop_size: Random crop size (height, width)
        iters_per_epoch: Iterations per epoch (for iter-based training)

    Returns:
        Config file content as string
    """
    # Convert epochs to iterations
    max_iters = epochs * iters_per_epoch
    val_interval_iters = val_interval * iters_per_epoch

    # Load pretrained weights line
    load_from_line = f"load_from = '{pretrained_url}'" if pretrained_url else ""

    return f'''# Auto-generated MMSegmentation config for {model_name}
# Generated by Vision AI Platform

_base_ = 'mmseg::segmentation/{base_config}'

# Dataset settings
data_root = '{dataset_dir}'

# Override number of classes
num_classes = {num_classes}

# Model modifications for custom classes
model = dict(
    decode_head=dict(num_classes={num_classes}),
    auxiliary_head=dict(num_classes={num_classes}) if hasattr(_base_.model, 'auxiliary_head') else None
)

# Custom dataset
train_dataloader = dict(
    batch_size={batch_size},
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='InfiniteSampler', shuffle=True),
    dataset=dict(
        type='BaseSegDataset',
        data_root=data_root,
        data_prefix=dict(
            img_path='images/train',
            seg_map_path='annotations/train'
        ),
        img_suffix='.jpg',
        seg_map_suffix='.png',
        reduce_zero_label=False,
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='RandomResize', scale=(2048, {crop_size[0]}), ratio_range=(0.5, 2.0), keep_ratio=True),
            dict(type='RandomCrop', crop_size={crop_size}, cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs')
        ]
    )
)

val_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='BaseSegDataset',
        data_root=data_root,
        data_prefix=dict(
            img_path='images/val',
            seg_map_path='annotations/val'
        ),
        img_suffix='.jpg',
        seg_map_suffix='.png',
        reduce_zero_label=False,
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', scale=(2048, {crop_size[0]}), keep_ratio=True),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs')
        ]
    )
)

test_dataloader = val_dataloader

# Evaluator
val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU', 'mDice', 'mFscore'])
test_evaluator = val_evaluator

# Training schedule (iteration-based)
train_cfg = dict(type='IterBasedTrainLoop', max_iters={max_iters}, val_interval={val_interval_iters})
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

# Optimizer
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(type='SGD', lr={learning_rate}, momentum=0.9, weight_decay={weight_decay}),
    clip_grad=None
)

# Learning rate scheduler (poly schedule for segmentation)
param_scheduler = [
    dict(type='PolyLR', eta_min=1e-4, power=0.9, begin=0, end={max_iters}, by_epoch=False)
]

# Runtime settings
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', by_epoch=False, interval={val_interval_iters}, save_best='mIoU', rule='greater'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='SegVisualizationHook')
)

# Work directory
work_dir = '{work_dir}'

# Randomness
randomness = dict(seed=42)

{load_from_line}
'''
