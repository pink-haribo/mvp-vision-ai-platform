version: '3.8'

# Tier-0 Infrastructure
# Lightweight infrastructure for local development without Kubernetes
# Use this when:
# - Your PC has limited resources
# - You want faster startup times
# - You're doing rapid development iteration
# - You don't need Kubernetes-specific features

services:
  # PostgreSQL - Platform database (projects, datasets, training jobs, etc.)
  postgres:
    image: postgres:16
    container_name: platform-postgres-tier0
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: devpass
      POSTGRES_DB: platform
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=en_US.UTF-8"
    volumes:
      - postgres-data-tier0:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d platform"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - platform-tier0

  # PostgreSQL - Shared User database (Phase 11: Microservice Separation)
  # Shared between Platform and Labeler services
  # Contains: users, organizations, invitations, project_members, sessions
  postgres-user:
    image: postgres:16
    container_name: platform-postgres-user-tier0
    restart: unless-stopped
    ports:
      - "5433:5432"  # Port 5433 on host to avoid conflict
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: devpass
      POSTGRES_DB: users
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=en_US.UTF-8"
    volumes:
      - postgres-user-data-tier0:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d users"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - platform-tier0

  # Redis - Cache and session store
  redis:
    image: redis:7.2-alpine
    container_name: platform-redis-tier0
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data-tier0:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s
    networks:
      - platform-tier0

  # MinIO-Datasets - S3-compatible object storage for datasets and images
  minio-datasets:
    image: minio/minio:latest
    container_name: platform-minio-datasets-tier0
    restart: unless-stopped
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # Console UI
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9001
    volumes:
      - minio-datasets-data-tier0:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 30s
    networks:
      - platform-tier0

  # MinIO-Results - S3-compatible object storage for checkpoints, weights, configs
  minio-results:
    image: minio/minio:latest
    container_name: platform-minio-results-tier0
    restart: unless-stopped
    ports:
      - "9002:9000"   # API (mapped to 9002 on host)
      - "9003:9001"   # Console UI (mapped to 9003 on host)
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9003
    volumes:
      - minio-results-data-tier0:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 30s
    networks:
      - platform-tier0

  # MinIO Setup - Create buckets in both storage instances
  minio-setup:
    image: minio/mc:latest
    container_name: platform-minio-setup-tier0
    depends_on:
      minio-datasets:
        condition: service_healthy
      minio-results:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for MinIO instances to be ready...';
      sleep 5;

      echo '=== Setting up MinIO-Datasets (S3-A) ===';
      mc alias set datasets http://minio-datasets:9000 minioadmin minioadmin;
      echo 'Creating dataset buckets...';
      mc mb datasets/training-datasets --ignore-existing;
      mc mb datasets/vision-platform-dev --ignore-existing;
      echo 'Dataset buckets:';
      mc ls datasets;

      echo '';
      echo '=== Setting up MinIO-Results (S3-B) ===';
      mc alias set results http://minio-results:9000 minioadmin minioadmin;
      echo 'Creating result buckets...';
      mc mb results/training-checkpoints --ignore-existing;
      mc mb results/training-results --ignore-existing;
      mc mb results/model-weights --ignore-existing;
      mc mb results/config-schemas --ignore-existing;
      # mlflow-artifacts bucket removed - using ClearML (Phase 12.2)
      mc mb results/vision-platform-results --ignore-existing;
      echo 'Result buckets:';
      mc ls results;

      echo '';
      echo '=== Dual Storage Setup Complete ===';
      echo 'Datasets Storage: http://localhost:9000 (Console: http://localhost:9001)';
      echo 'Results Storage:  http://localhost:9002 (Console: http://localhost:9003)';
      "
    networks:
      - platform-tier0

  # MLflow removed - replaced by ClearML (Phase 12.2)
  # Use infrastructure/docker-compose.clearml.yaml for ClearML services

  # Temporal - Workflow orchestration
  temporal:
    image: temporalio/auto-setup:1.22.4
    container_name: platform-temporal-tier0
    restart: unless-stopped
    ports:
      - "7233:7233"   # gRPC
      - "8233:8233"   # Web UI
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=admin
      - POSTGRES_PWD=devpass
      - POSTGRES_SEEDS=postgres
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "tctl", "--address", "localhost:7233", "cluster", "health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - platform-tier0

  # ================================
  # Observability Stack
  # ================================

  # Prometheus - Metrics collection and storage
  prometheus:
    image: prom/prometheus:latest
    container_name: platform-prometheus-tier0
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data-tier0:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - platform-tier0
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Grafana - Visualization and dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: platform-grafana-tier0
    restart: unless-stopped
    ports:
      - "3200:3000"  # Port 3200 to avoid conflict with Frontend on 3000
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3200
      - GF_INSTALL_PLUGINS=
    volumes:
      - ./grafana/datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml:ro
      - grafana-data-tier0:/var/lib/grafana
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - platform-tier0

  # Loki - Log aggregation
  loki:
    image: grafana/loki:latest
    container_name: platform-loki-tier0
    restart: unless-stopped
    ports:
      - "3100:3100"
      - "9096:9096"
    volumes:
      - ./loki/loki-config.yml:/etc/loki/loki-config.yml:ro
      - loki-data-tier0:/loki
    command: -config.file=/etc/loki/loki-config.yml
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - platform-tier0

networks:
  platform-tier0:
    name: platform-tier0
    driver: bridge

volumes:
  # Shared persistent storage (same path for Tier-0 and Tier-1)
  # Data persists across tier migrations
  postgres-data-tier0:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: C:/platform-data/postgres

  # Phase 11: Shared User DB (Platform + Labeler)
  postgres-user-data-tier0:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: C:/platform-data/postgres-user

  redis-data-tier0:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: C:/platform-data/redis

  minio-datasets-data-tier0:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: C:/platform-data/minio-datasets

  minio-results-data-tier0:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: C:/platform-data/minio-results

  prometheus-data-tier0:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: C:/platform-data/prometheus

  grafana-data-tier0:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: C:/platform-data/grafana

  loki-data-tier0:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: C:/platform-data/loki

# Usage:
# Start:  docker-compose -f docker-compose.tier0.yaml up -d
# Stop:   docker-compose -f docker-compose.tier0.yaml down
# Logs:   docker-compose -f docker-compose.tier0.yaml logs -f [service]
# Reset:  docker-compose -f docker-compose.tier0.yaml down -v  (WARNING: deletes all data)
