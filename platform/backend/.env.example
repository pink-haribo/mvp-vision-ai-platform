# ================================
# Backend Environment Variables (Local Development)
# ================================

# ==========================================
# LLM API (REQUIRED)
# ==========================================
GOOGLE_API_KEY=your-gemini-api-key-here
LLM_MODEL=gemini-2.5-flash-lite

# ==========================================
# Database
# ==========================================
# Platform DB: Projects, training jobs, datasets, etc.
DATABASE_URL=sqlite:///../../mvp/data/db/vision_platform.db

# ==========================================
# Shared User Database (Phase 11: Microservice Separation)
# ==========================================
# Shared between Platform and Labeler for user authentication
# Tier 1 (Local): SQLite file (default: C:\temp\shared_users.db on Windows, /tmp/shared_users.db on Linux/Mac)
# Tier 2 (Railway): PostgreSQL (e.g., postgresql://user:password@railway.app:5432/users)
# Tier 3 (K8s): PostgreSQL StatefulSet (e.g., postgresql://user:password@postgres-user:5432/users)
# USER_DATABASE_URL=sqlite:///C:/temp/shared_users.db

# ==========================================
# Redis (Multi-backend State Management - Phase 5)
# ==========================================
# Redis URL for session store, pub/sub, and caching
# Local development: Use localhost with DB 0 (production uses DB 0, tests use DB 15)
# Production: Use managed Redis service (Railway, AWS ElastiCache, etc.)
REDIS_URL=redis://localhost:6379/0

# ==========================================
# Paths (relative to mvp/backend directory)
# ==========================================
UPLOAD_DIR=../../mvp/data/uploads
OUTPUT_DIR=../../mvp/data/outputs
MODEL_DIR=../../mvp/data/models
LOG_DIR=../../mvp/data/logs

# ==========================================
# Backend API
# ==========================================
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
FRONTEND_PORT=3000

# ==========================================
# Training Defaults
# ==========================================
DEFAULT_EPOCHS=50
DEFAULT_BATCH_SIZE=32
DEFAULT_LEARNING_RATE=0.001

# ==========================================
# Training Services (HTTP API - Microservice Architecture)
# ==========================================
# Framework-specific service URLs (Railway production uses separate services)
TIMM_SERVICE_URL=http://localhost:8001
ULTRALYTICS_SERVICE_URL=http://localhost:8002
HUGGINGFACE_SERVICE_URL=http://localhost:8003

# Fallback URL (if framework-specific URL not set)
TRAINING_SERVICE_URL=http://localhost:8001

# ==========================================
# Labeler Service (Phase 11.5: Dataset Service Integration)
# ==========================================
# Labeler Backend API for dataset metadata (Single Source of Truth)
# Local development: localhost:8011
# Production: Separate Railway service
LABELER_API_URL=http://localhost:8011

# Service-to-Service authentication key (Platform â†’ Labeler)
# Generate with: openssl rand -base64 32
# IMPORTANT: Use different keys for dev/prod environments
LABELER_SERVICE_KEY=dev-labeler-service-key-change-in-production

# ==========================================
# Dual Storage Architecture (Internal + External)
# ==========================================
# Internal Storage: Pretrained weights, checkpoints, config schemas (MinIO - Backend location)
# External Storage: Training datasets, user uploads (S3/R2 - Cloud storage)

# Local Development: Both use same MinIO instance
INTERNAL_STORAGE_ENDPOINT=http://localhost:30900
INTERNAL_STORAGE_ACCESS_KEY=minioadmin
INTERNAL_STORAGE_SECRET_KEY=minioadmin

EXTERNAL_STORAGE_ENDPOINT=http://localhost:30900
EXTERNAL_STORAGE_ACCESS_KEY=minioadmin
EXTERNAL_STORAGE_SECRET_KEY=minioadmin

# Production Example:
# Internal Storage (MinIO - same location as Backend):
# INTERNAL_STORAGE_ENDPOINT=http://minio.backend.svc.cluster.local:9000
# INTERNAL_STORAGE_ACCESS_KEY=your_minio_access_key
# INTERNAL_STORAGE_SECRET_KEY=your_minio_secret_key

# External Storage (Cloudflare R2):
# EXTERNAL_STORAGE_ENDPOINT=https://your-account-id.r2.cloudflarestorage.com
# EXTERNAL_STORAGE_ACCESS_KEY=your_r2_access_key
# EXTERNAL_STORAGE_SECRET_KEY=your_r2_secret_key

# Internal Storage Buckets (MinIO - Backend location)
INTERNAL_BUCKET_WEIGHTS=model-weights
INTERNAL_BUCKET_CHECKPOINTS=training-checkpoints
INTERNAL_BUCKET_SCHEMAS=config-schemas

# External Storage Buckets (S3/R2 - Cloud)
EXTERNAL_BUCKET_DATASETS=training-datasets

# ==========================================
# Legacy Storage Configuration (for backward compatibility)
# ==========================================
# These are deprecated in favor of INTERNAL_/EXTERNAL_ settings above
AWS_S3_ENDPOINT_URL=http://localhost:30900
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin
S3_BUCKET_DATASETS=training-datasets
S3_BUCKET_CHECKPOINTS=training-checkpoints
S3_BUCKET_RESULTS=training-results

# ==========================================
# MLflow Tracking
# ==========================================
# Local Dev (Kubernetes): Use NodePort
MLFLOW_TRACKING_URI=http://localhost:30500
# Production (Railway): Use internal service URL
# MLFLOW_TRACKING_URI=http://mlflow.monitoring.svc.cluster.local:5000

# ==========================================
# Loki Log Aggregation
# ==========================================
# Loki endpoint for log queries
LOKI_URL=http://localhost:3100

# ==========================================
# Backend Internal API (for Training Service callbacks)
# ==========================================
BACKEND_INTERNAL_URL=http://localhost:8000/internal
BACKEND_INTERNAL_AUTH_TOKEN=dev-internal-token-123

# ==========================================
# CORS
# ==========================================
CORS_ORIGINS=http://localhost:3000

# ==========================================
# Logging
# ==========================================
LOG_LEVEL=INFO

# ==========================================
# Development Settings
# ==========================================
DEBUG=true
RELOAD=true
ENVIRONMENT=development

# ==========================================
# Training Execution Mode
# ==========================================
# Options: "subprocess" (local dev), "kubernetes" (production)
# - subprocess: Run training locally in a subprocess (for development/testing)
# - kubernetes: Run training as Kubernetes Job (requires Docker image and K8s cluster)
TRAINING_EXECUTOR=subprocess

# ==========================================
# GPU Settings (for subprocess mode)
# ==========================================
# USE_GPU: Enable/disable GPU usage (true/false)
# CUDA_VISIBLE_DEVICES: GPU device indices
#   - "0" = use GPU 0
#   - "0,1" = use GPU 0 and 1
#   - "-1" = use CPU only
USE_GPU=false
CUDA_VISIBLE_DEVICES=-1

# ==========================================
# Kubernetes Job Resources (for kubernetes mode)
# ==========================================
# K8S_GPU_COUNT: Number of GPUs to request
#   - 0 = CPU only (for local kind cluster testing)
#   - 1 = Single GPU (default production)
#   - 2+ = Multi-GPU training (AWS/GCP with GPU nodes)
# Memory/CPU limits and requests for K8s Pod
K8S_GPU_COUNT=0
K8S_MEMORY_LIMIT=16Gi
K8S_MEMORY_REQUEST=8Gi
K8S_CPU_LIMIT=4
K8S_CPU_REQUEST=2
