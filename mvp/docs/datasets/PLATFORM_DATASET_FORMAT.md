# Platform Dataset Format Specification

**Version:** 1.0
**Date:** 2025-01-04
**Status:** Draft

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ê¸°ì¡´ í¬ë§· ë¶„ì„](#ê¸°ì¡´-í¬ë§·-ë¶„ì„)
3. [ìƒˆë¡œìš´ í¬ë§· ì„¤ê³„](#ìƒˆë¡œìš´-í¬ë§·-ì„¤ê³„)
4. [í•˜ìœ„ í˜¸í™˜ì„± ì „ëµ](#í•˜ìœ„-í˜¸í™˜ì„±-ì „ëµ)
5. [ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ](#ë§ˆì´ê·¸ë ˆì´ì…˜-ê°€ì´ë“œ)
6. [êµ¬í˜„ ê³„íš](#êµ¬í˜„-ê³„íš)

---

## ê°œìš”

### ë°°ê²½

**ê¸°ì¡´ ì‹œìŠ¤í…œ (AI ê²€ì‚¬ íˆ´ v0.9)**
- ì˜¤í”„ë¼ì¸ ë¡œì»¬ ê¸°ë°˜ ë ˆì´ë¸”ë§ íˆ´
- Classification, Detection, Segmentation ì§€ì›
- **í¬ë§· íŠ¹ì§•:**
  - ì´ë¯¸ì§€ 1ê°œë‹¹ ë ˆì´ë¸” íŒŒì¼ 1ê°œ (image.jpg + image.json)
  - summary.jsonìœ¼ë¡œ ì „ì²´ ë°ì´í„°ì…‹ ê´€ë¦¬
  - ë¡œì»¬ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (E:/, C:/ ë“±)

**í˜„ì¬ ìƒí™©:**
- âœ… ë§ì€ ê¸°ì¡´ ì‚¬ìš©ìê°€ ì´ í¬ë§·ìœ¼ë¡œ ë°ì´í„°ì…‹ êµ¬ì¶•
- âš ï¸ ìƒˆë¡œìš´ í´ë¼ìš°ë“œ ê¸°ë°˜ í”Œë«í¼ìœ¼ë¡œ ì „í™˜ í•„ìš”
- âš ï¸ ë” ë‹¤ì–‘í•œ íƒœìŠ¤í¬ ì§€ì› í•„ìš” (Pose, Super-Resolution ë“±)
- âš ï¸ R2/Cloud storageì— ì í•©í•œ êµ¬ì¡° í•„ìš”

### ì„¤ê³„ ëª©í‘œ

1. **í•˜ìœ„ í˜¸í™˜ì„± 100%**: ê¸°ì¡´ v0.9 í¬ë§· ì™„ì „ ì§€ì›
2. **Cloud ìµœì í™”**: ìƒëŒ€ ê²½ë¡œ, ê³„ì¸µì  êµ¬ì¡°
3. **í™•ì¥ ê°€ëŠ¥**: ìƒˆ íƒœìŠ¤í¬ ì¶”ê°€ ìš©ì´
4. **íš¨ìœ¨ì„±**: ì¤‘ë³µ ì œê±°, ë¹ ë¥¸ ì¸ë±ì‹±
5. **ë¦¬ì¹˜ ë©”íƒ€ë°ì´í„°**: ë²„ì „ ê´€ë¦¬, ìˆ˜ì • ì´ë ¥, í˜‘ì—… ì •ë³´

---

## ê¸°ì¡´ í¬ë§· ë¶„ì„

### v0.9 í¬ë§· êµ¬ì¡°

#### ë””ë ‰í† ë¦¬ êµ¬ì¡° (ë¡œì»¬)
```
E:/my-dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ img001.jpg
â”‚   â”œâ”€â”€ img002.jpg
â”‚   â””â”€â”€ img003.jpg
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ img001.json
â”‚   â”œâ”€â”€ img002.json
â”‚   â””â”€â”€ img003.json
â”œâ”€â”€ masks/                    # segmentation only
â”‚   â”œâ”€â”€ img001_mask.png
â”‚   â””â”€â”€ img002_mask.png
â””â”€â”€ label_map.json            # summary file
```

#### ê°œë³„ ë ˆì´ë¸” íŒŒì¼ (img001.json)

**Classification:**
```json
{
  "version": "0.9",
  "task_type": "cls",
  "shapes": [
    {
      "label": "Cat",
      "points": [[0, 0]],          // dummy point
      "group_id": null,
      "shape_type": "point",
      "flags": {}
    }
  ],
  "split": "train",
  "imageHeight": 600,
  "imageWidth": 800,
  "imageDepth": 4
}
```

**Detection:**
```json
{
  "version": "0.9",
  "task_type": "det",
  "shapes": [
    {
      "label": "cat",
      "points": [[100, 150], [400, 350]],  // [top-left, bottom-right]
      "group_id": null,
      "shape_type": "rectangle",
      "flags": {}
    },
    {
      "label": "dog",
      "points": [[500, 200], [700, 400]],
      "group_id": null,
      "shape_type": "rectangle",
      "flags": {}
    }
  ],
  "split": "train",
  "imageHeight": 600,
  "imageWidth": 800,
  "imageDepth": 4
}
```

**Segmentation:**
```json
{
  "version": "0.9",
  "task_type": "det",                      // Note: task_type is "det"
  "shapes": [
    {
      "label": "cat",
      "points": [
        [2818.5, 373.48],
        [2887.0, 360.5],
        [2900.0, 426.5],
        [2831.5, 439.48]
      ],
      "group_id": null,
      "shape_type": "polygon",
      "flags": {}
    }
  ],
  "split": "train",
  "imageHeight": 600,
  "imageWidth": 800,
  "imageDepth": 4
}
```

#### Summary íŒŒì¼ (label_map.json)

```json
{
  "task_type": "seg",
  "class_summary": {
    "num_classes": 3,
    "classes": [
      {
        "name": "_background_",
        "idx": 0,
        "color": "#000000"
      },
      {
        "name": "cat",
        "idx": 1,
        "color": "#FF0000"
      },
      {
        "name": "dog",
        "idx": 2,
        "color": "#00FF00"
      }
    ]
  },
  "data_summary": [
    {
      "img_path": "E:/data/images/image1.jpg",
      "label_path": "E:/data/labels/image1.json",
      "mask_path": "E:/data/masks/image1_mask.png"
    },
    {
      "img_path": "E:/data/images/image2.jpg",
      "label_path": "E:/data/labels/image2.json",
      "mask_path": "E:/data/masks/image2_mask.png"
    }
  ]
}
```

### v0.9 í¬ë§·ì˜ í•œê³„

| ë¬¸ì œ | ì„¤ëª… | ì˜í–¥ |
|------|------|------|
| **ë¡œì»¬ ê²½ë¡œ ì˜ì¡´** | ì ˆëŒ€ ê²½ë¡œ (E:/, C:/) ì‚¬ìš© | R2/Cloud ì—…ë¡œë“œ ì‹œ ê²½ë¡œ ê¹¨ì§ |
| **ì œí•œëœ ë©”íƒ€ë°ì´í„°** | ë²„ì „, ìˆ˜ì • ì´ë ¥, ë ˆì´ë¸”ëŸ¬ ì •ë³´ ì—†ìŒ | í˜‘ì—…, ì¶”ì  ë¶ˆê°€ |
| **í™•ì¥ì„± ë¶€ì¡±** | Pose, Super-Resolution ë“± ë¯¸ì§€ì› | ì‹ ê·œ íƒœìŠ¤í¬ ì¶”ê°€ ì–´ë ¤ì›€ |
| **ì¤‘ë³µ ì •ë³´** | ê° jsonì— imageHeight/Width ë°˜ë³µ | ìŠ¤í† ë¦¬ì§€ ë‚­ë¹„ |
| **ë¶„ì‚°ëœ ì •ë³´** | summary.json + ê°œë³„ json ë¶„ë¦¬ | ë°ì´í„° ì¼ê´€ì„± ê´€ë¦¬ ì–´ë ¤ì›€ |
| **task_type ë¶ˆì¼ì¹˜** | segmentationë„ task_type="det" | í˜¼ë€ ì•¼ê¸° |

---

## ìƒˆë¡œìš´ í¬ë§· ì„¤ê³„

### v1.0 Platform Format

#### í•µì‹¬ ì›ì¹™

1. **Single Source of Truth**: í•˜ë‚˜ì˜ `annotations.json` íŒŒì¼
2. **ìƒëŒ€ ê²½ë¡œ**: Cloud storage í˜¸í™˜
3. **í™•ì¥ ê°€ëŠ¥í•œ ìŠ¤í‚¤ë§ˆ**: ìƒˆ íƒœìŠ¤í¬ ì¶”ê°€ ìš©ì´
4. **í•˜ìœ„ í˜¸í™˜ ëª¨ë“œ**: v0.9 í¬ë§· ìë™ ê°ì§€ ë° ë³€í™˜

#### ë””ë ‰í† ë¦¬ êµ¬ì¡° (R2/Cloud)

```
s3://bucket/datasets/user123-cats-dogs/
â”œâ”€â”€ annotations.json          â† Single source of truth
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ img001.jpg
â”‚   â”œâ”€â”€ img002.jpg
â”‚   â””â”€â”€ img003.jpg
â”œâ”€â”€ masks/                    â† Segmentation only
â”‚   â”œâ”€â”€ img001_mask.png
â”‚   â””â”€â”€ img002_mask.png
â”œâ”€â”€ meta.json                 â† DB ë™ê¸°í™”ìš© ë©”íƒ€ë°ì´í„°
â””â”€â”€ legacy/                   â† Optional: ê¸°ì¡´ v0.9 ë°±ì—…
    â”œâ”€â”€ labels/
    â”‚   â”œâ”€â”€ img001.json
    â”‚   â””â”€â”€ img002.json
    â””â”€â”€ label_map.json
```

#### annotations.json ì „ì²´ êµ¬ì¡°

```json
{
  "format_version": "1.0",
  "dataset_id": "user123-cats-dogs",
  "dataset_name": "My Cats and Dogs Dataset",

  "task_type": "image_classification",

  "created_at": "2025-01-15T10:00:00Z",
  "last_modified_at": "2025-01-20T15:30:00Z",
  "version": 3,
  "content_hash": "sha256:abc123...",

  "migration_info": {
    "migrated_from": "v0.9",
    "migration_date": "2025-01-15T10:00:00Z",
    "original_paths": {
      "images": "E:/my-dataset/images/",
      "labels": "E:/my-dataset/labels/"
    }
  },

  "classes": [
    {
      "id": 0,
      "name": "cat",
      "color": "#FF6B6B",
      "supercategory": "animal"
    },
    {
      "id": 1,
      "name": "dog",
      "color": "#4ECDC4",
      "supercategory": "animal"
    }
  ],

  "splits": {
    "train": 800,
    "val": 150,
    "test": 50
  },

  "images": [
    {
      "id": 1,
      "file_name": "img001.jpg",
      "width": 1920,
      "height": 1080,
      "depth": 3,
      "split": "train",

      "annotation": { /* task-specific */ },

      "metadata": {
        "labeled_by": "user123",
        "labeled_at": "2025-01-15T10:05:00Z",
        "reviewed_by": "admin",
        "reviewed_at": "2025-01-16T09:00:00Z",
        "source": "platform_labeler_v1.0"
      }
    }
  ],

  "statistics": {
    "total_images": 1000,
    "total_annotations": 1000,
    "avg_annotations_per_image": 1.0,
    "class_distribution": {
      "cat": 600,
      "dog": 400
    }
  }
}
```

### Taskë³„ Annotation ìŠ¤í‚¤ë§ˆ

#### 1. Classification

```json
{
  "id": 1,
  "file_name": "cat_001.jpg",
  "width": 1920,
  "height": 1080,
  "depth": 3,
  "split": "train",

  "annotation": {
    "class_id": 0,
    "class_name": "cat",
    "confidence": 1.0
  },

  "legacy_v09": {
    "shape_type": "point",
    "points": [[0, 0]]
  }
}
```

#### 2. Object Detection

```json
{
  "id": 2,
  "file_name": "street_001.jpg",
  "width": 1920,
  "height": 1080,
  "split": "train",

  "annotations": [
    {
      "id": 1001,
      "class_id": 0,
      "class_name": "car",
      "bbox": [100, 200, 300, 400],
      "bbox_format": "xywh",
      "area": 120000,
      "iscrowd": 0
    },
    {
      "id": 1002,
      "class_id": 1,
      "class_name": "person",
      "bbox": [500, 300, 100, 200],
      "bbox_format": "xywh",
      "area": 20000,
      "iscrowd": 0
    }
  ],

  "legacy_v09": {
    "shapes": [
      {
        "label": "car",
        "points": [[100, 200], [400, 600]],
        "shape_type": "rectangle"
      }
    ]
  }
}
```

#### 3. Instance Segmentation

```json
{
  "id": 3,
  "file_name": "cat_segmentation.jpg",
  "width": 3000,
  "height": 2000,
  "split": "train",

  "annotations": [
    {
      "id": 2001,
      "class_id": 0,
      "class_name": "cat",
      "bbox": [2800, 350, 100, 100],
      "segmentation": [
        [2818.5, 373.48, 2887.0, 360.5, 2900.0, 426.5, 2831.5, 439.48]
      ],
      "area": 2500,
      "iscrowd": 0
    }
  ],

  "legacy_v09": {
    "shapes": [
      {
        "label": "cat",
        "points": [[2818.5, 373.48], [2887.0, 360.5], [2900.0, 426.5], [2831.5, 439.48]],
        "shape_type": "polygon"
      }
    ]
  }
}
```

#### 4. Semantic Segmentation

```json
{
  "id": 4,
  "file_name": "scene_001.jpg",
  "width": 1920,
  "height": 1080,
  "split": "train",

  "annotation": {
    "mask_file": "masks/scene_001_mask.png",
    "mask_format": "indexed_png",
    "num_classes": 3
  },

  "legacy_v09": {
    "mask_path": "masks/scene_001_mask.png"
  }
}
```

#### 5. Pose Estimation (NEW)

```json
{
  "id": 5,
  "file_name": "person_pose.jpg",
  "width": 1920,
  "height": 1080,
  "split": "train",

  "annotations": [
    {
      "id": 3001,
      "class_id": 0,
      "class_name": "person",
      "bbox": [500, 200, 300, 600],
      "keypoints": [
        [520, 220, 2],  // [x, y, visibility] - nose
        [510, 240, 2],  // left_eye
        [530, 240, 2],  // right_eye
        [500, 260, 2],  // left_ear
        [540, 260, 2],  // right_ear
        // ... 17 keypoints total (COCO format)
      ],
      "num_keypoints": 17
    }
  ]
}
```

#### 6. Super-Resolution (NEW)

```json
{
  "id": 6,
  "file_name": "low_res_001.jpg",
  "width": 480,
  "height": 270,
  "split": "train",

  "annotation": {
    "hr_image": "hr_images/high_res_001.jpg",
    "upscale_factor": 4,
    "hr_width": 1920,
    "hr_height": 1080
  }
}
```

---

## í•˜ìœ„ í˜¸í™˜ì„± ì „ëµ

### 3-Tier í˜¸í™˜ì„± ëª¨ë¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 1: Native v1.0 (ì‹ ê·œ ì‚¬ìš©ì)          â”‚
â”‚  - í”Œë«í¼ ë ˆì´ë¸”ëŸ¬ ì‚¬ìš©                      â”‚
â”‚  - annotations.json ì§ì ‘ ìƒì„±                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 2: Auto-Migration (ê¸°ì¡´ ì‚¬ìš©ì)       â”‚
â”‚  - v0.9 í¬ë§· ì—…ë¡œë“œ                          â”‚
â”‚  - ìë™ ë³€í™˜ â†’ v1.0                          â”‚
â”‚  - legacy_v09 í•„ë“œ ë³´ì¡´                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 3: Dual-Format Support (í•˜ì´ë¸Œë¦¬ë“œ)   â”‚
â”‚  - v1.0 annotations.json ìƒì„±                â”‚
â”‚  - legacy/ í´ë”ì— v0.9 ë°±ì—… ìœ ì§€             â”‚
â”‚  - ì–‘ë°©í–¥ export ì§€ì›                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìë™ ê°ì§€ ë° ë³€í™˜

#### Backend API: Dataset Upload

```python
# mvp/backend/app/api/datasets.py

@router.post("/datasets/upload")
async def upload_dataset(files: List[UploadFile], ...):
    """
    ë°ì´í„°ì…‹ ì—…ë¡œë“œ ì‹œ í¬ë§· ìë™ ê°ì§€ ë° ë³€í™˜.

    ì§€ì› í¬ë§·:
    - v1.0: annotations.json
    - v0.9: label_map.json + individual labels/
    - YOLO: data.yaml
    - COCO: instances.json
    - ImageFolder: directory structure
    """
    # 1. ì—…ë¡œë“œëœ íŒŒì¼ ë¶„ì„
    detected_format = detect_dataset_format(files)

    # 2. í¬ë§·ë³„ ì²˜ë¦¬
    if detected_format == "platform_v1.0":
        # annotations.json ì§ì ‘ ì‚¬ìš©
        annotations = parse_v1_annotations(files)

    elif detected_format == "platform_v0.9":
        # v0.9 â†’ v1.0 ìë™ ë³€í™˜
        print("[Migration] Detected v0.9 format, converting to v1.0...")
        annotations = migrate_v09_to_v10(files)

    elif detected_format == "yolo":
        annotations = convert_yolo_to_v10(files)

    # ... ê¸°íƒ€ í¬ë§·

    # 3. R2 ì—…ë¡œë“œ (v1.0 í¬ë§·)
    await upload_to_r2(dataset_id, annotations)
```

#### Format Detector

```python
# mvp/backend/app/utils/format_detector.py

def detect_dataset_format(files: List[UploadFile]) -> str:
    """
    ì—…ë¡œë“œëœ íŒŒì¼ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ í¬ë§· ê°ì§€.

    Returns:
        "platform_v1.0" | "platform_v0.9" | "yolo" | "coco" | "imagefolder"
    """
    file_names = [f.filename for f in files]

    # v1.0: annotations.json ì¡´ì¬
    if "annotations.json" in file_names:
        # íŒŒì¼ ë‚´ìš© í™•ì¸
        annotations = json.loads(find_file(files, "annotations.json").read())
        if annotations.get("format_version") == "1.0":
            return "platform_v1.0"

    # v0.9: label_map.json + labels/ ë””ë ‰í† ë¦¬
    if "label_map.json" in file_names:
        label_dirs = [f for f in file_names if f.startswith("labels/")]
        if label_dirs:
            return "platform_v0.9"

    # YOLO: data.yaml
    if "data.yaml" in file_names:
        return "yolo"

    # COCO: annotations/instances_*.json
    coco_files = [f for f in file_names if "instances_" in f and f.endswith(".json")]
    if coco_files:
        return "coco"

    # ImageFolder: ë””ë ‰í† ë¦¬ êµ¬ì¡°ë§Œ ì¡´ì¬
    if any(f.startswith("train/") for f in file_names):
        return "imagefolder"

    raise ValueError("Unknown dataset format")
```

#### v0.9 â†’ v1.0 Migrator

```python
# mvp/backend/app/utils/dataset_migrator.py

class V09ToV10Migrator:
    """
    v0.9 í¬ë§·ì„ v1.0ìœ¼ë¡œ ë³€í™˜.

    Input:
        - label_map.json (summary)
        - labels/*.json (individual annotations)
        - images/*.jpg
        - masks/*.png (optional)

    Output:
        - annotations.json (v1.0 format)
        - images/ (unchanged)
        - masks/ (unchanged)
        - legacy/ (v0.9 ë°±ì—…)
    """

    def migrate(self, v09_files: List[UploadFile]) -> dict:
        """
        v0.9 ë°ì´í„°ì…‹ì„ v1.0 í¬ë§·ìœ¼ë¡œ ë³€í™˜.

        Returns:
            v1.0 annotations.json dict
        """
        # 1. label_map.json íŒŒì‹±
        label_map = self._parse_label_map(v09_files)

        task_type = label_map['task_type']
        classes = label_map['class_summary']['classes']
        data_summary = label_map['data_summary']

        # 2. v1.0 annotations.json ìƒì„±
        annotations = {
            "format_version": "1.0",
            "dataset_id": generate_dataset_id(),
            "dataset_name": "Migrated from v0.9",

            "task_type": self._normalize_task_type(task_type),

            "created_at": datetime.utcnow().isoformat() + "Z",
            "last_modified_at": datetime.utcnow().isoformat() + "Z",
            "version": 1,
            "content_hash": None,  # ë‚˜ì¤‘ì— ê³„ì‚°

            "migration_info": {
                "migrated_from": "v0.9",
                "migration_date": datetime.utcnow().isoformat() + "Z",
                "original_paths": self._extract_original_paths(data_summary)
            },

            "classes": self._convert_classes(classes),
            "splits": {},  # ë‚˜ì¤‘ì— ê³„ì‚°
            "images": [],
            "statistics": {}
        }

        # 3. ê°œë³„ ë ˆì´ë¸” íŒŒì¼ ì²˜ë¦¬
        for entry in data_summary:
            img_filename = os.path.basename(entry['img_path'])
            label_filename = os.path.basename(entry['label_path'])

            # labels/xxx.json íŒŒì‹±
            label_data = self._parse_label_file(v09_files, label_filename)

            # v1.0 image entry ìƒì„±
            image_entry = self._convert_image_entry(
                img_filename=img_filename,
                label_data=label_data,
                task_type=task_type,
                entry=entry
            )

            annotations['images'].append(image_entry)

        # 4. Split í†µê³„ ê³„ì‚°
        annotations['splits'] = self._calculate_splits(annotations['images'])

        # 5. Content hash ê³„ì‚°
        annotations['content_hash'] = self._calculate_content_hash(annotations)

        return annotations

    def _normalize_task_type(self, v09_task_type: str) -> str:
        """
        v0.9 task_type â†’ v1.0 í‘œì¤€ task_type.

        v0.9:
        - cls â†’ image_classification
        - det â†’ object_detection (or instance_segmentation)
        - seg â†’ semantic_segmentation
        """
        mapping = {
            "cls": "image_classification",
            "det": "object_detection",  # default
            "seg": "semantic_segmentation"
        }
        return mapping.get(v09_task_type, v09_task_type)

    def _convert_classes(self, v09_classes: List[dict]) -> List[dict]:
        """
        v0.9 classes â†’ v1.0 classes.

        v0.9: {"name": "cat", "idx": 1, "color": "#FF0000"}
        v1.0: {"id": 1, "name": "cat", "color": "#FF0000"}
        """
        return [
            {
                "id": cls['idx'],
                "name": cls['name'],
                "color": cls.get('color', '#000000')
            }
            for cls in v09_classes
            if cls['name'] != '_background_'  # ë°°ê²½ í´ë˜ìŠ¤ ì œì™¸
        ]

    def _convert_image_entry(
        self,
        img_filename: str,
        label_data: dict,
        task_type: str,
        entry: dict
    ) -> dict:
        """
        ê°œë³„ ì´ë¯¸ì§€ + ë ˆì´ë¸” â†’ v1.0 image entry.
        """
        image_id = int(os.path.splitext(img_filename)[0].replace('img', ''))

        base_entry = {
            "id": image_id,
            "file_name": img_filename,
            "width": label_data.get('imageWidth', 0),
            "height": label_data.get('imageHeight', 0),
            "depth": label_data.get('imageDepth', 3),
            "split": label_data.get('split', 'train'),

            "metadata": {
                "labeled_by": "unknown",
                "labeled_at": datetime.utcnow().isoformat() + "Z",
                "source": "migrated_from_v0.9"
            }
        }

        # Taskë³„ annotation ë³€í™˜
        if task_type == "cls":
            base_entry['annotation'] = self._convert_cls_annotation(label_data)
        elif task_type == "det":
            # shape_typeìœ¼ë¡œ det vs seg êµ¬ë¶„
            if self._is_segmentation(label_data):
                base_entry['annotations'] = self._convert_seg_annotations(label_data)
            else:
                base_entry['annotations'] = self._convert_det_annotations(label_data)
        elif task_type == "seg":
            base_entry['annotation'] = self._convert_semantic_seg_annotation(label_data, entry)

        # legacy v0.9 ì •ë³´ ë³´ì¡´
        base_entry['legacy_v09'] = {
            "shapes": label_data.get('shapes', [])
        }

        return base_entry

    def _is_segmentation(self, label_data: dict) -> bool:
        """
        Detection vs Segmentation êµ¬ë¶„.

        v0.9ì—ì„œëŠ” ë‘˜ ë‹¤ task_type="det"ì´ë¯€ë¡œ shape_typeìœ¼ë¡œ êµ¬ë¶„.
        - rectangle â†’ object_detection
        - polygon â†’ instance_segmentation
        """
        shapes = label_data.get('shapes', [])
        if not shapes:
            return False

        return any(s['shape_type'] == 'polygon' for s in shapes)

    def _convert_cls_annotation(self, label_data: dict) -> dict:
        """
        v0.9 classification â†’ v1.0.

        v0.9:
        {
          "shapes": [{"label": "Cat", "points": [[0, 0]], "shape_type": "point"}]
        }

        v1.0:
        {
          "class_id": 0,
          "class_name": "Cat",
          "confidence": 1.0
        }
        """
        shapes = label_data.get('shapes', [])
        if not shapes:
            return None

        label = shapes[0]['label']

        return {
            "class_id": self._get_class_id(label),
            "class_name": label,
            "confidence": 1.0
        }

    def _convert_det_annotations(self, label_data: dict) -> List[dict]:
        """
        v0.9 detection â†’ v1.0.

        v0.9:
        {
          "shapes": [
            {
              "label": "cat",
              "points": [[100, 150], [400, 350]],  // [top-left, bottom-right]
              "shape_type": "rectangle"
            }
          ]
        }

        v1.0:
        {
          "id": 1001,
          "class_id": 0,
          "class_name": "cat",
          "bbox": [100, 150, 300, 200],  // [x, y, w, h]
          "bbox_format": "xywh",
          "area": 60000
        }
        """
        shapes = label_data.get('shapes', [])
        annotations = []

        for i, shape in enumerate(shapes):
            if shape['shape_type'] != 'rectangle':
                continue

            points = shape['points']
            x1, y1 = points[0]
            x2, y2 = points[1]

            w = abs(x2 - x1)
            h = abs(y2 - y1)
            x = min(x1, x2)
            y = min(y1, y2)

            annotations.append({
                "id": i + 1001,
                "class_id": self._get_class_id(shape['label']),
                "class_name": shape['label'],
                "bbox": [x, y, w, h],
                "bbox_format": "xywh",
                "area": w * h,
                "iscrowd": 0
            })

        return annotations

    def _convert_seg_annotations(self, label_data: dict) -> List[dict]:
        """
        v0.9 instance segmentation â†’ v1.0.

        v0.9:
        {
          "shapes": [
            {
              "label": "cat",
              "points": [[x1, y1], [x2, y2], [x3, y3], [x4, y4]],
              "shape_type": "polygon"
            }
          ]
        }

        v1.0:
        {
          "id": 2001,
          "class_id": 0,
          "class_name": "cat",
          "bbox": [x_min, y_min, w, h],
          "segmentation": [[x1, y1, x2, y2, x3, y3, x4, y4]],
          "area": polygon_area
        }
        """
        shapes = label_data.get('shapes', [])
        annotations = []

        for i, shape in enumerate(shapes):
            if shape['shape_type'] != 'polygon':
                continue

            points = shape['points']

            # Flatten points: [[x1, y1], [x2, y2]] â†’ [x1, y1, x2, y2]
            flat_points = [coord for point in points for coord in point]

            # Calculate bbox from polygon
            xs = [p[0] for p in points]
            ys = [p[1] for p in points]
            x_min, x_max = min(xs), max(xs)
            y_min, y_max = min(ys), max(ys)

            bbox = [x_min, y_min, x_max - x_min, y_max - y_min]

            annotations.append({
                "id": i + 2001,
                "class_id": self._get_class_id(shape['label']),
                "class_name": shape['label'],
                "bbox": bbox,
                "segmentation": [flat_points],
                "area": self._calculate_polygon_area(points),
                "iscrowd": 0
            })

        return annotations

    def _convert_semantic_seg_annotation(self, label_data: dict, entry: dict) -> dict:
        """
        v0.9 semantic segmentation â†’ v1.0.

        v0.9:
        {
          "mask_path": "E:/data/masks/image1_mask.png"
        }

        v1.0:
        {
          "mask_file": "masks/image1_mask.png",
          "mask_format": "indexed_png"
        }
        """
        mask_path = entry.get('mask_path', '')
        mask_filename = os.path.basename(mask_path)

        return {
            "mask_file": f"masks/{mask_filename}",
            "mask_format": "indexed_png",
            "num_classes": len(self.classes)
        }
```

---

## ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### ê¸°ì¡´ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ë¡œì»¬ v0.9 ë°ì´í„°ì…‹ â†’ í”Œë«í¼ ì—…ë¡œë“œ

**ì‚¬ìš©ì ìƒí™©:**
- E:/my-dataset/ ì— v0.9 í¬ë§· ë°ì´í„°ì…‹ ë³´ìœ 
- images/, labels/, label_map.json êµ¬ì¡°

**ë§ˆì´ê·¸ë ˆì´ì…˜ ì ˆì°¨:**

1. **ë°ì´í„°ì…‹ ì••ì¶•**
   ```bash
   # ë¡œì»¬ì—ì„œ ì••ì¶• (ê²½ë¡œ êµ¬ì¡° ìœ ì§€)
   cd E:/my-dataset
   zip -r my-dataset.zip images/ labels/ label_map.json
   ```

2. **í”Œë«í¼ ì—…ë¡œë“œ**
   - ì›¹ UIì—ì„œ "ë°ì´í„°ì…‹ ì—…ë¡œë“œ" í´ë¦­
   - my-dataset.zip ë“œë˜ê·¸ ì•¤ ë“œë¡­
   - âœ… ìë™ ê°ì§€: "v0.9 í¬ë§·ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. v1.0ìœ¼ë¡œ ìë™ ë³€í™˜ë©ë‹ˆë‹¤."

3. **ìë™ ë³€í™˜ ì‹¤í–‰**
   ```
   [Backend] Detecting format... v0.9
   [Backend] Migrating v0.9 â†’ v1.0...
   [Backend] Converting 1000 images...
   [Backend] Generating annotations.json...
   [Backend] Uploading to R2...
   [Backend] âœ… Complete!
   ```

4. **ê²°ê³¼ í™•ì¸**
   - R2ì— ì €ì¥ëœ êµ¬ì¡°:
     ```
     s3://bucket/datasets/user123-my-dataset/
     â”œâ”€â”€ annotations.json        â† v1.0 í¬ë§·
     â”œâ”€â”€ images/
     â”‚   â”œâ”€â”€ img001.jpg
     â”‚   â””â”€â”€ ...
     â”œâ”€â”€ legacy/                 â† v0.9 ë°±ì—…
     â”‚   â”œâ”€â”€ labels/
     â”‚   â””â”€â”€ label_map.json
     â””â”€â”€ meta.json
     ```

5. **í•™ìŠµ ì‹œì‘**
   - í”Œë«í¼ì—ì„œ ë°”ë¡œ í•™ìŠµ ê°€ëŠ¥
   - ë³€í™˜ëœ v1.0 í¬ë§· ì‚¬ìš©
   - ê¸°ì¡´ v0.9 ë ˆì´ë¸” ì •ë³´ëŠ” legacy_v09 í•„ë“œì— ë³´ì¡´

#### ì‹œë‚˜ë¦¬ì˜¤ 2: ê¸°ì¡´ íˆ´ ê³„ì† ì‚¬ìš© + í”Œë«í¼ í†µí•©

**ì‚¬ìš©ì ìƒí™©:**
- ê¸°ì¡´ AI ê²€ì‚¬ íˆ´ v0.9 ê³„ì† ì‚¬ìš© ì¤‘
- ì£¼ê¸°ì ìœ¼ë¡œ í”Œë«í¼ ì—…ë¡œë“œ í•„ìš”

**ê¶Œì¥ ì›Œí¬í”Œë¡œìš°:**

1. **ë¡œì»¬ì—ì„œ ë ˆì´ë¸”ë§ (v0.9 íˆ´)**
   - ê¸°ì¡´ íˆ´ë¡œ ì‘ì—… ê³„ì†
   - images/, labels/ ìƒì„±

2. **Export to Platform ê¸°ëŠ¥ ì¶”ê°€**
   - ê¸°ì¡´ íˆ´ì— "í”Œë«í¼ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°" ë²„íŠ¼ ì¶”ê°€
   - í´ë¦­ ì‹œ ìë™ìœ¼ë¡œ:
     - v1.0 annotations.json ìƒì„±
     - APIë¡œ í”Œë«í¼ ì—…ë¡œë“œ
     - ë¡œì»¬ì—ëŠ” v0.9 ìœ ì§€

3. **í”Œë«í¼ì—ì„œ í•™ìŠµ**
   - ì—…ë¡œë“œëœ v1.0 í¬ë§·ìœ¼ë¡œ í•™ìŠµ

#### ì‹œë‚˜ë¦¬ì˜¤ 3: ì–‘ë°©í–¥ ë™ê¸°í™”

**ì‚¬ìš©ì ìƒí™©:**
- ì—¬ëŸ¬ ëª…ì´ í˜‘ì—…
- ì¼ë¶€ëŠ” ë¡œì»¬ íˆ´, ì¼ë¶€ëŠ” í”Œë«í¼ ë ˆì´ë¸”ëŸ¬ ì‚¬ìš©

**í•´ê²°ì±…: Dual-Format Sync**

```python
# Export v1.0 â†’ v0.9 (í”Œë«í¼ â†’ ë¡œì»¬)
class V10ToV09Exporter:
    """
    v1.0 annotations.json â†’ v0.9 format.

    Use case:
    - í”Œë«í¼ì—ì„œ ë ˆì´ë¸”ë§í•œ ë°ì´í„°ë¥¼ ë¡œì»¬ íˆ´ë¡œ ë‹¤ìš´ë¡œë“œ
    """

    def export(self, annotations_v10: dict) -> dict:
        """
        v1.0 â†’ v0.9 ë³€í™˜.

        Returns:
            {
                "label_map.json": {...},
                "labels/": {
                    "img001.json": {...},
                    "img002.json": {...}
                }
            }
        """
        # ... êµ¬í˜„
```

---

## êµ¬í˜„ ê³„íš

### Phase 1: Core Migration (1ì£¼)

**ëª©í‘œ:** v0.9 í¬ë§· ìë™ ë³€í™˜ ì§€ì›

- [ ] Format Detector êµ¬í˜„
  - `detect_dataset_format()`
  - ì§€ì›: v1.0, v0.9, YOLO, COCO, ImageFolder

- [ ] V09ToV10Migrator êµ¬í˜„
  - `migrate()` ë©”ì„œë“œ
  - Classification, Detection, Segmentation ì§€ì›
  - legacy_v09 í•„ë“œ ë³´ì¡´

- [ ] Backend API í†µí•©
  - `POST /datasets/upload` ìˆ˜ì •
  - ìë™ ê°ì§€ ë° ë³€í™˜ ë¡œì§
  - R2 ì—…ë¡œë“œ

- [ ] Unit Tests
  - ê° task typeë³„ ë³€í™˜ í…ŒìŠ¤íŠ¸
  - Edge case ì²˜ë¦¬

### Phase 2: UI/UX (3ì¼)

**ëª©í‘œ:** ì‚¬ìš©ì ì¹œí™”ì ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½í—˜

- [ ] Upload UI ê°œì„ 
  - í¬ë§· ìë™ ê°ì§€ ì•ˆë‚´ ë©”ì‹œì§€
  - ë³€í™˜ ì§„í–‰ë¥  í‘œì‹œ
  - ë³€í™˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°

- [ ] Migration Report
  - ë³€í™˜ëœ ì´ë¯¸ì§€ ìˆ˜
  - ê²½ë¡œ ë§¤í•‘ ì •ë³´
  - ê²½ê³  ë° ì˜¤ë¥˜ ë¡œê·¸

- [ ] Legacy Backup ë‹¤ìš´ë¡œë“œ
  - v0.9 í¬ë§· ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
  - ê¸°ì¡´ íˆ´ í˜¸í™˜ì„± ìœ ì§€

### Phase 3: Advanced Features (1ì£¼)

**ëª©í‘œ:** ì–‘ë°©í–¥ ë™ê¸°í™” ë° í•˜ì´ë¸Œë¦¬ë“œ ì›Œí¬í”Œë¡œìš°

- [ ] V10ToV09Exporter êµ¬í˜„
  - í”Œë«í¼ â†’ ë¡œì»¬ íˆ´ export
  - label_map.json + individual labels/ ìƒì„±

- [ ] Sync API
  - `POST /datasets/{id}/sync` ì—”ë“œí¬ì¸íŠ¸
  - ì–‘ë°©í–¥ ë™ê¸°í™” ì§€ì›
  - ì¶©ëŒ í•´ê²° ë¡œì§

- [ ] CLI Tool
  - ë¡œì»¬ v0.9 ë°ì´í„°ì…‹ â†’ v1.0 ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
  - ì˜¤í”„ë¼ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬

### Phase 4: Documentation & Training (3ì¼)

**ëª©í‘œ:** ê¸°ì¡´ ì‚¬ìš©ì ì˜¨ë³´ë”©

- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ ë¬¸ì„œ
  - ì‹œë‚˜ë¦¬ì˜¤ë³„ ë‹¨ê³„ë³„ ê°€ì´ë“œ
  - ìŠ¤í¬ë¦°ìƒ· í¬í•¨

- [ ] ë¹„ë””ì˜¤ íŠœí† ë¦¬ì–¼
  - v0.9 â†’ v1.0 ë§ˆì´ê·¸ë ˆì´ì…˜
  - í”Œë«í¼ ë ˆì´ë¸”ëŸ¬ ì‚¬ìš©ë²•

- [ ] FAQ í˜ì´ì§€
  - ìì£¼ ë¬»ëŠ” ì§ˆë¬¸
  - íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

---

## ë¶€ë¡

### A. í¬ë§· ë¹„êµ ë§¤íŠ¸ë¦­ìŠ¤

| Feature | v0.9 | v1.0 | ê°œì„  ì‚¬í•­ |
|---------|------|------|-----------|
| **íŒŒì¼ êµ¬ì¡°** | summary + ê°œë³„ json | ë‹¨ì¼ annotations.json | âœ… ë‹¨ìˆœí™” |
| **ê²½ë¡œ** | ì ˆëŒ€ ê²½ë¡œ | ìƒëŒ€ ê²½ë¡œ | âœ… Cloud í˜¸í™˜ |
| **ë©”íƒ€ë°ì´í„°** | ì œí•œì  | í’ë¶€ (ë ˆì´ë¸”ëŸ¬, ë¦¬ë·°ì–´, íƒ€ì„ìŠ¤íƒ¬í”„) | âœ… í˜‘ì—… ì§€ì› |
| **Task ì§€ì›** | cls, det, seg | ëª¨ë“  vision task | âœ… í™•ì¥ì„± |
| **ë²„ì „ ê´€ë¦¬** | âŒ | content_hash, version | âœ… Mutable ì§€ì› |
| **í†µê³„** | âŒ | ìë™ ê³„ì‚° | âœ… ë¹ ë¥¸ ì¸ë±ì‹± |
| **í•˜ìœ„ í˜¸í™˜** | N/A | legacy_v09 í•„ë“œ | âœ… ì •ë³´ ë³´ì¡´ |

### B. ë³€í™˜ ë§¤í•‘ í…Œì´ë¸”

#### Task Type ë§¤í•‘

| v0.9 | shape_type | v1.0 |
|------|------------|------|
| cls | point | image_classification |
| det | rectangle | object_detection |
| det | polygon | instance_segmentation |
| seg | N/A | semantic_segmentation |

#### í•„ë“œ ë§¤í•‘

| v0.9 | v1.0 | ë³€í™˜ ë¡œì§ |
|------|------|-----------|
| `shapes[0].label` | `annotation.class_name` | ì§ì ‘ ë§¤í•‘ |
| `shapes[0].points` | `annotation.bbox` | ì¢Œí‘œ ë³€í™˜ |
| `imageWidth` | `width` | ì§ì ‘ ë§¤í•‘ |
| `imageHeight` | `height` | ì§ì ‘ ë§¤í•‘ |
| `split` | `split` | ì§ì ‘ ë§¤í•‘ |
| `data_summary[].img_path` | `images[].file_name` | basename ì¶”ì¶œ |

---

**Last Updated:** 2025-01-04
**Version:** 1.0 Draft
**Author:** Development Team
