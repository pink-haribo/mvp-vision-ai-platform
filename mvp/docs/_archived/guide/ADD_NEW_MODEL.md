# ì‹ ê·œ ëª¨ë¸ ì¶”ê°€ ê°€ì´ë“œ (Add New Model Guide)

ì´ ë¬¸ì„œëŠ” Vision AI Training Platformì— ìƒˆë¡œìš´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì¶”ê°€í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ëª¨ë¸ ì¶”ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸](#ëª¨ë¸-ì¶”ê°€-ì²´í¬ë¦¬ìŠ¤íŠ¸)
3. [Step 1: ëª¨ë¸ ì„ ì • ë° ê²€ì¦](#step-1-ëª¨ë¸-ì„ ì •-ë°-ê²€ì¦)
4. [Step 2: ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¶”ê°€](#step-2-ëª¨ë¸-ë ˆì§€ìŠ¤íŠ¸ë¦¬-ì¶”ê°€)
5. [Step 3: Adapter êµ¬í˜„ (í•„ìš”ì‹œ)](#step-3-adapter-êµ¬í˜„-í•„ìš”ì‹œ)
6. [Step 4: Config Schema ì •ì˜ (í•„ìš”ì‹œ)](#step-4-config-schema-ì •ì˜-í•„ìš”ì‹œ)
7. [Step 5: í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸](#step-5-í˜¸í™˜ì„±-í…ŒìŠ¤íŠ¸)
8. [Step 6: UI í™•ì¸](#step-6-ui-í™•ì¸)
9. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ê°œìš”

Vision AI Training Platformì€ **ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê¸°ë°˜ ì•„í‚¤í…ì²˜**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

```
Model Registry (ë©”íƒ€ë°ì´í„°)
    â†“
Adapter (í•™ìŠµ/ì¶”ë¡  ë¡œì§)
    â†“
Config Schema (ì„¤ì • ìŠ¤í‚¤ë§ˆ)
    â†“
API & UI
```

### ì§€ì› í”„ë ˆì„ì›Œí¬

í˜„ì¬ ì§€ì›í•˜ëŠ” ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬:
- **timm** (PyTorch Image Models) - ì´ë¯¸ì§€ ë¶„ë¥˜
- **ultralytics** (YOLO) - ê°ì²´ íƒì§€, ì„¸ê·¸ë©˜í…Œì´ì…˜, í¬ì¦ˆ ì¶”ì •

---

## ëª¨ë¸ ì¶”ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸

ìƒˆë¡œìš´ ëª¨ë¸ì„ ì¶”ê°€í•  ë•Œ ë‹¤ìŒ í•­ëª©ë“¤ì„ ì²´í¬í•˜ì„¸ìš”:

- [ ] **Step 1**: ëª¨ë¸ì´ timm ë˜ëŠ” ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì§€ì›ë˜ëŠ”ì§€ í™•ì¸
- [ ] **Step 2**: ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
- [ ] **Step 3**: ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¼ë©´ Adapter êµ¬í˜„ (ê¸°ì¡´ í”„ë ˆì„ì›Œí¬ëŠ” ìƒëµ)
- [ ] **Step 4**: ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¼ë©´ Config Schema ì •ì˜ (ê¸°ì¡´ í”„ë ˆì„ì›Œí¬ëŠ” ìƒëµ)
- [ ] **Step 5**: í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] **Step 6**: UIì—ì„œ ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ í…ŒìŠ¤íŠ¸
- [ ] **Step 7**: ì½”ë“œ ì»¤ë°‹ ë° PR ìƒì„±

---

## Step 1: ëª¨ë¸ ì„ ì • ë° ê²€ì¦

### 1.1 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì› í™•ì¸

#### timm ëª¨ë¸ í™•ì¸
```python
import timm

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  timm ëª¨ë¸ ëª©ë¡
available_models = timm.list_models()
print(f"Total timm models: {len(available_models)}")

# íŠ¹ì • ëª¨ë¸ ê²€ìƒ‰
model_name = "vgg16"
if model_name in available_models:
    print(f"âœ“ {model_name} is available in timm")
else:
    print(f"âœ— {model_name} is NOT available in timm")

# ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
try:
    model = timm.create_model(model_name, pretrained=False, num_classes=10)
    print(f"âœ“ Model created successfully")
except Exception as e:
    print(f"âœ— Error creating model: {e}")
```

#### ultralytics ëª¨ë¸ í™•ì¸
```python
from ultralytics import YOLO

# YOLO ëª¨ë¸ íŒ¨í„´
# Format: {version}{size}{variant}
# - version: yolov5, yolov8, yolo11, etc.
# - size: n (nano), s (small), m (medium), l (large), x (xlarge)
# - variant: -seg (segmentation), -pose (pose), -cls (classification)

model_name = "yolov8n"
known_patterns = ["yolov5", "yolov8", "yolo11", "yolo_world"]

if any(model_name.startswith(p) for p in known_patterns):
    print(f"âœ“ {model_name} matches known YOLO pattern")

# ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
try:
    model = YOLO(f"{model_name}.pt")  # Will download weights on first use
    print(f"âœ“ Model weights accessible")
except Exception as e:
    print(f"âœ— Error loading model: {e}")
```

### 1.2 ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘

ì¶”ê°€í•˜ë ¤ëŠ” ëª¨ë¸ì˜ ë‹¤ìŒ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”:

1. **ê¸°ë³¸ ì •ë³´**
   - Display name (ì‚¬ìš©ìì—ê²Œ ë³´ì´ëŠ” ì´ë¦„)
   - Model name (ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì •í™•í•œ ì´ë¦„)
   - Description (ê°„ë‹¨í•œ ì„¤ëª…)
   - Parameter count (ì˜ˆ: "25.6M")
   - Input size (ì˜ˆ: 224, 640)

2. **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**
   - ImageNet Top-1/Top-5 accuracy (ë¶„ë¥˜ ëª¨ë¸)
   - COCO mAP (íƒì§€/ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸)
   - Inference speed (ì˜ˆ: "120 img/s on V100")

3. **ì‚¬ìš© ê°€ì´ë“œ**
   - Use cases (ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€)
   - Pros (ì¥ì )
   - Cons (ë‹¨ì )
   - When to use (ì‚¬ìš© ì‹œì )
   - When not to use (ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ì‹œì )
   - Alternatives (ëŒ€ì•ˆ ëª¨ë¸)

4. **ì¶”ì²œ ì„¤ì •**
   - Recommended learning rate
   - Recommended batch size
   - Recommended epochs
   - Recommended optimizer
   - Recommended scheduler

---

## Step 2: ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¶”ê°€

### 2.1 íŒŒì¼ ìœ„ì¹˜

- **timm ëª¨ë¸**: `mvp/training/model_registry/timm_models.py`
- **ultralytics ëª¨ë¸**: `mvp/training/model_registry/ultralytics_models.py`

### 2.2 ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ êµ¬ì¡°

```python
TIMM_MODEL_REGISTRY = {
    "model_name": {
        # ===== ê¸°ë³¸ ì •ë³´ =====
        "display_name": str,           # UIì— í‘œì‹œë  ì´ë¦„
        "description": str,            # í•œ ì¤„ ì„¤ëª…
        "params": str,                 # íŒŒë¼ë¯¸í„° ìˆ˜ (ì˜ˆ: "25.6M")
        "input_size": int,             # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
        "pretrained_available": bool,  # Pretrained ê°€ì¤‘ì¹˜ ì œê³µ ì—¬ë¶€
        "recommended_batch_size": int, # ê¶Œì¥ ë°°ì¹˜ ì‚¬ì´ì¦ˆ
        "recommended_lr": float,       # ê¶Œì¥ í•™ìŠµë¥ 

        # ===== íƒœê·¸ ë° ë¶„ë¥˜ =====
        "tags": List[str],             # ê²€ìƒ‰ìš© íƒœê·¸
        "priority": int,               # ìš°ì„ ìˆœìœ„ (0=P0, 1=P1, 2=P2)
        "task_type": str,              # TaskType enum ê°’

        # ===== ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥ =====
        "benchmark": {
            "imagenet_top1": float,           # ImageNet Top-1 (%)
            "imagenet_top5": float,           # ImageNet Top-5 (%)
            "inference_speed_v100": float,    # V100 ì¶”ë¡  ì†ë„
            "inference_speed_unit": str,      # ë‹¨ìœ„ (ì˜ˆ: "img/s")
        },

        # ===== ì‚¬ìš© ê°€ì´ë“œ =====
        "use_cases": List[str],        # ì‚¬ìš© ì‚¬ë¡€ ëª©ë¡
        "pros": List[str],             # ì¥ì  ëª©ë¡
        "cons": List[str],             # ë‹¨ì  ëª©ë¡
        "when_to_use": str,            # ì‚¬ìš© ì‹œì  (í•œ ë¬¸ì¥)
        "when_not_to_use": str,        # ì‚¬ìš© ê¸ˆì§€ ì‹œì  (í•œ ë¬¸ì¥)
        "alternatives": List[str],     # ëŒ€ì•ˆ ëª¨ë¸ ëª©ë¡

        # ===== ì¶”ì²œ ì„¤ì • =====
        "recommended_settings": {
            "epochs": int,
            "learning_rate": float,
            "batch_size": int,
            "optimizer": str,
            "scheduler": str,
        },
    }
}
```

### 2.3 ì‹¤ì œ ì¶”ê°€ ì˜ˆì‹œ (timm - VGG-16)

`mvp/training/model_registry/timm_models.py` íŒŒì¼ì„ ì—´ê³  ì ì ˆí•œ ìš°ì„ ìˆœìœ„ ì„¹ì…˜ì— ì¶”ê°€:

```python
# ============================================================
# P1: Core Expansion (12 models)
# ============================================================

"vgg16": {
    "display_name": "VGG-16",
    "description": "Classic deep CNN - Simple architecture, excellent for transfer learning",
    "params": "138.4M",
    "input_size": 224,
    "pretrained_available": True,
    "recommended_batch_size": 32,
    "recommended_lr": 0.001,
    "tags": ["p1", "classic", "simple", "transfer-learning"],
    "priority": 1,
    "task_type": "image_classification",
    "benchmark": {
        "imagenet_top1": 71.6,
        "imagenet_top5": 90.6,
        "inference_speed_v100": 120,
        "inference_speed_unit": "img/s",
    },
    "use_cases": [
        "Transfer learning for custom image classification",
        "Educational purposes and research baselines",
        "Feature extraction for computer vision tasks",
        "Simple deployment scenarios",
    ],
    "pros": [
        "Very simple and interpretable architecture",
        "Excellent for transfer learning",
        "Well-documented and widely used",
        "Strong feature extraction capability",
    ],
    "cons": [
        "Large model size (138.4M params)",
        "Lower accuracy than modern architectures",
        "Slow inference compared to efficient models",
        "Not suitable for mobile/edge devices",
    ],
    "when_to_use": "Choose VGG-16 when you need a simple, proven architecture for transfer learning or when interpretability is more important than efficiency.",
    "when_not_to_use": "Avoid VGG-16 for production systems requiring fast inference or deployment on resource-constrained devices.",
    "alternatives": [
        "ResNet-50 (better accuracy/efficiency)",
        "EfficientNet-B0 (much smaller, similar accuracy)",
        "MobileNetV3 (for mobile deployment)",
    ],
    "recommended_settings": {
        "epochs": 100,
        "learning_rate": 0.001,
        "batch_size": 32,
        "optimizer": "Adam",
        "scheduler": "StepLR",
    },
},
```

### 2.4 ì‹¤ì œ ì¶”ê°€ ì˜ˆì‹œ (ultralytics - YOLOv5n)

`mvp/training/model_registry/ultralytics_models.py` íŒŒì¼ì— ì¶”ê°€:

```python
# ============================================================
# P1: Core Expansion (6 models)
# ============================================================

"yolov5nu": {
    "display_name": "YOLOv5n-Ultralytics",
    "description": "YOLOv5 Nano - Ultra-lightweight detection model",
    "params": "1.9M",
    "input_size": 640,
    "pretrained_available": True,
    "recommended_batch_size": 64,
    "recommended_lr": 0.01,
    "tags": ["p1", "yolov5", "nano", "lightweight", "fast"],
    "priority": 1,
    "task_type": "object_detection",
    "benchmark": {
        "coco_map50": 45.7,
        "coco_map50_95": 28.0,
        "inference_speed": "6.3ms (V100)",
    },
    "use_cases": [
        "Real-time object detection on edge devices",
        "Mobile and embedded vision applications",
        "Rapid prototyping and quick experiments",
        "Resource-constrained deployment scenarios",
    ],
    "pros": [
        "Ultra-lightweight (1.9M params)",
        "Very fast inference (6.3ms)",
        "Good accuracy for its size",
        "Easy to deploy on mobile/edge",
    ],
    "cons": [
        "Lower accuracy than larger models",
        "May struggle with small objects",
        "Limited capacity for complex scenes",
    ],
    "when_to_use": "Choose YOLOv5n when deploying on edge devices or when inference speed is critical and moderate accuracy is acceptable.",
    "when_not_to_use": "Avoid for applications requiring high detection accuracy (>40 mAP) or detecting very small objects.",
    "alternatives": [
        "YOLOv8n (newer, similar performance)",
        "YOLOv5s (more accurate, slightly slower)",
        "MobileNet-SSD (alternative lightweight detector)",
    ],
    "recommended_settings": {
        "epochs": 100,
        "learning_rate": 0.01,
        "batch_size": 64,
        "optimizer": "SGD",
        "scheduler": "Cosine",
    },
},
```

### 2.5 TaskType ê°’

`task_type` í•„ë“œì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°’:

```python
# timm (ë¶„ë¥˜ ëª¨ë¸)
"image_classification"

# ultralytics (íƒì§€, ì„¸ê·¸ë©˜í…Œì´ì…˜, í¬ì¦ˆ)
"object_detection"
"instance_segmentation"
"pose_estimation"
"zero_shot_detection"
```

### 2.6 Priority ì„¤ì • ê°€ì´ë“œ

ëª¨ë¸ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ê²°ì •í•˜ëŠ” ê¸°ì¤€:

| Priority | ì„¤ëª… | ëŒ€ìƒ ëª¨ë¸ |
|----------|------|----------|
| **P0** (0) | Initial Validation - í”Œë«í¼ ê¸°ë³¸ ê¸°ëŠ¥ ê²€ì¦ìš© | ResNet-50, EfficientNet-B0, YOLOv8n, YOLO11n |
| **P1** (1) | Core Expansion - í•µì‹¬ ì•„í‚¤í…ì²˜ ë‹¤ì–‘ì„± í™•ë³´ | VGG-16, MobileNetV3, DenseNet, ViT, YOLOv5 variants |
| **P2** (2) | Full Coverage - ì „ë¬¸í™”/ê³ ê¸‰ ì•„í‚¤í…ì²˜ | MaxViT, BEiT, ConvNeXt, YOLO-World, large models |

**ì„ ì • ê¸°ì¤€:**
- **P0**: ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ì•ˆì •ì ì¸ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸
- **P1**: ë‹¤ì–‘í•œ use caseë¥¼ ì»¤ë²„í•˜ëŠ” í•µì‹¬ ëª¨ë¸
- **P2**: íŠ¹ìˆ˜ ëª©ì , ìµœì‹  ì—°êµ¬, ê³ ì„±ëŠ¥ ëª¨ë¸

---

## Step 3: Adapter êµ¬í˜„ (í•„ìš”ì‹œ)

> **Note**: ê¸°ì¡´ í”„ë ˆì„ì›Œí¬(timm, ultralytics)ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì´ ë‹¨ê³„ëŠ” **ìƒëµ**í•©ë‹ˆë‹¤.
> ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ë¥¼ ì¶”ê°€í•  ë•Œë§Œ í•„ìš”í•©ë‹ˆë‹¤.

### 3.1 Adapter êµ¬ì¡°

ëª¨ë“  AdapterëŠ” `mvp/training/adapters/base.py`ì˜ `TrainingAdapter`ë¥¼ ìƒì†í•´ì•¼ í•©ë‹ˆë‹¤.

```python
from adapters.base import TrainingAdapter, MetricsResult, TaskType

class MyNewAdapter(TrainingAdapter):
    """Adapter for new framework."""

    @classmethod
    def get_config_schema(cls) -> ConfigSchema:
        """Return configuration schema."""
        from training.config_schemas import get_my_new_schema
        return get_my_new_schema()

    def train(self, config: Dict[str, Any]) -> MetricsResult:
        """
        Execute training with given config.

        Args:
            config: Training configuration
                - model_name: str
                - dataset_path: str
                - num_epochs: int
                - batch_size: int
                - learning_rate: float
                - ...

        Returns:
            MetricsResult with training metrics
        """
        # 1. Load model
        model = self._load_model(config)

        # 2. Prepare data
        train_loader, val_loader = self._prepare_data(config)

        # 3. Setup optimizer and scheduler
        optimizer = self._setup_optimizer(model, config)
        scheduler = self._setup_scheduler(optimizer, config)

        # 4. Training loop
        for epoch in range(config["num_epochs"]):
            train_metrics = self._train_epoch(model, train_loader, optimizer)
            val_metrics = self._validate(model, val_loader)

            # Save checkpoint
            if val_metrics["accuracy"] > best_acc:
                self._save_checkpoint(model, config["output_dir"])

        # 5. Return final metrics
        return MetricsResult(
            epoch=config["num_epochs"],
            train_loss=train_metrics["loss"],
            val_loss=val_metrics["loss"],
            metrics={
                "accuracy": val_metrics["accuracy"],
                "top5_accuracy": val_metrics["top5_accuracy"],
            }
        )

    def validate(self, config: Dict[str, Any]) -> MetricsResult:
        """Execute validation."""
        # Implementation
        pass
```

### 3.2 Adapter íŒŒì¼ ìƒì„±

1. `mvp/training/adapters/my_new_adapter.py` íŒŒì¼ ìƒì„±
2. `mvp/training/adapters/__init__.py`ì— ì¶”ê°€:
   ```python
   from .my_new_adapter import MyNewAdapter

   __all__ = ["TrainingAdapter", "TimmAdapter", "UltralyticsAdapter", "MyNewAdapter"]
   ```

---

## Step 4: Config Schema ì •ì˜ (í•„ìš”ì‹œ)

> **Note**: ê¸°ì¡´ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì´ ë‹¨ê³„ë„ **ìƒëµ**í•©ë‹ˆë‹¤.

### 4.1 Config Schema êµ¬ì¡°

`mvp/training/config_schemas.py`ì— ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆ í•¨ìˆ˜ ì¶”ê°€:

```python
def get_my_new_schema() -> ConfigSchema:
    """Return configuration schema for my new framework."""
    fields = [
        # Optimizer Settings
        ConfigField(
            name="optimizer_type",
            type="select",
            default="adam",
            options=["adam", "adamw", "sgd"],
            description="Optimizer algorithm",
            group="optimizer",
            required=False
        ),
        ConfigField(
            name="learning_rate",
            type="float",
            default=0.001,
            min=0.0001,
            max=0.1,
            step=0.0001,
            description="Learning rate",
            group="optimizer",
            required=True
        ),

        # Scheduler Settings
        ConfigField(
            name="scheduler_type",
            type="select",
            default="cosine",
            options=["none", "step", "cosine"],
            description="LR scheduler",
            group="scheduler",
            required=False
        ),

        # Augmentation Settings
        ConfigField(
            name="random_flip",
            type="bool",
            default=True,
            description="Random horizontal flip",
            group="augmentation",
            required=False
        ),
    ]

    presets = {
        "easy": {
            "optimizer_type": "adam",
            "learning_rate": 0.001,
            "scheduler_type": "cosine",
        },
        "medium": {
            "optimizer_type": "adamw",
            "learning_rate": 0.0005,
            "scheduler_type": "cosine",
        },
        "advanced": {
            "optimizer_type": "adamw",
            "learning_rate": 0.0003,
            "scheduler_type": "cosine",
        }
    }

    return ConfigSchema(fields=fields, presets=presets)
```

### 4.2 ConfigField íƒ€ì…

| Type | ì„¤ëª… | ì¶”ê°€ íŒŒë¼ë¯¸í„° |
|------|------|--------------|
| `"select"` | ë“œë¡­ë‹¤ìš´ ì„ íƒ | `options: List[str]` |
| `"int"` | ì •ìˆ˜ ì…ë ¥ | `min, max, step` |
| `"float"` | ì‹¤ìˆ˜ ì…ë ¥ | `min, max, step` |
| `"bool"` | ì²´í¬ë°•ìŠ¤ | - |
| `"text"` | í…ìŠ¤íŠ¸ ì…ë ¥ | - |

### 4.3 Group ë¶„ë¥˜

ì¼ê´€ì„± ìˆëŠ” group ì´ë¦„ ì‚¬ìš©:
- `"optimizer"` - ì˜µí‹°ë§ˆì´ì € ì„¤ì •
- `"scheduler"` - ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
- `"augmentation"` - ë°ì´í„° ì¦ê°•
- `"validation"` - ê²€ì¦ ì„¤ì •
- `"optimization"` - í•™ìŠµ ìµœì í™”

---

## Step 5: í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸

### 5.1 í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
cd mvp/training
venv/Scripts/python.exe test_model_compatibility.py
```

### 5.2 ì˜ˆìƒ ì¶œë ¥

```
============================================================
TESTING TIMM MODEL COMPATIBILITY
============================================================
[OK] timm version: 0.9.12
[OK] Total available timm models: 1017

[OK] [P1] VGG-16                         (vgg16)
...

============================================================
TIMM SUMMARY
============================================================
P0: 4/4 available
P1: 7/7 available  <- ìƒˆë¡œìš´ ëª¨ë¸ í¬í•¨
P2: 8/8 available

============================================================
OVERALL SUMMARY
============================================================
timm: 19/19 models available  <- ì´ ê°œìˆ˜ ì¦ê°€
ultralytics: 19/19 known model patterns
```

### 5.3 ì‹¤íŒ¨ ì‹œ í™•ì¸ ì‚¬í•­

ëª¨ë¸ì´ `[FAIL]`ë¡œ í‘œì‹œë˜ë©´:

1. **ëª¨ë¸ëª… ì˜¤íƒ€ í™•ì¸**
   ```python
   import timm
   # ì •í™•í•œ ëª¨ë¸ëª… ê²€ìƒ‰
   matches = [m for m in timm.list_models() if "vgg" in m.lower()]
   print(matches)  # ['vgg11', 'vgg13', 'vgg16', 'vgg19', ...]
   ```

2. **ë²„ì „ í˜¸í™˜ì„± í™•ì¸**
   - timm ë²„ì „: 0.9.12 ì´ìƒ
   - ultralytics ë²„ì „: 8.0.220 ì´ìƒ

3. **ëª¨ë¸ëª… ìˆ˜ì •**
   - ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ `model_name` (ë”•ì…”ë„ˆë¦¬ í‚¤)ì„ ì •í™•í•œ ì´ë¦„ìœ¼ë¡œ ìˆ˜ì •

---

## Step 6: UI í™•ì¸

### 6.1 Backend ì„œë²„ ì‹œì‘

```bash
cd mvp/backend
venv/Scripts/python.exe -m uvicorn app.main:app --reload --port 8000
```

### 6.2 Frontend ì„œë²„ ì‹œì‘

```bash
cd mvp/frontend
npm run dev
```

### 6.3 UIì—ì„œ í™•ì¸í•  í•­ëª©

1. **ëª¨ë¸ ëª©ë¡ API í…ŒìŠ¤íŠ¸**
   ```bash
   curl http://localhost:8000/api/v1/models/list
   ```
   - ìƒˆë¡œ ì¶”ê°€í•œ ëª¨ë¸ì´ ëª©ë¡ì— í‘œì‹œë˜ëŠ”ì§€ í™•ì¸

2. **ìš°ì„ ìˆœìœ„ í•„í„° í…ŒìŠ¤íŠ¸**
   ```bash
   curl http://localhost:8000/api/v1/models/list?priority=1
   ```
   - P1 ëª¨ë¸ë§Œ í•„í„°ë§ë˜ëŠ”ì§€ í™•ì¸

3. **í”„ë ˆì„ì›Œí¬ í•„í„° í…ŒìŠ¤íŠ¸**
   ```bash
   curl http://localhost:8000/api/v1/models/list?framework=timm
   ```

4. **Model Selector UI í™•ì¸**
   - `http://localhost:3000` ì ‘ì†
   - Training í˜ì´ì§€ì—ì„œ ëª¨ë¸ ì„ íƒ UI í™•ì¸
   - ìƒˆë¡œìš´ ëª¨ë¸ì´ ì¹´ë“œë¡œ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸
   - í•„í„°ë§ (ìš°ì„ ìˆœìœ„, í”„ë ˆì„ì›Œí¬, ì‘ì—… ìœ í˜•) ë™ì‘ í™•ì¸
   - ëª¨ë¸ ì¹´ë“œ í´ë¦­ ì‹œ ìƒì„¸ ì •ë³´ í‘œì‹œ í™•ì¸

5. **Config Schema API í…ŒìŠ¤íŠ¸**
   ```bash
   curl http://localhost:8000/api/v1/training/config-schema?framework=timm
   ```
   - Advanced Config ìŠ¤í‚¤ë§ˆê°€ ì˜¬ë°”ë¥´ê²Œ ë°˜í™˜ë˜ëŠ”ì§€ í™•ì¸

---

## Step 7: ì»¤ë°‹ ë° PR

### 7.1 ë³€ê²½ ì‚¬í•­ í™•ì¸

```bash
git status
git diff mvp/training/model_registry/timm_models.py
```

### 7.2 ì»¤ë°‹ ë©”ì‹œì§€ ì‘ì„±

Conventional Commits í˜•ì‹ ì‚¬ìš©:

```bash
git add mvp/training/model_registry/timm_models.py
git commit -m "feat(mvp): add VGG-16 model to P1 registry

Add VGG-16 (vgg16) to P1 model registry with comprehensive metadata:
- Display name: VGG-16
- Params: 138.4M
- ImageNet Top-1: 71.6%
- Use cases: Transfer learning, educational purposes
- Recommended settings: Adam optimizer, 0.001 LR

Compatibility: Verified with timm 0.9.12

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
```

### 7.3 PR ìƒì„±

```bash
git push origin feat/add-vgg16-model
```

PR ì œëª© ë° ì„¤ëª…:
```markdown
## feat(mvp): Add VGG-16 to P1 Model Registry

### Summary
Add VGG-16 (classic CNN architecture) to the P1 model registry for core expansion.

### Changes
- Add VGG-16 metadata to `timm_models.py`
- Includes comprehensive documentation (use cases, pros/cons, alternatives)
- Compatibility verified with timm 0.9.12

### Test Results
- âœ… Model available in timm library
- âœ… Compatibility test passed
- âœ… API endpoints working
- âœ… UI displays model correctly

### Model Details
- **Priority**: P1 (Core Expansion)
- **Parameters**: 138.4M
- **ImageNet Top-1**: 71.6%
- **Use Case**: Transfer learning, educational baseline

### Checklist
- [x] Model metadata added to registry
- [x] Compatibility test passed
- [x] UI confirmed working
- [x] Documentation updated
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: ëª¨ë¸ì´ APIì—ì„œ ë³´ì´ì§€ ì•ŠìŒ

**ì¦ìƒ**: ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì¶”ê°€í–ˆì§€ë§Œ APIì—ì„œ ëª¨ë¸ì´ ì•ˆ ë³´ì„

**í•´ê²° ë°©ë²•**:
```bash
# Backend ì„œë²„ ì¬ì‹œì‘
cd mvp/backend
# Ctrl+Cë¡œ ì„œë²„ ì¤‘ë‹¨ í›„
venv/Scripts/python.exe -m uvicorn app.main:app --reload --port 8000

# ë˜ëŠ” main.py íŒŒì¼ touchë¡œ ìë™ reload
touch app/main.py
```

### ë¬¸ì œ 2: ëª¨ë¸ëª…ì´ í‹€ë ¤ì„œ [FAIL] í‘œì‹œ

**ì¦ìƒ**: í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ì—ì„œ `[FAIL]` í‘œì‹œ

**í•´ê²° ë°©ë²•**:
```python
# 1. ì •í™•í•œ ëª¨ë¸ëª… ì°¾ê¸°
import timm
matches = [m for m in timm.list_models() if "vgg" in m]
print(matches)

# 2. ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ í‚¤ë¥¼ ì •í™•í•œ ì´ë¦„ìœ¼ë¡œ ìˆ˜ì •
# ì˜ëª»ëœ ì˜ˆ: "vgg-16"
# ì˜¬ë°”ë¥¸ ì˜ˆ: "vgg16"
```

### ë¬¸ì œ 3: Config Schemaê°€ í‘œì‹œë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**: Advanced Config UIê°€ ë¹„ì–´ìˆìŒ

**í•´ê²° ë°©ë²•**:
```bash
# 1. Config Schema API í…ŒìŠ¤íŠ¸
curl http://localhost:8000/api/v1/training/config-schema?framework=timm

# 2. config_schemas.pyì—ì„œ í•¨ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì •ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
# 3. Adapterì˜ get_config_schema() ë©”ì†Œë“œ í™•ì¸
```

### ë¬¸ì œ 4: ëª¨ë¸ í•™ìŠµì´ ì‹¤íŒ¨í•¨

**ì¦ìƒ**: ëª¨ë¸ì„ ì„ íƒí•˜ê³  í•™ìŠµ ì‹œì‘ ì‹œ ì—ëŸ¬ ë°œìƒ

**í™•ì¸ ì‚¬í•­**:
1. **ëª¨ë¸ëª…ì´ ì •í™•í•œì§€** - ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ í‚¤ì™€ ì‹¤ì œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë¸ëª… ì¼ì¹˜ ì—¬ë¶€
2. **Pretrained ê°€ì¤‘ì¹˜** - `pretrained_available: True`ì¸ë° ê°€ì¤‘ì¹˜ê°€ ì—†ëŠ” ê²½ìš°
3. **ì…ë ¥ í¬ê¸°** - `input_size`ê°€ ëª¨ë¸ê³¼ ë§ëŠ”ì§€ í™•ì¸
4. **ë°°ì¹˜ ì‚¬ì´ì¦ˆ** - GPU ë©”ëª¨ë¦¬ì— ë§ëŠ” `recommended_batch_size` ì„¤ì •

```python
# ë””ë²„ê¹…: ì§ì ‘ ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
import timm
model = timm.create_model("vgg16", pretrained=False, num_classes=10)
print(f"Model created: {model.__class__.__name__}")
```

---

## ë¶€ë¡: ì°¸ê³  ìë£Œ

### timm ê³µì‹ ë¬¸ì„œ
- GitHub: https://github.com/huggingface/pytorch-image-models
- Docs: https://huggingface.co/docs/timm

### ultralytics ê³µì‹ ë¬¸ì„œ
- GitHub: https://github.com/ultralytics/ultralytics
- Docs: https://docs.ultralytics.com/

### í”„ë¡œì íŠ¸ ë‚´ë¶€ ë¬¸ì„œ
- [Model Registry P0 Implementation](../planning/WEEK1_P0_FINAL.md)
- [Phased Implementation Plan](../planning/WEEK1_PHASED_IMPLEMENTATION.md)
- [Architecture Document](../architecture/ARCHITECTURE.md)

---

## ìš”ì•½

1. **ëª¨ë¸ ì„ ì •**: timm/ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì§€ì› ì—¬ë¶€ í™•ì¸
2. **ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¶”ê°€**: ë©”íƒ€ë°ì´í„° ì™„ì„± (ê¸°ë³¸ ì •ë³´, ë²¤ì¹˜ë§ˆí¬, ê°€ì´ë“œ, ì¶”ì²œ ì„¤ì •)
3. **í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸**: `test_model_compatibility.py` ì‹¤í–‰
4. **UI í™•ì¸**: Frontendì—ì„œ ëª¨ë¸ ì„ íƒ ë° í‘œì‹œ í™•ì¸
5. **ì»¤ë°‹ & PR**: Conventional Commits í˜•ì‹ìœ¼ë¡œ ì»¤ë°‹

**ì†Œìš” ì‹œê°„**: ëª¨ë¸ë‹¹ ì•½ 30-60ë¶„ (ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ í¬í•¨)

ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ ì¶”ê°€ ì‹œì—ë§Œ Adapterì™€ Config Schema êµ¬í˜„ì´ í•„ìš”í•˜ë©°, ê¸°ì¡´ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° **ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¶”ê°€ë§Œìœ¼ë¡œ ì™„ë£Œ**ë©ë‹ˆë‹¤.
